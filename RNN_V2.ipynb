{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14fc022b",
   "metadata": {},
   "source": [
    "Install Pytorch package (need to specify the version to get correctly installed. Possible error will lead died kernal.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8dcb538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f0fb9d",
   "metadata": {},
   "source": [
    "The RNN model with PyTorch will be implemented on the Metadata only to farmiliarize myself with the PyTorch library and get starts with RNN. First of all, we need to treat each patient as an observation and get every "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8b25ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43329a84",
   "metadata": {},
   "source": [
    "A better explanation about the RNN example https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b461620",
   "metadata": {},
   "source": [
    "# Read in data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7299f00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>project</th>\n",
       "      <th>specimen</th>\n",
       "      <th>was_term</th>\n",
       "      <th>delivery_wk</th>\n",
       "      <th>collect_wk</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>NIH.Racial.Category</th>\n",
       "      <th>NIH.Ethnicity.Category</th>\n",
       "      <th>was_preterm</th>\n",
       "      <th>was_early_preterm</th>\n",
       "      <th>collect_tri</th>\n",
       "      <th>age_imp</th>\n",
       "      <th>race_imp</th>\n",
       "      <th>age_imp_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00001</td>\n",
       "      <td>A</td>\n",
       "      <td>A00001-05</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>American Indian</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00002</td>\n",
       "      <td>A</td>\n",
       "      <td>A00002-01</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00003</td>\n",
       "      <td>A</td>\n",
       "      <td>A00003-02</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>Asian-Japanese</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>Asian</td>\n",
       "      <td>from_29_to_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00004</td>\n",
       "      <td>A</td>\n",
       "      <td>A00004-08</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00004</td>\n",
       "      <td>A</td>\n",
       "      <td>A00004-12</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>29</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>J00111</td>\n",
       "      <td>J</td>\n",
       "      <td>J00111-01</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>J00112</td>\n",
       "      <td>J</td>\n",
       "      <td>J00112-01</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3575</th>\n",
       "      <td>J00113</td>\n",
       "      <td>J</td>\n",
       "      <td>J00113-01</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>32</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>White</td>\n",
       "      <td>from_29_to_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576</th>\n",
       "      <td>J00115</td>\n",
       "      <td>J</td>\n",
       "      <td>J00115-01</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>35</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>White</td>\n",
       "      <td>from_29_to_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>J00116</td>\n",
       "      <td>J</td>\n",
       "      <td>J00116-01</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>26</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3578 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant_id project   specimen  was_term  delivery_wk  collect_wk  \\\n",
       "0            A00001       A  A00001-05      True           38          33   \n",
       "1            A00002       A  A00002-01      True           40          38   \n",
       "2            A00003       A  A00003-02      True           40          30   \n",
       "3            A00004       A  A00004-08      True           40          27   \n",
       "4            A00004       A  A00004-12      True           40          29   \n",
       "...             ...     ...        ...       ...          ...         ...   \n",
       "3573         J00111       J  J00111-01      True           40          17   \n",
       "3574         J00112       J  J00112-01      True           39          19   \n",
       "3575         J00113       J  J00113-01      True           41          16   \n",
       "3576         J00115       J  J00115-01      True           42          18   \n",
       "3577         J00116       J  J00116-01      True           40          17   \n",
       "\n",
       "                 race      age               NIH.Racial.Category  \\\n",
       "0     American Indian  Unknown  American Indian or Alaska Native   \n",
       "1               White  Unknown                             White   \n",
       "2      Asian-Japanese  Unknown                             Asian   \n",
       "3               White  Unknown                             White   \n",
       "4               White  Unknown                             White   \n",
       "...               ...      ...                               ...   \n",
       "3573        Caucasian       27                             White   \n",
       "3574        Caucasian       27                             White   \n",
       "3575        Caucasian       32                             White   \n",
       "3576        Caucasian       35                             White   \n",
       "3577        Caucasian       26                             White   \n",
       "\n",
       "     NIH.Ethnicity.Category  was_preterm  was_early_preterm  collect_tri  \\\n",
       "0                   Unknown        False              False            3   \n",
       "1                   Unknown        False              False            3   \n",
       "2                   Unknown        False              False            3   \n",
       "3                   Unknown        False              False            3   \n",
       "4                   Unknown        False              False            3   \n",
       "...                     ...          ...                ...          ...   \n",
       "3573                Unknown        False              False            2   \n",
       "3574                Unknown        False              False            2   \n",
       "3575                Unknown        False              False            2   \n",
       "3576                Unknown        False              False            2   \n",
       "3577                Unknown        False              False            2   \n",
       "\n",
       "      age_imp                          race_imp    age_imp_cat  \n",
       "0          27  American Indian or Alaska Native  from_18_to_28  \n",
       "1          24                             White  from_18_to_28  \n",
       "2          32                             Asian  from_29_to_38  \n",
       "3          25                             White  from_18_to_28  \n",
       "4          25                             White  from_18_to_28  \n",
       "...       ...                               ...            ...  \n",
       "3573       27                             White  from_18_to_28  \n",
       "3574       27                             White  from_18_to_28  \n",
       "3575       32                             White  from_29_to_38  \n",
       "3576       35                             White  from_29_to_38  \n",
       "3577       26                             White  from_18_to_28  \n",
       "\n",
       "[3578 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata = pd.read_csv('/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/metadata_imputed1.csv', delimiter=',')\n",
    "mydata = pd.DataFrame(mydata)\n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb41fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specimen</th>\n",
       "      <th>shannon</th>\n",
       "      <th>inv_simpson</th>\n",
       "      <th>bwpd</th>\n",
       "      <th>phylo_entropy</th>\n",
       "      <th>quadratic</th>\n",
       "      <th>unrooted_pd</th>\n",
       "      <th>rooted_pd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00001-05</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.53935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00002-01</td>\n",
       "      <td>1.96362</td>\n",
       "      <td>1.81277</td>\n",
       "      <td>2.628940</td>\n",
       "      <td>1.318870</td>\n",
       "      <td>0.876314</td>\n",
       "      <td>3.943410</td>\n",
       "      <td>4.14816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00003-02</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.62632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00004-08</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.83870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00004-12</td>\n",
       "      <td>6.94884</td>\n",
       "      <td>4.07385</td>\n",
       "      <td>2.788960</td>\n",
       "      <td>3.134220</td>\n",
       "      <td>1.219900</td>\n",
       "      <td>15.518500</td>\n",
       "      <td>15.58460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>J00111-01</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.25993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>J00112-01</td>\n",
       "      <td>1.00149</td>\n",
       "      <td>1.00108</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>1.93897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3575</th>\n",
       "      <td>J00113-01</td>\n",
       "      <td>3.05187</td>\n",
       "      <td>2.53112</td>\n",
       "      <td>3.399690</td>\n",
       "      <td>2.177080</td>\n",
       "      <td>1.180320</td>\n",
       "      <td>6.952930</td>\n",
       "      <td>7.15767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576</th>\n",
       "      <td>J00115-01</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.26097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>J00116-01</td>\n",
       "      <td>1.09715</td>\n",
       "      <td>1.07276</td>\n",
       "      <td>0.441990</td>\n",
       "      <td>0.201400</td>\n",
       "      <td>0.147330</td>\n",
       "      <td>0.662985</td>\n",
       "      <td>2.47034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3578 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       specimen  shannon  inv_simpson      bwpd  phylo_entropy  quadratic  \\\n",
       "0     A00001-05  1.00000      1.00000  0.000000      -0.000000   0.000000   \n",
       "1     A00002-01  1.96362      1.81277  2.628940       1.318870   0.876314   \n",
       "2     A00003-02  1.00000      1.00000  0.000000      -0.000000   0.000000   \n",
       "3     A00004-08  1.00000      1.00000  0.000000      -0.000000   0.000000   \n",
       "4     A00004-12  6.94884      4.07385  2.788960       3.134220   1.219900   \n",
       "...         ...      ...          ...       ...            ...        ...   \n",
       "3573  J00111-01  1.00000      1.00000  0.000000      -0.000000   0.000000   \n",
       "3574  J00112-01  1.00149      1.00108  0.008313       0.002881   0.002078   \n",
       "3575  J00113-01  3.05187      2.53112  3.399690       2.177080   1.180320   \n",
       "3576  J00115-01  1.00000      1.00000  0.000000      -0.000000   0.000000   \n",
       "3577  J00116-01  1.09715      1.07276  0.441990       0.201400   0.147330   \n",
       "\n",
       "      unrooted_pd  rooted_pd  \n",
       "0        0.000000    2.53935  \n",
       "1        3.943410    4.14816  \n",
       "2        0.000000    2.62632  \n",
       "3        0.000000    1.83870  \n",
       "4       15.518500   15.58460  \n",
       "...           ...        ...  \n",
       "3573     0.000000    2.25993  \n",
       "3574     0.008313    1.93897  \n",
       "3575     6.952930    7.15767  \n",
       "3576     0.000000    2.26097  \n",
       "3577     0.662985    2.47034  \n",
       "\n",
       "[3578 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata_alpha = pd.read_csv('/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/training_data_2022-05-27/alpha_diversity/alpha_diversity.csv', delimiter=',')\n",
    "mydata_alpha = pd.DataFrame(mydata_alpha)\n",
    "mydata_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e4d6a",
   "metadata": {},
   "source": [
    "Combine two data sets together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff810533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>project</th>\n",
       "      <th>specimen</th>\n",
       "      <th>was_term</th>\n",
       "      <th>delivery_wk</th>\n",
       "      <th>collect_wk</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>NIH.Racial.Category</th>\n",
       "      <th>NIH.Ethnicity.Category</th>\n",
       "      <th>...</th>\n",
       "      <th>race_imp</th>\n",
       "      <th>age_imp_cat</th>\n",
       "      <th>specimen</th>\n",
       "      <th>shannon</th>\n",
       "      <th>inv_simpson</th>\n",
       "      <th>bwpd</th>\n",
       "      <th>phylo_entropy</th>\n",
       "      <th>quadratic</th>\n",
       "      <th>unrooted_pd</th>\n",
       "      <th>rooted_pd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00001</td>\n",
       "      <td>A</td>\n",
       "      <td>A00001-05</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>American Indian</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>from_18_to_28</td>\n",
       "      <td>A00001-05</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.53935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00002</td>\n",
       "      <td>A</td>\n",
       "      <td>A00002-01</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "      <td>A00002-01</td>\n",
       "      <td>1.96362</td>\n",
       "      <td>1.81277</td>\n",
       "      <td>2.628940</td>\n",
       "      <td>1.318870</td>\n",
       "      <td>0.876314</td>\n",
       "      <td>3.943410</td>\n",
       "      <td>4.14816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00003</td>\n",
       "      <td>A</td>\n",
       "      <td>A00003-02</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>Asian-Japanese</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>Asian</td>\n",
       "      <td>from_29_to_38</td>\n",
       "      <td>A00003-02</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.62632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00004</td>\n",
       "      <td>A</td>\n",
       "      <td>A00004-08</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "      <td>A00004-08</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.83870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00004</td>\n",
       "      <td>A</td>\n",
       "      <td>A00004-12</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>29</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "      <td>A00004-12</td>\n",
       "      <td>6.94884</td>\n",
       "      <td>4.07385</td>\n",
       "      <td>2.788960</td>\n",
       "      <td>3.134220</td>\n",
       "      <td>1.219900</td>\n",
       "      <td>15.518500</td>\n",
       "      <td>15.58460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>J00111</td>\n",
       "      <td>J</td>\n",
       "      <td>J00111-01</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "      <td>J00111-01</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.25993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>J00112</td>\n",
       "      <td>J</td>\n",
       "      <td>J00112-01</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "      <td>J00112-01</td>\n",
       "      <td>1.00149</td>\n",
       "      <td>1.00108</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>1.93897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3575</th>\n",
       "      <td>J00113</td>\n",
       "      <td>J</td>\n",
       "      <td>J00113-01</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>32</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>from_29_to_38</td>\n",
       "      <td>J00113-01</td>\n",
       "      <td>3.05187</td>\n",
       "      <td>2.53112</td>\n",
       "      <td>3.399690</td>\n",
       "      <td>2.177080</td>\n",
       "      <td>1.180320</td>\n",
       "      <td>6.952930</td>\n",
       "      <td>7.15767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576</th>\n",
       "      <td>J00115</td>\n",
       "      <td>J</td>\n",
       "      <td>J00115-01</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>35</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>from_29_to_38</td>\n",
       "      <td>J00115-01</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.26097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>J00116</td>\n",
       "      <td>J</td>\n",
       "      <td>J00116-01</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>26</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "      <td>J00116-01</td>\n",
       "      <td>1.09715</td>\n",
       "      <td>1.07276</td>\n",
       "      <td>0.441990</td>\n",
       "      <td>0.201400</td>\n",
       "      <td>0.147330</td>\n",
       "      <td>0.662985</td>\n",
       "      <td>2.47034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3578 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant_id project   specimen  was_term  delivery_wk  collect_wk  \\\n",
       "0            A00001       A  A00001-05      True           38          33   \n",
       "1            A00002       A  A00002-01      True           40          38   \n",
       "2            A00003       A  A00003-02      True           40          30   \n",
       "3            A00004       A  A00004-08      True           40          27   \n",
       "4            A00004       A  A00004-12      True           40          29   \n",
       "...             ...     ...        ...       ...          ...         ...   \n",
       "3573         J00111       J  J00111-01      True           40          17   \n",
       "3574         J00112       J  J00112-01      True           39          19   \n",
       "3575         J00113       J  J00113-01      True           41          16   \n",
       "3576         J00115       J  J00115-01      True           42          18   \n",
       "3577         J00116       J  J00116-01      True           40          17   \n",
       "\n",
       "                 race      age               NIH.Racial.Category  \\\n",
       "0     American Indian  Unknown  American Indian or Alaska Native   \n",
       "1               White  Unknown                             White   \n",
       "2      Asian-Japanese  Unknown                             Asian   \n",
       "3               White  Unknown                             White   \n",
       "4               White  Unknown                             White   \n",
       "...               ...      ...                               ...   \n",
       "3573        Caucasian       27                             White   \n",
       "3574        Caucasian       27                             White   \n",
       "3575        Caucasian       32                             White   \n",
       "3576        Caucasian       35                             White   \n",
       "3577        Caucasian       26                             White   \n",
       "\n",
       "     NIH.Ethnicity.Category  ...                          race_imp  \\\n",
       "0                   Unknown  ...  American Indian or Alaska Native   \n",
       "1                   Unknown  ...                             White   \n",
       "2                   Unknown  ...                             Asian   \n",
       "3                   Unknown  ...                             White   \n",
       "4                   Unknown  ...                             White   \n",
       "...                     ...  ...                               ...   \n",
       "3573                Unknown  ...                             White   \n",
       "3574                Unknown  ...                             White   \n",
       "3575                Unknown  ...                             White   \n",
       "3576                Unknown  ...                             White   \n",
       "3577                Unknown  ...                             White   \n",
       "\n",
       "        age_imp_cat   specimen  shannon inv_simpson      bwpd phylo_entropy  \\\n",
       "0     from_18_to_28  A00001-05  1.00000     1.00000  0.000000     -0.000000   \n",
       "1     from_18_to_28  A00002-01  1.96362     1.81277  2.628940      1.318870   \n",
       "2     from_29_to_38  A00003-02  1.00000     1.00000  0.000000     -0.000000   \n",
       "3     from_18_to_28  A00004-08  1.00000     1.00000  0.000000     -0.000000   \n",
       "4     from_18_to_28  A00004-12  6.94884     4.07385  2.788960      3.134220   \n",
       "...             ...        ...      ...         ...       ...           ...   \n",
       "3573  from_18_to_28  J00111-01  1.00000     1.00000  0.000000     -0.000000   \n",
       "3574  from_18_to_28  J00112-01  1.00149     1.00108  0.008313      0.002881   \n",
       "3575  from_29_to_38  J00113-01  3.05187     2.53112  3.399690      2.177080   \n",
       "3576  from_29_to_38  J00115-01  1.00000     1.00000  0.000000     -0.000000   \n",
       "3577  from_18_to_28  J00116-01  1.09715     1.07276  0.441990      0.201400   \n",
       "\n",
       "      quadratic  unrooted_pd  rooted_pd  \n",
       "0      0.000000     0.000000    2.53935  \n",
       "1      0.876314     3.943410    4.14816  \n",
       "2      0.000000     0.000000    2.62632  \n",
       "3      0.000000     0.000000    1.83870  \n",
       "4      1.219900    15.518500   15.58460  \n",
       "...         ...          ...        ...  \n",
       "3573   0.000000     0.000000    2.25993  \n",
       "3574   0.002078     0.008313    1.93897  \n",
       "3575   1.180320     6.952930    7.15767  \n",
       "3576   0.000000     0.000000    2.26097  \n",
       "3577   0.147330     0.662985    2.47034  \n",
       "\n",
       "[3578 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata = pd.concat([mydata, mydata_alpha], axis=1)\n",
    "mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bca3f2",
   "metadata": {},
   "source": [
    "We add 1 on *race_imp* and *age_imp_cat* to indicate category start from 1 since 0 will be used for indicating missing values (Nan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327d6668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_22783/3780121403.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"project\"] = mydata[\"project\"].astype('category').cat.codes\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_22783/3780121403.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"race_imp\"] = mydata[\"race_imp\"].astype('category').cat.codes + 1\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_22783/3780121403.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"age_imp_cat\"] = mydata[\"age_imp_cat\"].astype('category').cat.codes + 1\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_22783/3780121403.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata['was_preterm'] = mydata['was_preterm'].astype('int8')\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_22783/3780121403.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata['was_early_preterm'] = mydata['was_early_preterm'].astype('int8')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "participant_id        object\n",
       "project                 int8\n",
       "specimen              object\n",
       "specimen              object\n",
       "collect_wk             int64\n",
       "was_preterm             int8\n",
       "was_early_preterm       int8\n",
       "race_imp                int8\n",
       "age_imp_cat             int8\n",
       "shannon              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata = mydata[[\"participant_id\", \"project\", \"specimen\", \"collect_wk\", \n",
    "                 \"was_preterm\", \"was_early_preterm\", \"race_imp\", \"age_imp_cat\", \"shannon\"]]\n",
    "mydata[\"project\"] = mydata[\"project\"].astype('category').cat.codes\n",
    "\n",
    "# add 1 to indicate category start from 1\n",
    "mydata[\"race_imp\"] = mydata[\"race_imp\"].astype('category').cat.codes + 1\n",
    "mydata[\"age_imp_cat\"] = mydata[\"age_imp_cat\"].astype('category').cat.codes + 1\n",
    "\n",
    "mydata['was_preterm'] = mydata['was_preterm'].astype('int8')\n",
    "mydata['was_early_preterm'] = mydata['was_early_preterm'].astype('int8')\n",
    "mydata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7412c20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of      participant_id  project   specimen   specimen  collect_wk  was_preterm  \\\n",
       "0            A00001        0  A00001-05  A00001-05          33            0   \n",
       "1            A00002        0  A00002-01  A00002-01          38            0   \n",
       "2            A00003        0  A00003-02  A00003-02          30            0   \n",
       "3            A00004        0  A00004-08  A00004-08          27            0   \n",
       "4            A00004        0  A00004-12  A00004-12          29            0   \n",
       "...             ...      ...        ...        ...         ...          ...   \n",
       "3573         J00111        9  J00111-01  J00111-01          17            0   \n",
       "3574         J00112        9  J00112-01  J00112-01          19            0   \n",
       "3575         J00113        9  J00113-01  J00113-01          16            0   \n",
       "3576         J00115        9  J00115-01  J00115-01          18            0   \n",
       "3577         J00116        9  J00116-01  J00116-01          17            0   \n",
       "\n",
       "      was_early_preterm  race_imp  age_imp_cat  shannon  \n",
       "0                     0         1            3  1.00000  \n",
       "1                     0         5            3  1.96362  \n",
       "2                     0         2            4  1.00000  \n",
       "3                     0         5            3  1.00000  \n",
       "4                     0         5            3  6.94884  \n",
       "...                 ...       ...          ...      ...  \n",
       "3573                  0         5            3  1.00000  \n",
       "3574                  0         5            3  1.00149  \n",
       "3575                  0         5            4  3.05187  \n",
       "3576                  0         5            4  1.00000  \n",
       "3577                  0         5            3  1.09715  \n",
       "\n",
       "[3578 rows x 10 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa51c19",
   "metadata": {},
   "source": [
    "We split the training and testing data set based on *project* J."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b1aabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata_train = mydata[mydata['project']!=9] # Not project J\n",
    "mydata_test  = mydata[mydata['project']==9] # project J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca89d4e0",
   "metadata": {},
   "source": [
    "We want to predict the class of preterm birth and early preterm birth for few consecutive specimemns collected. We will have to define the\n",
    "\n",
    "- Input data (3 covariates)\n",
    "    - The meta data (imputed age and race category) for each observation\n",
    "    - The alpha_diversity (shannon index) for each observation\n",
    "- Output (1 covariate)\n",
    "    - The class label of preterm birth/early preterm birth\n",
    "    \n",
    "via data pre-processing and move the data from numpy arrays to Pytorch data structure - **Torch Tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcdd5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num_covariates = 3\n",
    "output_num_covariates = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1295b91",
   "metadata": {},
   "source": [
    "# Preterm birth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a11bad",
   "metadata": {},
   "source": [
    "The RNN model with two covariates, *age_imp_cat* and *race_imp* are included. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85722261",
   "metadata": {},
   "source": [
    "Some data filtering first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1127d1",
   "metadata": {},
   "source": [
    "1. Only keep the rows with collect_wk < 37 for Preterm task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f98e4c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3381, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata1 = mydata_train.loc[mydata_train['collect_wk']<37,]\n",
    "mydata1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5eefc8",
   "metadata": {},
   "source": [
    "2. Delete the duplicated samples in the same collection week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8391c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2417, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata2 = mydata1.drop_duplicates(subset=['participant_id', 'collect_wk'], keep='first')\n",
    "mydata2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ca36a",
   "metadata": {},
   "source": [
    "Note: Too much samples are deleted, we need to take care of this situation. For metadata table, its OK since the information of duplicates are exactly same. But it will be specimen specific for taxonomy, phylotypes and distance data sets. **We need to discuss it**. We need to either form up some summary statistic for multiple collected sample in the same week or other methods (???)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6843c2e",
   "metadata": {},
   "source": [
    "Since we will give a patient the label of preterm birth as the delievey week < 37, we have $L=36$ as one of the dimension for the tensor, which is the sequence length (number of time points). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8598c1",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c4ef4",
   "metadata": {},
   "source": [
    "### Input data from categorical age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e8066",
   "metadata": {},
   "source": [
    "Here, we assume age category for each patient doesn't change during the pregency months, which is **not time varying**. Therefore, each row in the below are 36 constant for variable *age_imp_cat*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cfe2d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>collect_wk</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A00001</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00003</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00004</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00005</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00006</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00534</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00535</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00536</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00537</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00538</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1174 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "collect_wk       1    2    3    4    5    6    7    8    9    10  ...   27  \\\n",
       "participant_id                                                    ...        \n",
       "A00001          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  ...  3.0   \n",
       "A00003          4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  ...  4.0   \n",
       "A00004          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  ...  3.0   \n",
       "A00005          4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  ...  4.0   \n",
       "A00006          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  ...  3.0   \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "I00534          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  ...  3.0   \n",
       "I00535          4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  ...  4.0   \n",
       "I00536          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  ...  3.0   \n",
       "I00537          4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  ...  4.0   \n",
       "I00538          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  ...  3.0   \n",
       "\n",
       "collect_wk       28   29   30   31   32   33   34   35   36  \n",
       "participant_id                                               \n",
       "A00001          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  \n",
       "A00003          4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  \n",
       "A00004          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  \n",
       "A00005          4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  \n",
       "A00006          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "I00534          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  \n",
       "I00535          4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  \n",
       "I00536          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  \n",
       "I00537          4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  \n",
       "I00538          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  \n",
       "\n",
       "[1174 rows x 36 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata2_wide_age = mydata2.pivot_table(index=['participant_id'], columns='collect_wk', values='age_imp_cat')\n",
    "# sort by collect_wk\n",
    "mydata2_wide_age = mydata2_wide_age.sort_index(axis=1)\n",
    "# mydata2_wide_age = mydata2_wide_age.fillna(0)\n",
    "mydata2_wide_age = mydata2_wide_age.T.fillna(mydata2_wide_age.max(axis=1)).T\n",
    "mydata2_wide_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe273648",
   "metadata": {},
   "source": [
    "### Input data from categorical race"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4769419",
   "metadata": {},
   "source": [
    "Similarly, race category for each patient is also **not time varying**. Therefore, each row in the below are 36 constant for variable *race_imp*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "985e6a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>collect_wk</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A00001</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00003</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00004</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00005</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00006</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00534</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00535</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00536</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00537</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00538</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1174 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "collect_wk       1    2    3    4    5    6    7    8    9    10  ...   27  \\\n",
       "participant_id                                                    ...        \n",
       "A00001          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0   \n",
       "A00003          2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  ...  2.0   \n",
       "A00004          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  ...  5.0   \n",
       "A00005          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  ...  5.0   \n",
       "A00006          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  ...  5.0   \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "I00534          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  ...  5.0   \n",
       "I00535          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  ...  3.0   \n",
       "I00536          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  ...  3.0   \n",
       "I00537          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  ...  3.0   \n",
       "I00538          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  ...  3.0   \n",
       "\n",
       "collect_wk       28   29   30   31   32   33   34   35   36  \n",
       "participant_id                                               \n",
       "A00001          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "A00003          2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  \n",
       "A00004          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  \n",
       "A00005          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  \n",
       "A00006          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "I00534          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  \n",
       "I00535          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  \n",
       "I00536          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  \n",
       "I00537          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  \n",
       "I00538          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  \n",
       "\n",
       "[1174 rows x 36 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata2_wide_race = mydata2.pivot_table(index=['participant_id'], columns='collect_wk', values='race_imp')\n",
    "# sort by collect_wk\n",
    "mydata2_wide_race = mydata2_wide_race.sort_index(axis=1)\n",
    "# mydata2_wide_race = mydata2_wide_race.fillna(0)\n",
    "mydata2_wide_race = mydata2_wide_race.T.fillna(mydata2_wide_race.max(axis=1)).T\n",
    "mydata2_wide_race"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60552635",
   "metadata": {},
   "source": [
    "### Input data from alpha_diversity (Shannon index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dc163e",
   "metadata": {},
   "source": [
    "The variable of *alpha_diversity* for each patient is **time varying**. For each patient/each row, the patient will have different values. If there is NaN value, fill with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4042f64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>collect_wk</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A00001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.94884</td>\n",
       "      <td>3.04127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07470</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.49608</td>\n",
       "      <td>6.05325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00006</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.88744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00534</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00535</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00536</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00537</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I00538</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1174 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "collect_wk       1    2    3    4    5    6    7    8    9    10  ...   27  \\\n",
       "participant_id                                                    ...        \n",
       "A00001          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00003          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00004          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0   \n",
       "A00005          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00006          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "I00534          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "I00535          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "I00536          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "I00537          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "I00538          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "collect_wk       28       29       30   31   32       33   34       35  \\\n",
       "participant_id                                                           \n",
       "A00001          0.0  0.00000  0.00000  0.0  0.0  1.00000  0.0  0.00000   \n",
       "A00003          0.0  0.00000  1.00000  0.0  0.0  0.00000  0.0  0.00000   \n",
       "A00004          0.0  6.94884  3.04127  0.0  0.0  1.00000  0.0  2.07470   \n",
       "A00005          0.0  1.00000  0.00000  0.0  0.0  0.00000  0.0  2.49608   \n",
       "A00006          0.0  0.00000  0.00000  1.0  0.0  1.88744  0.0  0.00000   \n",
       "...             ...      ...      ...  ...  ...      ...  ...      ...   \n",
       "I00534          0.0  0.00000  0.00000  0.0  0.0  0.00000  0.0  0.00000   \n",
       "I00535          0.0  0.00000  0.00000  0.0  0.0  0.00000  0.0  0.00000   \n",
       "I00536          0.0  0.00000  0.00000  0.0  0.0  0.00000  0.0  0.00000   \n",
       "I00537          0.0  0.00000  0.00000  0.0  0.0  0.00000  0.0  0.00000   \n",
       "I00538          0.0  0.00000  0.00000  0.0  0.0  0.00000  0.0  0.00000   \n",
       "\n",
       "collect_wk           36  \n",
       "participant_id           \n",
       "A00001          0.00000  \n",
       "A00003          0.00000  \n",
       "A00004          0.00000  \n",
       "A00005          6.05325  \n",
       "A00006          0.00000  \n",
       "...                 ...  \n",
       "I00534          0.00000  \n",
       "I00535          0.00000  \n",
       "I00536          0.00000  \n",
       "I00537          0.00000  \n",
       "I00538          0.00000  \n",
       "\n",
       "[1174 rows x 36 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata2_wide_shannon = mydata2.pivot_table(index=['participant_id'], columns='collect_wk', values='shannon')\n",
    "# sort by collect_wk\n",
    "mydata2_wide_shannon = mydata2_wide_shannon.sort_index(axis=1)\n",
    "mydata2_wide_shannon = mydata2_wide_shannon.fillna(0)\n",
    "mydata2_wide_shannon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e658a",
   "metadata": {},
   "source": [
    "### Form input tensor for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47b3d0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1174, 36, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[3.0000, 1.0000, 0.0000],\n",
       "         [3.0000, 1.0000, 0.0000],\n",
       "         [3.0000, 1.0000, 0.0000],\n",
       "         ...,\n",
       "         [3.0000, 1.0000, 0.0000],\n",
       "         [3.0000, 1.0000, 0.0000],\n",
       "         [3.0000, 1.0000, 0.0000]],\n",
       "\n",
       "        [[4.0000, 2.0000, 0.0000],\n",
       "         [4.0000, 2.0000, 0.0000],\n",
       "         [4.0000, 2.0000, 0.0000],\n",
       "         ...,\n",
       "         [4.0000, 2.0000, 0.0000],\n",
       "         [4.0000, 2.0000, 0.0000],\n",
       "         [4.0000, 2.0000, 0.0000]],\n",
       "\n",
       "        [[3.0000, 5.0000, 0.0000],\n",
       "         [3.0000, 5.0000, 0.0000],\n",
       "         [3.0000, 5.0000, 0.0000],\n",
       "         ...,\n",
       "         [3.0000, 5.0000, 0.0000],\n",
       "         [3.0000, 5.0000, 2.0747],\n",
       "         [3.0000, 5.0000, 0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[3.0000, 3.0000, 0.0000],\n",
       "         [3.0000, 3.0000, 0.0000],\n",
       "         [3.0000, 3.0000, 0.0000],\n",
       "         ...,\n",
       "         [3.0000, 3.0000, 0.0000],\n",
       "         [3.0000, 3.0000, 0.0000],\n",
       "         [3.0000, 3.0000, 0.0000]],\n",
       "\n",
       "        [[4.0000, 3.0000, 0.0000],\n",
       "         [4.0000, 3.0000, 0.0000],\n",
       "         [4.0000, 3.0000, 0.0000],\n",
       "         ...,\n",
       "         [4.0000, 3.0000, 0.0000],\n",
       "         [4.0000, 3.0000, 0.0000],\n",
       "         [4.0000, 3.0000, 0.0000]],\n",
       "\n",
       "        [[3.0000, 3.0000, 0.0000],\n",
       "         [3.0000, 3.0000, 0.0000],\n",
       "         [3.0000, 3.0000, 0.0000],\n",
       "         ...,\n",
       "         [3.0000, 3.0000, 0.0000],\n",
       "         [3.0000, 3.0000, 0.0000],\n",
       "         [3.0000, 3.0000, 0.0000]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, seq_length = mydata2_wide_shannon.shape\n",
    "mytrain_input = np.zeros((batch_size, seq_length, input_num_covariates), dtype=np.float32)\n",
    "for i in range(batch_size):\n",
    "    mytrain_input[i,:,0] = mydata2_wide_age.iloc[[i]]\n",
    "    mytrain_input[i,:,1] = mydata2_wide_race.iloc[[i]]\n",
    "    mytrain_input[i,:,2] = mydata2_wide_shannon.iloc[[i]]\n",
    "# change to rnn input format\n",
    "input_seq = torch.from_numpy(mytrain_input)\n",
    "print(input_seq.shape)\n",
    "input_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e69b9",
   "metadata": {},
   "source": [
    "## Output data from Preterm birth label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84dbb94",
   "metadata": {},
   "source": [
    "1. Linear smoothed class label for Only class 1\n",
    "- For class 0 (not preterm): \n",
    "- For class 1 (preterm): from starting week (0.5) to last collection week (1) and keep label 1 for the rest labels;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4954d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1174, 36, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5147, 0.4853],\n",
      "        [0.5294, 0.4706],\n",
      "        [0.5441, 0.4559],\n",
      "        [0.5588, 0.4412],\n",
      "        [0.5735, 0.4265],\n",
      "        [0.5882, 0.4118],\n",
      "        [0.6029, 0.3971],\n",
      "        [0.6176, 0.3824],\n",
      "        [0.6324, 0.3676],\n",
      "        [0.6471, 0.3529],\n",
      "        [0.6618, 0.3382],\n",
      "        [0.6765, 0.3235],\n",
      "        [0.6912, 0.3088],\n",
      "        [0.7059, 0.2941],\n",
      "        [0.7206, 0.2794],\n",
      "        [0.7353, 0.2647],\n",
      "        [0.7500, 0.2500],\n",
      "        [0.7647, 0.2353],\n",
      "        [0.7794, 0.2206],\n",
      "        [0.7941, 0.2059],\n",
      "        [0.8088, 0.1912],\n",
      "        [0.8235, 0.1765],\n",
      "        [0.8382, 0.1618],\n",
      "        [0.8529, 0.1471],\n",
      "        [0.8676, 0.1324],\n",
      "        [0.8824, 0.1176],\n",
      "        [0.8971, 0.1029],\n",
      "        [0.9118, 0.0882],\n",
      "        [0.9265, 0.0735],\n",
      "        [0.9412, 0.0588],\n",
      "        [0.9559, 0.0441],\n",
      "        [0.9706, 0.0294],\n",
      "        [0.9853, 0.0147],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "mydata2_wide_Y = mydata2.pivot_table(index=['participant_id'], columns='collect_wk', values='was_preterm')\n",
    "# sort by collect_wk\n",
    "mydata2_wide_Y = mydata2_wide_Y.sort_index(axis=1)\n",
    "mydata2_wide_Y = mydata2_wide_Y.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "\n",
    "output_seq = np.ones((batch_size, seq_length, output_num_covariates), dtype=np.float32)\n",
    "for i in range(batch_size):\n",
    "    tmp = mydata2_wide_Y.iloc[i,:]\n",
    "    if max(tmp) == 1:\n",
    "        # label linear smoonthing\n",
    "        lastmax = np.argmax(tmp.cumsum())  # last maximum 1\n",
    "        output_seq[i,range(lastmax),0] = np.linspace(start=0.5, stop=1, num=lastmax)\n",
    "    else:\n",
    "        # just 0\n",
    "        output_seq[i,:,0] = tmp\n",
    "    output_seq[i,:,1] = 1-output_seq[i,:,0]\n",
    "        \n",
    "# change to rnn input format\n",
    "output_seq = torch.from_numpy(output_seq)\n",
    "print(output_seq.shape)\n",
    "print(output_seq[1]) # label 0\n",
    "print(output_seq[5]) # label 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb53f3",
   "metadata": {},
   "source": [
    "2. Linear smoothed class label for class 0 and 1\n",
    "- For class 0 (not preterm): from starting week (0.5) to last collection week (0) and keep label 0 for the rest labels;\n",
    "- For class 1 (preterm): from starting week (0.5) to last collection week (1) and keep label 1 for the rest labels;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d3e45b",
   "metadata": {},
   "source": [
    "Since the second smoothing label applied later, the model trainning used 2nd approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f0d328b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1174, 36, 2])\n",
      "tensor([[0.5000, 0.4821, 0.4643, 0.4464, 0.4286, 0.4107, 0.3929, 0.3750, 0.3571,\n",
      "         0.3393, 0.3214, 0.3036, 0.2857, 0.2679, 0.2500, 0.2321, 0.2143, 0.1964,\n",
      "         0.1786, 0.1607, 0.1429, 0.1250, 0.1071, 0.0893, 0.0714, 0.0536, 0.0357,\n",
      "         0.0179, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5179, 0.5357, 0.5536, 0.5714, 0.5893, 0.6071, 0.6250, 0.6429,\n",
      "         0.6607, 0.6786, 0.6964, 0.7143, 0.7321, 0.7500, 0.7679, 0.7857, 0.8036,\n",
      "         0.8214, 0.8393, 0.8571, 0.8750, 0.8929, 0.9107, 0.9286, 0.9464, 0.9643,\n",
      "         0.9821, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])\n",
      "tensor([[0.5000, 0.5156, 0.5312, 0.5469, 0.5625, 0.5781, 0.5938, 0.6094, 0.6250,\n",
      "         0.6406, 0.6562, 0.6719, 0.6875, 0.7031, 0.7188, 0.7344, 0.7500, 0.7656,\n",
      "         0.7812, 0.7969, 0.8125, 0.8281, 0.8438, 0.8594, 0.8750, 0.8906, 0.9062,\n",
      "         0.9219, 0.9375, 0.9531, 0.9688, 0.9844, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.5000, 0.4844, 0.4688, 0.4531, 0.4375, 0.4219, 0.4062, 0.3906, 0.3750,\n",
      "         0.3594, 0.3438, 0.3281, 0.3125, 0.2969, 0.2812, 0.2656, 0.2500, 0.2344,\n",
      "         0.2188, 0.2031, 0.1875, 0.1719, 0.1562, 0.1406, 0.1250, 0.1094, 0.0938,\n",
      "         0.0781, 0.0625, 0.0469, 0.0312, 0.0156, 0.0000, 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "mydata2_wide_Y = mydata2.pivot_table(index=['participant_id'], columns='collect_wk', values='was_preterm')\n",
    "# sort by collect_wk\n",
    "mydata2_wide_Y = mydata2_wide_Y.sort_index(axis=1)\n",
    "\n",
    "output_seq = np.zeros((batch_size, seq_length, output_num_covariates), dtype=np.float32)\n",
    "for i in range(batch_size):\n",
    "    tmp = mydata2_wide_Y.iloc[i,:]\n",
    "    flag = np.argmax(tmp.cumsum()) # first non na used for class 0\n",
    "    if np.nanmax(tmp) == 1:\n",
    "        # fill all position 1 to have final labels equal to 1\n",
    "        output_seq[i,:,0].fill(1)\n",
    "        # label linear smoonthing from 0.5 to 1\n",
    "        lastobs = np.argmax(tmp.cumsum())  # last non-zero element\n",
    "        output_seq[i,range(lastobs),0] = np.linspace(start=0.5, stop=1, num=lastobs)\n",
    "    else:\n",
    "        # fill all position 0 to have final labels equal to 0 (but array alrady initialize as 0)\n",
    "        # label linear smoonthing from 0.5 to 0\n",
    "        output_seq[i,range(flag),0] = np.linspace(start=0.5, stop=0, num=flag)\n",
    "        \n",
    "    output_seq[i,:,1] = 1-output_seq[i,:,0]\n",
    "        \n",
    "# change to rnn input format\n",
    "output_seq = torch.from_numpy(output_seq)\n",
    "print(output_seq.shape)\n",
    "print(output_seq[1].T) # label 1 \n",
    "print(output_seq[5].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b3a1cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1174, 36, 2])\n",
      "tensor([[0.5000, 0.4828, 0.4655, 0.4483, 0.4310, 0.4138, 0.3966, 0.3793, 0.3621,\n",
      "         0.3448, 0.3276, 0.3103, 0.2931, 0.2759, 0.2586, 0.2414, 0.2241, 0.2069,\n",
      "         0.1897, 0.1724, 0.1552, 0.1379, 0.1207, 0.1034, 0.0862, 0.0690, 0.0517,\n",
      "         0.0345, 0.0172, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5172, 0.5345, 0.5517, 0.5690, 0.5862, 0.6034, 0.6207, 0.6379,\n",
      "         0.6552, 0.6724, 0.6897, 0.7069, 0.7241, 0.7414, 0.7586, 0.7759, 0.7931,\n",
      "         0.8103, 0.8276, 0.8448, 0.8621, 0.8793, 0.8966, 0.9138, 0.9310, 0.9483,\n",
      "         0.9655, 0.9828, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])\n",
      "tensor([[0.5000, 0.5152, 0.5303, 0.5455, 0.5606, 0.5758, 0.5909, 0.6061, 0.6212,\n",
      "         0.6364, 0.6515, 0.6667, 0.6818, 0.6970, 0.7121, 0.7273, 0.7424, 0.7576,\n",
      "         0.7727, 0.7879, 0.8030, 0.8182, 0.8333, 0.8485, 0.8636, 0.8788, 0.8939,\n",
      "         0.9091, 0.9242, 0.9394, 0.9545, 0.9697, 0.9848, 1.0000, 1.0000, 1.0000],\n",
      "        [0.5000, 0.4848, 0.4697, 0.4545, 0.4394, 0.4242, 0.4091, 0.3939, 0.3788,\n",
      "         0.3636, 0.3485, 0.3333, 0.3182, 0.3030, 0.2879, 0.2727, 0.2576, 0.2424,\n",
      "         0.2273, 0.2121, 0.1970, 0.1818, 0.1667, 0.1515, 0.1364, 0.1212, 0.1061,\n",
      "         0.0909, 0.0758, 0.0606, 0.0455, 0.0303, 0.0152, 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "mydata2_wide_Y = mydata2.pivot_table(index=['participant_id'], columns='collect_wk', values='was_preterm')\n",
    "# sort by collect_wk\n",
    "mydata2_wide_Y = mydata2_wide_Y.sort_index(axis=1)\n",
    "\n",
    "output_seq = np.zeros((batch_size, seq_length, output_num_covariates), dtype=np.float32)\n",
    "\n",
    "for i in range(batch_size):\n",
    "    tmp = mydata2_wide_Y.iloc[i,:]\n",
    "    flag = tmp.last_valid_index() # last non NaN for patient i\n",
    "    if np.nanmax(tmp) == 1:\n",
    "        # label linear smoonthing from 0.5 to 1\n",
    "        # fill all position 1 to have final labels equal to 1\n",
    "        output_seq[i,:,0].fill(1)\n",
    "        output_seq[i,range(flag),0] = np.linspace(start=0.5, stop=1, num=flag)\n",
    "    else:\n",
    "        # label linear smoonthing from 0.5 to 0\n",
    "        # fill all position 0 to have final labels equal to 0 \n",
    "        #     but array alrady initialize as 0\n",
    "        output_seq[i,range(flag),0] = np.linspace(start=0.5, stop=0, num=flag)\n",
    "        \n",
    "    output_seq[i,:,1] = 1-output_seq[i,:,0]\n",
    "    \n",
    "# change to rnn input format\n",
    "output_seq = torch.from_numpy(output_seq)\n",
    "print(output_seq.shape)\n",
    "print(output_seq[1].T) # label 1 \n",
    "print(output_seq[5].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab1a8060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "301a270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        # print(out.shape)\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7825a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model(input_size=input_num_covariates, output_size=output_num_covariates, hidden_dim=18, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 500\n",
    "lr=0.01\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bdf0fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/500............. Loss: 0.1760\n",
      "Epoch: 20/500............. Loss: 0.1443\n",
      "Epoch: 30/500............. Loss: 0.1350\n",
      "Epoch: 40/500............. Loss: 0.1319\n",
      "Epoch: 50/500............. Loss: 0.1304\n",
      "Epoch: 60/500............. Loss: 0.1297\n",
      "Epoch: 70/500............. Loss: 0.1293\n",
      "Epoch: 80/500............. Loss: 0.1291\n",
      "Epoch: 90/500............. Loss: 0.1288\n",
      "Epoch: 100/500............. Loss: 0.1286\n",
      "Epoch: 110/500............. Loss: 0.1283\n",
      "Epoch: 120/500............. Loss: 0.1279\n",
      "Epoch: 130/500............. Loss: 0.1274\n",
      "Epoch: 140/500............. Loss: 0.1269\n",
      "Epoch: 150/500............. Loss: 0.1265\n",
      "Epoch: 160/500............. Loss: 0.1261\n",
      "Epoch: 170/500............. Loss: 0.1258\n",
      "Epoch: 180/500............. Loss: 0.1273\n",
      "Epoch: 190/500............. Loss: 0.1264\n",
      "Epoch: 200/500............. Loss: 0.1256\n",
      "Epoch: 210/500............. Loss: 0.1252\n",
      "Epoch: 220/500............. Loss: 0.1249\n",
      "Epoch: 230/500............. Loss: 0.1247\n",
      "Epoch: 240/500............. Loss: 0.1244\n",
      "Epoch: 250/500............. Loss: 0.1244\n",
      "Epoch: 260/500............. Loss: 0.1241\n",
      "Epoch: 270/500............. Loss: 0.1243\n",
      "Epoch: 280/500............. Loss: 0.1240\n",
      "Epoch: 290/500............. Loss: 0.1242\n",
      "Epoch: 300/500............. Loss: 0.1238\n",
      "Epoch: 310/500............. Loss: 0.1243\n",
      "Epoch: 320/500............. Loss: 0.1252\n",
      "Epoch: 330/500............. Loss: 0.1242\n",
      "Epoch: 340/500............. Loss: 0.1238\n",
      "Epoch: 350/500............. Loss: 0.1236\n",
      "Epoch: 360/500............. Loss: 0.1233\n",
      "Epoch: 370/500............. Loss: 0.1239\n",
      "Epoch: 380/500............. Loss: 0.1236\n",
      "Epoch: 390/500............. Loss: 0.1239\n",
      "Epoch: 400/500............. Loss: 0.1232\n",
      "Epoch: 410/500............. Loss: 0.1234\n",
      "Epoch: 420/500............. Loss: 0.1226\n",
      "Epoch: 430/500............. Loss: 0.1242\n",
      "Epoch: 440/500............. Loss: 0.1232\n",
      "Epoch: 450/500............. Loss: 0.1235\n",
      "Epoch: 460/500............. Loss: 0.1248\n",
      "Epoch: 470/500............. Loss: 0.1243\n",
      "Epoch: 480/500............. Loss: 0.1236\n",
      "Epoch: 490/500............. Loss: 0.1235\n",
      "Epoch: 500/500............. Loss: 0.1224\n"
     ]
    }
   ],
   "source": [
    "# Training Run\n",
    "input_seq = input_seq.to(device)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    #input_seq = input_seq.to(device)\n",
    "    output, hidden = model(input_seq)\n",
    "    output_seq = output_seq.to(device)\n",
    "    loss = criterion(output, output_seq.view(-1, output_num_covariates))\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85050fab",
   "metadata": {},
   "source": [
    "# Apply back to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd6cca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to print all elements in array\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b742dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_22783/3108587336.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/distiller/project/pytorch/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  mytrain_input_one = torch.Tensor([mytrain_input_one])\n"
     ]
    }
   ],
   "source": [
    "model.eval() # eval mode\n",
    "\n",
    "pred_prob = []\n",
    "predicted_labels = []\n",
    "for ii in range(batch_size):\n",
    "    mytrain_input_one = mytrain_input[ii]\n",
    "    lastobs = np.argmax(mytrain_input_one[:,2].cumsum())\n",
    "    mytrain_input_one = torch.Tensor([mytrain_input_one])\n",
    "    out, hidden = model(mytrain_input_one)\n",
    "    prob = nn.functional.softmax(out, dim=1).data[:,0].numpy()\n",
    "    \n",
    "    #----- Using the highest predicted probability to generate label\n",
    "    # prob_max = torch.max(prob).item()\n",
    "    # print(prob_max)\n",
    "    # pred_label = 1*(prob_max < 0.5)\n",
    "    \n",
    "    #----- Using the predicted probability of the last sample-collected week to generate label\n",
    "    prob_obs = prob[lastobs]\n",
    "    pred_label = 1*(prob_obs > 0.5)\n",
    "    pred_prob.append(prob_obs)\n",
    "    predicted_labels.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bc79f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = mydata2_wide_Y.mean(axis=1)\n",
    "pred_res = pd.DataFrame({'prob': pred_prob, 'pred': predicted_labels, \"obs\": actual_labels})\n",
    "\n",
    "# uncomment this self-defined function to print all elements in pred_res\n",
    "# print_full(pred_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25b9c834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6771720613287905"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_accuracy = metrics.accuracy_score(actual_labels, predicted_labels, normalize=False) / float(actual_labels.size)\n",
    "my_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fdbad9",
   "metadata": {},
   "source": [
    "# Apply the simple RNN on testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bec0460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = mydata_test[[\"participant_id\", \"project\", \"specimen\", \"collect_wk\", \n",
    "                       \"was_preterm\", \"was_early_preterm\", \"race_imp\", \"age_imp_cat\", \"shannon\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c55f15",
   "metadata": {},
   "source": [
    "The proportion of preterm in testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8489199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18072289156626506"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset['was_preterm'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a17dcf",
   "metadata": {},
   "source": [
    "Same filtering applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9b91e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep the rows with collect_wk < 37 for Preterm task\n",
    "testset1 = testset.loc[testset['collect_wk']<37,]\n",
    "\n",
    "# delete the duplicated samples in the same collection week\n",
    "testset2 = testset1.drop_duplicates(subset=['participant_id', 'collect_wk'], keep='first')\n",
    "testset2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b305c080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>collect_wk</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>J00001</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00004</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00007</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00008</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00010</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00111</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00112</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00113</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00115</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00116</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "collect_wk       12   13   14   15   16   17   18   19\n",
       "participant_id                                        \n",
       "J00001          4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0\n",
       "J00004          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0\n",
       "J00007          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "J00008          4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0\n",
       "J00010          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...\n",
       "J00111          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0\n",
       "J00112          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0\n",
       "J00113          4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0\n",
       "J00115          4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0\n",
       "J00116          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0\n",
       "\n",
       "[83 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset2_wide_age = testset2.pivot_table(index=['participant_id'], columns='collect_wk', values='age_imp_cat')\n",
    "# sort by collect_wk\n",
    "testset2_wide_age = testset2_wide_age.sort_index(axis=1)\n",
    "# testset2_wide_age = testset2_wide_age.fillna(0)\n",
    "testset2_wide_age = testset2_wide_age.T.fillna(testset2_wide_age.max(axis=1)).T\n",
    "testset2_wide_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "573b61fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>collect_wk</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>J00001</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00004</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00007</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00008</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00010</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00111</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00112</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00113</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00115</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00116</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "collect_wk       12   13   14   15   16   17   18   19\n",
       "participant_id                                        \n",
       "J00001          2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0\n",
       "J00004          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0\n",
       "J00007          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0\n",
       "J00008          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0\n",
       "J00010          3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0\n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...\n",
       "J00111          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0\n",
       "J00112          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0\n",
       "J00113          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0\n",
       "J00115          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0\n",
       "J00116          5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0\n",
       "\n",
       "[83 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset2_wide_race = testset2.pivot_table(index=['participant_id'], columns='collect_wk', values='race_imp')\n",
    "# sort by collect_wk\n",
    "testset2_wide_race = testset2_wide_race.sort_index(axis=1)\n",
    "# testset2_wide_race = testset2_wide_race.fillna(0)\n",
    "testset2_wide_race = testset2_wide_race.T.fillna(testset2_wide_race.max(axis=1)).T\n",
    "testset2_wide_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "863ef6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>collect_wk</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>J00001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.25278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00008</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00010</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.09082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00112</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.05187</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00115</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J00116</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.09715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "collect_wk       12   13       14   15       16       17   18       19\n",
       "participant_id                                                        \n",
       "J00001          0.0  0.0  0.00000  0.0  0.00000  0.00000  1.0  0.00000\n",
       "J00004          0.0  0.0  0.00000  0.0  0.00000  1.25278  0.0  0.00000\n",
       "J00007          0.0  0.0  0.00000  0.0  1.00000  0.00000  0.0  0.00000\n",
       "J00008          0.0  0.0  0.00000  0.0  0.00000  0.00000  1.0  0.00000\n",
       "J00010          0.0  0.0  2.09082  0.0  0.00000  0.00000  0.0  0.00000\n",
       "...             ...  ...      ...  ...      ...      ...  ...      ...\n",
       "J00111          0.0  0.0  0.00000  0.0  0.00000  1.00000  0.0  0.00000\n",
       "J00112          0.0  0.0  0.00000  0.0  0.00000  0.00000  0.0  1.00149\n",
       "J00113          0.0  0.0  0.00000  0.0  3.05187  0.00000  0.0  0.00000\n",
       "J00115          0.0  0.0  0.00000  0.0  0.00000  0.00000  1.0  0.00000\n",
       "J00116          0.0  0.0  0.00000  0.0  0.00000  1.09715  0.0  0.00000\n",
       "\n",
       "[83 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset2_wide_shannon = testset2.pivot_table(index=['participant_id'], columns='collect_wk', values='shannon')\n",
    "# sort by collect_wk\n",
    "testset2_wide_shannon = testset2_wide_shannon.sort_index(axis=1)\n",
    "testset2_wide_shannon = testset2_wide_shannon.fillna(0)\n",
    "testset2_wide_shannon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edb25d",
   "metadata": {},
   "source": [
    "Fill-in zeros for empty collection weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9909fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = testset2_wide_shannon.shape[0]\n",
    "# get column for available collect_wk's\n",
    "test_index = testset2_wide_shannon._get_numeric_data().columns.values - 1 # index starting from 0\n",
    "test_index = test_index.tolist()\n",
    "mytest_input = np.zeros((test_batch_size, seq_length, input_num_covariates), dtype=np.float32)\n",
    "\n",
    "for i in range(test_batch_size):\n",
    "    mytest_input[i,:,0] = testset2_wide_age.iloc[i,1]\n",
    "    mytest_input[i,:,1] = testset2_wide_race.iloc[i,1]\n",
    "    mytest_input[i,test_index,2] = testset2_wide_shannon.iloc[[i]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3332ac",
   "metadata": {},
   "source": [
    "Prediction through the trainned network. Here, we use the probability associated with the last collection week to predict class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc666e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # eval mode\n",
    "\n",
    "pred_prob = []\n",
    "predicted_labels = []\n",
    "for ii in range(test_batch_size):\n",
    "    mytest_input_one = mytest_input[ii]\n",
    "    lastobs = np.argmax(mytest_input_one[:,2].cumsum())\n",
    "    mytest_input_one = torch.Tensor([mytest_input_one])\n",
    "    out, hidden = model(mytest_input_one)\n",
    "    prob = nn.functional.softmax(out, dim=1).data[:,0].numpy()\n",
    "    \n",
    "    #----- Using the highest predicted probability to generate label\n",
    "    # prob_max = torch.max(prob).item()\n",
    "    # print(prob_max)\n",
    "    # pred_label = 1*(prob_max > 0.5)\n",
    "    \n",
    "    #----- Using the predicted probability of the last sample-collected week to generate label\n",
    "    prob_obs = prob[lastobs]\n",
    "    pred_label = 1*(prob_obs > 0.5)\n",
    "    pred_prob.append(prob_obs)\n",
    "    predicted_labels.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f027b11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    prob  pred  obs\n",
      "participant_id                     \n",
      "J00001          0.523153     1  0.0\n",
      "J00004          0.447048     0  0.0\n",
      "J00007          0.502631     1  0.0\n",
      "J00008          0.450507     0  0.0\n",
      "J00010          0.572330     1  0.0\n",
      "J00011          0.440346     0  0.0\n",
      "J00012          0.450507     0  0.0\n",
      "J00013          0.427740     0  0.0\n",
      "J00014          0.516524     1  1.0\n",
      "J00015          0.450682     0  0.0\n",
      "J00016          0.576654     1  0.0\n",
      "J00018          0.398567     0  0.0\n",
      "J00019          0.574696     1  1.0\n",
      "J00020          0.524097     1  0.0\n",
      "J00022          0.450902     0  0.0\n",
      "J00023          0.450300     0  0.0\n",
      "J00024          0.501282     1  1.0\n",
      "J00025          0.525169     1  0.0\n",
      "J00026          0.502631     1  0.0\n",
      "J00027          0.450902     0  0.0\n",
      "J00028          0.632713     1  0.0\n",
      "J00029          0.516538     1  1.0\n",
      "J00030          0.424743     0  0.0\n",
      "J00031          0.450613     0  0.0\n",
      "J00032          0.452538     0  0.0\n",
      "J00033          0.451740     0  1.0\n",
      "J00034          0.525512     1  0.0\n",
      "J00037          0.485708     0  0.0\n",
      "J00038          0.450863     0  0.0\n",
      "J00039          0.450385     0  0.0\n",
      "J00040          0.524384     1  0.0\n",
      "J00041          0.385231     0  0.0\n",
      "J00042          0.448834     0  0.0\n",
      "J00043          0.449710     0  0.0\n",
      "J00047          0.450902     0  0.0\n",
      "J00049          0.525496     1  0.0\n",
      "J00050          0.391381     0  0.0\n",
      "J00051          0.450367     0  0.0\n",
      "J00052          0.385790     0  0.0\n",
      "J00053          0.450893     0  0.0\n",
      "J00054          0.452015     0  0.0\n",
      "J00056          0.432647     0  0.0\n",
      "J00058          0.450706     0  0.0\n",
      "J00059          0.391346     0  0.0\n",
      "J00062          0.447624     0  0.0\n",
      "J00063          0.450561     0  0.0\n",
      "J00067          0.448273     0  0.0\n",
      "J00071          0.447778     0  0.0\n",
      "J00072          0.502631     1  0.0\n",
      "J00073          0.449194     0  0.0\n",
      "J00075          0.449540     0  0.0\n",
      "J00076          0.450153     0  0.0\n",
      "J00077          0.385304     0  1.0\n",
      "J00078          0.451776     0  1.0\n",
      "J00079          0.450902     0  1.0\n",
      "J00080          0.391658     0  1.0\n",
      "J00082          0.624119     1  1.0\n",
      "J00086          0.500292     1  1.0\n",
      "J00087          0.450902     0  1.0\n",
      "J00088          0.385320     0  1.0\n",
      "J00090          0.450647     0  1.0\n",
      "J00091          0.398743     0  1.0\n",
      "J00093          0.385309     0  0.0\n",
      "J00095          0.502223     1  0.0\n",
      "J00096          0.450368     0  0.0\n",
      "J00097          0.449793     0  0.0\n",
      "J00098          0.385310     0  0.0\n",
      "J00099          0.525512     1  0.0\n",
      "J00100          0.450507     0  0.0\n",
      "J00101          0.498782     0  0.0\n",
      "J00102          0.450539     0  0.0\n",
      "J00103          0.565640     1  0.0\n",
      "J00104          0.612493     1  0.0\n",
      "J00105          0.447905     0  0.0\n",
      "J00106          0.449383     0  0.0\n",
      "J00107          0.501790     1  0.0\n",
      "J00108          0.450541     0  0.0\n",
      "J00109          0.437004     0  0.0\n",
      "J00111          0.449217     0  0.0\n",
      "J00112          0.448230     0  0.0\n",
      "J00113          0.432761     0  0.0\n",
      "J00115          0.450507     0  0.0\n",
      "J00116          0.448408     0  0.0\n"
     ]
    }
   ],
   "source": [
    "testset2_wide_Y = testset2.pivot_table(index=['participant_id'], columns='collect_wk', values='was_preterm')\n",
    "# sort by collect_wk\n",
    "testset2_wide_Y = testset2_wide_Y.sort_index(axis=1)\n",
    "actual_labels = testset2_wide_Y.mean(axis=1)\n",
    "\n",
    "pred_res = pd.DataFrame({'prob': pred_prob, 'pred': predicted_labels, \"obs\": actual_labels})\n",
    "print_full(pred_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328bbc1e",
   "metadata": {},
   "source": [
    "Note: since we only involved *age_imp_cat* in this baby RNN model, all patients in project J are poredicted to not have preterm with a very small p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef683dbf",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f44d22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6867469879518072"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_accuracy = metrics.accuracy_score(actual_labels, predicted_labels, normalize=False) / float(actual_labels.size)\n",
    "my_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d93ac",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16864992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51 17]\n",
      " [ 9  6]]\n"
     ]
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(actual_labels, predicted_labels)\n",
    "print(confusion)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985af7b8",
   "metadata": {},
   "source": [
    "**Specificity**: When the actual value is negative, how often is the prediction correct?\n",
    " - Something we want to maximize\n",
    " - How \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n",
    " - TN / all negative\n",
    "     - all negative = TN + FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84b2fb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f91fb83",
   "metadata": {},
   "source": [
    "**False Positive Rate**: When the actual value is negative, how often is the prediction incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c67fa763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "false_positive_rate = FP / float(TN + FP)\n",
    "\n",
    "print(false_positive_rate)\n",
    "print(1 - specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c327e65",
   "metadata": {},
   "source": [
    "**Precision**: When a positive value is predicted, how often is the prediction correct?\n",
    "- How \"precise\" is the classifier when predicting positive instances (preterm/early_preterm)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb0ec331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2608695652173913\n"
     ]
    }
   ],
   "source": [
    "precision = TP / float(TP + FP)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41bf70",
   "metadata": {},
   "source": [
    "### Receiver Operating Characteristic (ROC) Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd26fb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.01470588 0.01470588 0.04411765 0.04411765 0.07352941\n",
      " 0.10294118 0.17647059 0.17647059 0.22058824 0.25       0.25\n",
      " 0.30882353 0.30882353 0.35294118 0.41176471 0.41176471 0.47058824\n",
      " 0.52941176 0.89705882 0.89705882 0.91176471 0.91176471 0.95588235\n",
      " 0.95588235 0.98529412 0.98529412 1.        ]\n",
      "[0.         0.         0.06666667 0.06666667 0.13333333 0.13333333\n",
      " 0.13333333 0.13333333 0.26666667 0.26666667 0.26666667 0.4\n",
      " 0.4        0.53333333 0.66666667 0.66666667 0.73333333 0.73333333\n",
      " 0.73333333 0.73333333 0.8        0.8        0.86666667 0.86666667\n",
      " 0.93333333 0.93333333 1.         1.        ]\n",
      "[1.6327131  0.63271314 0.6241187  0.5766541  0.57469594 0.56564003\n",
      " 0.52551186 0.5231533  0.51652396 0.50263083 0.50179017 0.5002923\n",
      " 0.4520153  0.45173955 0.45090213 0.45068198 0.4506468  0.45053864\n",
      " 0.4505074  0.4247431  0.39874333 0.39856687 0.39165807 0.38578972\n",
      " 0.38532034 0.3853089  0.38530448 0.3852313 ]\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(actual_labels, pred_prob)\n",
    "print(fpr)\n",
    "print(tpr)\n",
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01f539fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEXCAYAAACzhgONAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArSElEQVR4nO3deZwcVbn/8c83IZBASNgiSwAJGgJB2WRXMIAgKIpcUEBF0XtFXFBAvXDFy/UnXpcrVwUUMSLggsJFQBEQBHEIEtkJIQECAQKERcIiWUkyyfP745xhmqanpmYyvczM9/169au7qk5VPX2mp586dapPKSIwMzPrypBmB2BmZq3NicLMzAo5UZiZWSEnCjMzK+REYWZmhZwozMyskBOF9WuSRkm6QtJ8SSFpiwbs8xhJ7V1Nl9zGhZJu6PvomifX/0cbuL85kr5WMb2apPMlvZBjmTQQ67kZnCiaKH+IIz9WSJor6ZeSxtYou6Gks/M/xzJJ8yT9TtIONcquJul4SbdLWiDpZUn3SDpV0roNeXON8xlgD+DtwMbAk02I4RLgdX+zRpB0g6QLm7HvFrAL8IOK6cOADwPvI30WpgJfBD7Y+NAGFieK5ruZ9KHenPQh3xG4tLKApM2AO4E9SV+MbwbeCywHbpV0YEXZYcDVwH8D/wfsC2wPnArsDny8vm/ntSStXuddjAdmRsR9EfFsRKzozUZWJc6IWBIR/+jt+tY7ETEvIhZVzBoPPBURU/NnYVlEvBwRL63KfhrwGW59EeFHkx7AhcANVfOOBwIYVTHvSuDZynkVy67Jy0bk6S8BK4E9utjnugXxrAacBjwCLAWeAs6uWB7AR6vWuQG4sGJ6DvBN4BzgBeAO4CLgzzX29yfg4orp/YFbgCV53xcA6xfEOyfH1PFoy/PXBn4KzANeISXZAyrW2yKX/0iuv0XAGV3sQ8DpwHPAQuBi4ESgvaLMMVXT6wK/Bp7I72VW/ruo+m8PnJTf62LgMmCDqv0fCUzL72MO8H1grYptRNVjUl62YV4+D1iQ63Xviu0Oy9uam//Wz1T+Lbqoi5HAD0mttqU5nq929fkgHc1Py/X2bK67jcvGAGwLXAf8M/+NHgCOrvr7fy2/bquqhzkF/2Nd1mnFtn6e/+7PAPOa/V3R7EfTAxjMj+oPMbAJcBPQXvFlsC6wouMfosY29sr/GO/P09Oq/zF6EM8vSF+IRwNvIrVATqxYXjZRzAe+DmwFTATend/D2IpyG+b3eVCe3pf0ZXk86chwF+CvwBQqvmCr9j2GdNpnCrARsF6ef2mO493ANsCZwDJg67x8i/xe5gIfBbYExnWxjy/mL6mP5/fz7/mLqyhRbAScDOwEjMv7WAh8oupvP590EPBWYBLwMHBl1XZfyn+PLYG9genAr/Ly0fm9X5L3uRGwOjACuJ+UeHYmtUBPJX0Zb5PXPSm//0mk1uwuwAkFnw2RvkAfBT5QEc+nuvp85Lp7V66DPUingm6qWF4YQ36vvyF9hrYEDgIOrvqsdSSK9YAzgMdyPYzp4n+ssE5zmTZScj037/utzf6uaPaj6QEM5kf+ELfnL5HFdB4NnVFRZtc879AutrFeXv6VPL0YOKsXsbw5b+fwgjJlE8VfqsoMIR01n1wx7yTS0drQPN0GfKdqvc3zPnfopg5vqPE+3lNV7m7g/Px6i1zmP0vUy1zgv6vm/Y6CRNHFds4Erq+KeyEwumLeATmu8RV1eVzVdvbOZdatVf8V8cwFVquafyPww4p4bqSLJFwj/v3yfnfuyeejavmOuczYMjEALwPHFGxvDhUHUKSDk9ndfD7K1Gkb8BAwpKf/RwP14T6K5rsN2IGUEE4HbgX+s2K5ulk/qqZVY14ZO+XnP/di3Wq3V05ExErS6aejK2YfDVwUnX0KuwAnSFrY8SAdFUNqYZQ1MT9PqZo/hXQqo8s4q0kaReqknlq16G/drDdE0imSpkl6Pr+X44A3VhW9PyJerpi+JT9vI2lMLv/9qjr5Uy7z5oIQdiEdVf+zat296KzLC0gtmdmSzpV0WDfn4t8GvBQRdxa990r5qqPrJD0paQGd9dZRD93FcAZwnqQ2SV+XtBOroId1elf+3BrpnLQ115KImJ1fz5C0FfBj4JN53sOkPoe3AFfUWP8t+XlWxXP1F2JfCV6fuIbVKLeoxrxfAF+R9DbSKZAdeG3H+hDgu8Cvaqz7bI8jfb1aCbRWnNXrUGO97nwJ+A9Sq+lu0mmME0kXIJTVcRD3RdIpuGpzu1n3AeDQGssWA0TENEnjSP1C+5CO7k+XtHtEzO9iu6XrQdLmpP6fXwHfAJ4HNiW1gFYvE0NEnC7pIuBA0qnJr0r6n4j42uv3WEpP6rS7z8ag4hZF6/k68HFJOwNExIukI57P5SPcal8F/gFcn6d/DewraY9aGy+4PPbu/HxAQWzPkfpROra1Bp1H8IUiYmbex8fyY1pETK8ociewbUTMrvFYWGYf2cz8vHfV/L0qlpWSj/afIl16W6l6utrewLUR8fOIuCcfCNRqFW1T9TfdMz8/EOkqqieBCV3UySu57DJgaNV27ySdf59fY72nK97fwoi4IiK+QOrL2AZ4Zxfv6S5gvY7PZQm7kPpKToiIWyJiFqlf6jW6iyEiHo2IcyLicNKFFp8puf/X6UGdWhW3KFpMRDwo6Srg26QjLYDPkU5/3Jh/YDSTdGrhRNKR2AciYkkueyapE/c6Sd8gnW+dR/oHPI50JHVmjf3Ozkdv50gaDvyd1P+xZ0R0lL8BOE7SFNJR8qnko8OSfgF8jXRZ7xlVy04D/izpB7ncAtKX6weBz1e8v0IR8YikS/P7+DTwOOnL5S2ky4976n9JR7kPkk4Lvp/UQVtkFnC0pH1IieZjwG6kTtTXhAv8Mv9N1yO1JK+OiIfz8lOBn0v6J/B7Ur1tQ7oA4NO5zGPAPpLeRDqn/zLpNN+JwNWSTiWdb9+QdFT+QET8XtJXgKdJFz8sBo4iXXDwUBfv6UbSpdyXSDqJ1AG8Calz/Lwa5R/O7+9L+XO1Pelv/KqiGCSNJLUwL8vvcR1Sy+J+Vk2ZOrVqze4kGcwPaly6l+e/nfRPtl/FvI1JXySPk44inyf9E+1YY/3VSM3rO0lN6PnAPaTWxzoF8Qwj9ZPMyfuYS+78zMs3Av6Yt/ck6Qu4Vmd2V1dobZC3uxzYsMbyvfL2FtB5OeQPqeqU7a4OgVF0Xh67lK4vj31Hib/REOBbub4XkTqyu7s8djTpNyzzSZcI/7ijXqvjBr5M6tRfQjq1OKZq/x8gJe3FeXvTgNMqlm9J6n9ZyGsvj10f+AkpUS3Lz1d0fF6AT5NaCfPzuncAh3RTF2sDZ+d4l5G+wE+pWF591dPn8udkCal/4sCqGLuMARhOuuLpMdJlrM+Rru7arKvPGiU6s0vWaRtwXrO/H1rpoVwxZmZmNbmPwszMCtUtUeTBuZ6TNKOL5ZJ0lqTZkqav6qVvZmZWH/VsUVxIOifZlYNInZXjgWNJ51PNzKzF1C1RRMQU4MWCIocAv4zkVmAdSRvXKx4zM+udZl4eO5bXDgk9N897prqgpGNJrQ6GDx/+ts0337whAba6lStXMmSIu5nAdVHJddFpMNbFvCXBouWvv0hp2bOzn4+IMb3ZZjMTRa2hKWpeghURk4HJABMmTIhZs2bVKjbotLW1MWnSpGaH0RJcF51cF50GY1185td3MevZBVz0qd1eM3+TddZ8vLfbbGaimAtsVjG9KenHN2ZmtgpWGyo2Hj2iz7bXzDbZlcDH8tVPuwMvR8TrTjuZmVlz1a1FIem3pHHmN5A0F/gv8gByEXEuacCw9wCzSb+Q/ES9YjEzs96rW6KIiKO6WR6kn/ibmVkLG1yXA5iZWY85UZiZWSEnCjMzK+REYWZmhZwozMyskBOFmZkVcqIwM7NCThRmZlaomWM9mZlZSdfNfJavXzmTld3cvvqlxcsZt/5afbpvJwozs35g+tx/8szLr3DkLpt1W3bPN2/Qp/t2ojAz6ydWGyK+c9h2Dd+v+yjMzKyQE4WZmRVyojAzs0JOFGZmVsiJwszMCjlRmJlZIScKMzMr5ERhZmaFnCjMzKyQE4WZmRVyojAzs0Ie68nMrEGWta/k6vueZsmylT1ed8ZT8+sQUTlOFGZmDXLbYy9w4iX39nr9seuM6MNoynOiMDNrkOUrUkvigmN2YeImo3q8/qjhw/o6pFKcKMzMGmy9tVZnw1HDmx1Gae7MNjOzQk4UZmZWyInCzMwKOVGYmVmhws5sSZsCRwJ7AZsAS4AZwNXAnyKi5xcDm5lZv9JlopB0ATAWuAr4LvAcMBzYCjgQOFXSKRExpRGBmplZcxS1KP43ImbUmD8DuFzS6sDm9QnLzMxaRZd9FB1JQtLBkl5XLiKWRcTsegZnZmbNV6Yz+0jgYUn/I2mbegdkZmatpdtEEREfBXYEHgEukPR3ScdKWru7dSUdKGmWpNmSTqmxfLSkP0q6V9JMSZ/o1bswM7O6KXV5bETMBy4DLgY2Bg4F7pZ0fFfrSBoK/Bg4CJgIHCVpYlWxzwH3R8T2wCTgf3Pfh5mZtYhux3qS9H7gE8CbgF8Bu0bEc5LWBB4Azu5i1V2B2RHxaN7OxcAhwP0VZQJYW5KAkcCLQHsv34uZWcuYt2ApR0z+Owte6fxKW7p8BQBSs6LqnTKDAh4O/KD6MtiIWCzpkwXrjQWerJieC+xWVeZHwJXA08DawBG1fpsh6VjgWIAxY8bQ1tZWIuyBb+HCha6LzHXRyXXRqZl18cg/V/DovFd46wZDWX94Z2YYMWwY/3joHtpm959sUSZRPFOdJCR9NyJOjoi/FKxXqxaiavrdwDRgX1KL5XpJN+dTXZ0rRUwGJgNMmDAhJk2aVCLsga+trQ3XReK66OS66NTMuhj9xEtw61ROet9O7DPhDU2Joa+U6aPYv8a8g0qsNxfYrGJ6U1LLodIngMsjmQ08BmxdYttmZtYgXSYKSZ+RdB+wtaTpFY/HgOkltn0HMF7SuNxBfSTpNFOlJ4D98v42BCYAj/bmjZiZWX0UnXr6DfAn4NtA5aWtCyLixe42HBHtkj4PXAcMBc6PiJmSjsvLzwVOBy7MCUnAyRHxfO/eipmZ1UNRooiImCPpc9ULJK1XMllcA1xTNe/citdPAwf0IF4zM2uw7loUBwN3kTqhKzunA9iyjnGZmVmL6DJRRMTB+Xlc48IxM7NW0+1VT5L+IOmo/AM7MzMbZMpcHvt90o2LHpB0qaTDJQ2vc1xmZtYiuv3BXUTcBNyUx27aF/gUcD4wqs6xmZlZCyjzy2wkjQDeBxwB7AT8op5BmZlZ6ygzKOAlpDGariWNBtvme2WbmQ0eZVoUFwAfjogV9Q7GrC889vwibpk9eH+3+dATy5l76+PNDqMlNLMunnxpcVP2Ww9dJgpJ+0bEjcCawCGqGhc3Ii6vc2xmvfK96x7kmvuebXYYzXV/rdvdD1JNrIshgjEj12ja/vtKUYvincCNpL6JagE4UVhLWtYebLXhSH79b9Wj2g8OU6dOZc8992x2GC2h2XWxxmpDGT1iWNP231eKfnD3X/nlNyLiscplkvwjPGtpqw0ZwhvWHpxXca+zxuB979VcF32jzO8oLqsx73d9HYiZmbWmoj6KrYFtgdGS/qVi0SjAKdrMbJAo6qOYQBoUcB1e20+xgPSjOzMzGwSK+ij+APxB0h4R8fcGxmRmZi2k6NTTv0fE/wAflnRU9fKI+EJdIzMzs5ZQdOrpgfx8ZyMCMTOz1lR06umP+fnVcZ0kDQFGRsT8BsRmZmYtoMz9KH4jaZSktYD7gVmSvlL/0MzMrBWU+R3FxNyC+ADp/tebA0fXMygzM2sdZRLFMEnDSIniDxGxnDSEh5mZDQJlEsVPgTnAWsAUSW8E3EdhZjZIlLnD3VnAWRWzHpe0T/1CssHm5ofn8eVL72XFyt43VJctW8bqf7segPlL2hm/4ci+Cs9s0Ctz46I1gMOALarKf6NOMdkgsnJl8K1rHmSIxLu23bDX23n66afZZJONXp3ea/wGfRGemVHuxkV/AF4G7gKW1jccG2yunfksDzwznx8csT2H7rhpr7fT1vYCkya9tQ8jM7MOZRLFphFxYN0jsUFnxcrgB9c/xJvGrMX7tx/b7HDMrAtlOrOnSvKhmvW5q+97hoefW8gJ79qKoUPU/Qpm1hRlWhTvAI6R9Bjp1JOAiIjt6hqZDWjtK1bywxseYsKGa/Pet27c7HDMrECZRHFQ3aOwQefKe5/m0XmLOPejOzHErQmzltbtqaeIeBzYDNg3v15cZj2zrixfsZIz//IwEzcexQETN+p+BTNrqjJjPf0XcDLwH3nWMODX9QzKBrYr7n6Kx19YzEn7b+XWhFk/UKZlcCjwfmARQEQ8Daxdz6Bs4FrWvpKzbnyY7TYdzX7bvKHZ4ZhZCWUSxbKICPL4TnkUWbNeufSuJ5n70hJO3H8rJLcmzPqDMoni/yT9FFhH0qeAG4Cf1TcsG4iWtq/gRzfOZqfN12HSVmOaHY6ZlVSmM/sM4HfAZcBWwGkRcXaZjUs6UNIsSbMlndJFmUmSpkmaKemmngRv/cvFtz/JMy+/wkn7T3BrwqwfKXN5LBFxvaS7gb2BF8usI2ko8GNgf2AucIekKyPi/ooy6wDnAAdGxBOSfNJ6gHpl+Qp+/NfZ7DpuPd7+5vWbHY6Z9UCXLQpJV0l6S369MTAD+CTwK0knlNj2rsDsiHg0IpYBFwOHVJX5MHB5RDwBEBHP9fwtWH/w61sf57kFSznJfRNm/U5Ri2JcRMzIrz8BXB8RH5O0NnAL8MNutj0WeLJiei6wW1WZrUg3RmojXUl1ZkT8snpDko4FjgUYM2YMbW1t3ex6cFi4cGG/qIul7cFZUxYzcf0hvPLEfbQ90ff76C910Qiui06ui75RlCiWV7zej9yBHRELJK0sse1ah43VNxxYDXhb3v4I4O+Sbo2Ih16zUsRkYDLAhAkTYtKkSSV2P/C1tbXRH+ripzc9wvxlD/KND+7GzlusV5d99Je6aATXRSfXRd8oShRPSjqe1BLYCbgWQNII0o/uujOX9IvuDpsCT9co83xELAIWSZoCbA88hA0IC5e2c+5Nj7D3VmPqliTMrL6Krnr6V2Bb4BjgiIj4Z56/O3BBiW3fAYyXNE7S6sCRwJVVZf4A7CVpNUlrkk5NPVA+fGt1v5g6h5cWL+ek/bdqdihm1ktdtihyx/JxNeb/FfhrdxuOiHZJnweuA4YC50fETEnH5eXnRsQDkq4FpgMrgfMq+kWsn5v/ynImT3mU/bZ+Aztstk6zwzGzXuoyUUiaDJxV64s7/zr7CGBpRFzU1TYi4hrgmqp551ZNfw/4Xg/jtn7g/L89xstLlnOiWxNm/VpRH8U5wGn5pkUzgHnAcGA8MAo4H+gySdjg9vLi5fz85sd497Yb8paxo5sdjpmtgqJTT9OAD0kaCewMbAwsAR6IiFmNCc/6q5/d/CgLlra7NWE2AHT7y+yIWAi01T8UGyheXLSMC255jPdutzFbbzSq2eGY2SryDYisz/10yiMsXr6CE/Yb3+xQzKwPOFFYn5q3YCm/nPo4h2y/CeM39G1LzAaC0onC96GwMn560yMsbV/BF9yaMBswytwKdU9J95N/CCdpe0nn1D0y63f+Mf8VfnXr4/zLTpuy5ZiRzQ7HzPpImRbFD4B3Ay8ARMS9pOHGzV7jJ22PsGJl8IV93ZowG0hKnXqKiCerZq2oQyzWj720aBm/ue0JPrjzpmy+/prNDsfM+lCZGxc9KWlPIPKYTV/A4zFZlRcWLWPZipXsvqVvSmQ20JRpURwHfI50f4m5wA7AZ+sYk/VjvimR2cBTpkUxISI+UjlD0ttJNy8yM7MBrkyL4uyS88zMbAAqGj12D2BPYIykkyoWjSING25mZoNA0amn1YGRuUzlT2znA4fXMygzM2sdRaPH3gTcJOnCiHi8gTGZmVkLKdOZvVjS90i3RR3eMTMi9q1bVGZm1jLKdGZfBDwIjAP+HzCHdD9sMzMbBMokivUj4ufA8oi4KSI+Cexe57jMzKxFlDn1tDw/PyPpvcDTwKb1C8nMzFpJmUTxTUmjgS+Rfj8xCjihnkGZmVnrKHMr1Kvyy5eBfeDVX2abmdkgUPSDu6HAh0hjPF0bETMkHQx8FRgB7NiYEM3MrJmKWhQ/BzYDbgfOkvQ4sAdwSkT8vgGxmZlZCyhKFDsD20XESknDgeeBN0fEs40JzczMWkHR5bHLImIlQES8AjzkJGFmNvgUtSi2ljQ9vxbwpjwtICJiu7pHZ2ZmTVeUKLZpWBRmZtayigYF9ECAZmZWaggPMzMbxJwozMysUKlEIWmEpAn1DsbMzFpPt4lC0vuAacC1eXoHSVfWOS4zM2sRZVoUXwd2Bf4JEBHTgC3qFZCZmbWWMomiPSJernskZmbWksokihmSPgwMlTRe0tnA1DIbl3SgpFmSZks6paDcLpJWSDq8ZNxmZtYgZRLF8aT7ZS8FfkMabvyE7lbKo8/+GDgImAgcJWliF+W+C1xXOmozM2uYMjcumhARpwKn9nDbuwKzI+JRAEkXA4cA91eVOx64DNilh9u3VfSl/7uXvzz4jz7Z1oqVAaTxXcxsYCmTKL4vaWPgUuDiiJhZcttjgScrpucCu1UWkDQWOBTYl4JEIelY4FiAMWPG0NbWVjKEgW3hwoWrVBd/e3AxawBv2WBon8QzbMgw9I9ZtLU91Cfb64lVrYuBxHXRyXXRN8rc4W4fSRuRbmI0WdIo4JKI+GY3q9Y6uIyq6R8CJ0fECqnrY9GImAxMBpgwYUJMmjSpu7AHhba2NlalLta8s423jh3NWUf1/3tQrWpdDCSui06ui75R6gd3EfFsRJwFHEf6TcVpJVabS7rxUYdNgaeryuwMXCxpDnA4cI6kD5SJyczMGqPbFoWkbYAjSF/kLwAXA18qse07gPGSxgFPAUcCH64sEBHjKvZzIXCV755nZtZayvRRXAD8FjggIqpbBF2KiHZJnyddzTQUOD8iZko6Li8/tzcBm5lZY5Xpo9i9txuPiGuAa6rm1UwQEXFMb/djZmb102WikPR/EfEhSffx2k5o3+HOzGwQKWpRfDE/H9yIQMzMrDV1edVTRDyTX342Ih6vfACfbUx4ZmbWbGUuj92/xryD+joQMzNrTUV9FJ8htRy2lDS9YtHawC31DszMzFpDUR/Fb4A/Ad8GKkd+XRARL9Y1KjMzaxlFiSIiYo6kz1UvkLSek4WZ2eDQXYviYOAu0uWxlYMxBbBlHeMyM7MW0WWiiIiD8/O4rsqYmdnA1+1VT5LeLmmt/Pqjkr4vafP6h2ZmZq2gzOWxPwEWS9oe+HfgceBXdY3KzMxaRplE0R4RQbo73ZkRcSbpElkzMxsEyoweu0DSfwBHA3vle1wPq29YZmbWKsq0KI4AlgKfjIhnSbc4/V5dozIzs5bRbaLIyeEiYLSkg4FXIuKXdY/MzMxaQpmrnj4E3A58kHTf7NskHV7vwMzMrDWU6aM4FdglIp4DkDQGuAH4XT0DMzOz1lCmj2JIR5LIXii5npmZDQBlWhTXSrqOdN9sSJ3b1xSUNzOzAaTMPbO/IulfgHeQxnuaHBFX1D0yMzNrCUX3oxgPnAG8CbgP+HJEPNWowMzMrDUU9TWcD1wFHEYaQfbshkRkZmYtpejU09oR8bP8epakuxsRkCV/ffA5vnTpvbSvWNllmfb2dlZru67X+1iwtJ3tNh3d6/XNbHAoShTDJe1I530oRlROR4QTRx098Ox8Xly0jKN3fyNDh6hmmaeemsvYsZuu0n4O2WGTVVrfzAa+okTxDPD9iulnK6YD2LdeQVmnU9+7DcOHDa25rK1tHpMmbdvgiMxssCm6cdE+jQzEzMxak384Z2ZmhZwozMyskBOFmZkVKjN6rPK9sk/L05tL2rX+oZmZWSso06I4B9gDOCpPLwB+XLeIzMyspZQZFHC3iNhJ0j0AEfGSpNXrHJeZmbWIMi2K5fk+2QGv3o+i658Lm5nZgFImUZwFXAG8QdJ/A38DvlXXqMzMrGWUuWf2RcC/A98m/Vr7AxFxaZmNSzpQ0ixJsyWdUmP5RyRNz4+pkrbv6RswM7P66raPQtLmwGLgj5XzIuKJbtYbSur03h+YC9wh6cqIuL+i2GPAO3O/x0HAZGC3nr8NMzOrlzKd2VeT+icEDAfGAbOA7gYZ2hWYHRGPAki6GDgEeDVRRMTUivK3Aqs2wp2ZmfW5Mne4e2vltKSdgE+X2PZY4MmK6bkUtxb+FfhTrQWSjgWOBRgzZgxtbW0ldt+/PfroMgCmTJnC6kNrjx67cOHCQVEXZbguOrkuOrku+kaZFsVrRMTdknYpUbTWt1vULCjtQ0oU7+hin5NJp6WYMGFCTJo0qVyw/dj9zIaHZrH33nsXjB7bxmCoizJcF51cF51cF32jTB/FSRWTQ4CdgHkltj0X2KxielPg6Rrb3w44DzgoIl4osV0zM2ugMpfHrl3xWIPUZ3FIifXuAMZLGpd/oHckcGVlgdxRfjlwdEQ81JPAzcysMQpbFPnKpZER8ZWebjgi2iV9HrgOGAqcHxEzJR2Xl58LnAasD5wjCaA9Inbu6b7MzKx+ukwUklbLX/Y79XbjEXENcE3VvHMrXv8b8G+93b6ZmdVfUYvidlJ/xDRJVwKXAos6FkbE5XWOzczMWkCZq57WA14g3SO74/cUQepbMDOzAa4oUbwhX/E0g84E0aHmZa5mZjbwFCWKocBIevB7CDMzG3iKEsUzEfGNhkViZmYtqeh3FLXHjTAzs0GlKFHs17AozMysZXWZKCLixUYGYmZmranHgwL2V1+/ciaX3TW32WGUtrQ93W1WPgFoZk02aBLFtCf/yagRw3j3ths1O5TS3rj+mqyxWu2RY83MGmXQJAqAN71hJKe9b2KzwzAz61fKjB5rZmaDmBOFmZkVcqIwM7NCThRmZlbIicLMzAo5UZiZWSEnCjMzK+REYWZmhZwozMyskBOFmZkVcqIwM7NC/X6spznPL+KGB/7Rbbl5C5YyasSwBkRkZjaw9PtE8ZO2R7jkzidLlX3nhDF1jsbMbODp94mifWWwyejhXHfi3t2WHblGv3+7ZmYNNyC+OSWx9nCfVjIzqwd3ZpuZWSEnCjMzK+REYWZmhZwozMyskBOFmZkVcqIwM7NCThRmZlbIicLMzAo5UZiZWaG6JgpJB0qaJWm2pFNqLJeks/Ly6ZJ2qmc8ZmbWc3VLFJKGAj8GDgImAkdJmlhV7CBgfH4cC/ykXvGYmVnv1HOsp12B2RHxKICki4FDgPsryhwC/DIiArhV0jqSNo6IZ7ra6OPzV7Ltade+Ov1K+0o2WWd4Xd6AmZnVN1GMBSrH/54L7FaizFjgNYlC0rGkFgfA0vtPP2hG5fJHAZ3cBxH3PxsAzzc7iBbhuujkuujkuug0obcr1jNRqMa86EUZImIyMBlA0p0RsfOqh9f/uS46uS46uS46uS46Sbqzt+vWszN7LrBZxfSmwNO9KGNmZk1Uz0RxBzBe0jhJqwNHAldWlbkS+Fi++ml34OWi/gkzM2u8up16ioh2SZ8HrgOGAudHxExJx+Xl5wLXAO8BZgOLgU+U2PTkOoXcH7kuOrkuOrkuOrkuOvW6LpQuODIzM6vNv8w2M7NCThRmZlaoZROFh//oVKIuPpLrYLqkqZK2b0acjdBdXVSU20XSCkmHNzK+RipTF5ImSZomaaakmxodY6OU+B8ZLemPku7NdVGmP7TfkXS+pOckzehiee++NyOi5R6kzu9HgC2B1YF7gYlVZd4D/In0W4zdgduaHXcT62JPYN38+qDBXBcV5W4kXSxxeLPjbuLnYh3SSAib5+k3NDvuJtbFV4Hv5tdjgBeB1Zsdex3qYm9gJ2BGF8t79b3Zqi2KV4f/iIhlQMfwH5VeHf4jIm4F1pG0caMDbYBu6yIipkbES3nyVtLvUQaiMp8LgOOBy4DnGhlcg5Wpiw8Dl0fEEwARMVDro0xdBLC2JAEjSYmivbFh1l9ETCG9t6706nuzVRNFV0N79LTMQNDT9/mvpCOGgajbupA0FjgUOLeBcTVDmc/FVsC6ktok3SXpYw2LrrHK1MWPgG1IP+i9D/hiRKxsTHgtpVffm/UcwmNV9NnwHwNA6fcpaR9SonhHXSNqnjJ18UPg5IhYkQ4eB6wydbEa8DZgP2AE8HdJt0bEQ/UOrsHK1MW7gWnAvsCbgOsl3RwR8+scW6vp1fdmqyYKD//RqdT7lLQdcB5wUES80KDYGq1MXewMXJyTxAbAeyS1R8TvGxJh45T9H3k+IhYBiyRNAbYHBlqiKFMXnwC+E+lE/WxJjwFbA7c3JsSW0avvzVY99eThPzp1WxeSNgcuB44egEeLlbqti4gYFxFbRMQWwO+Azw7AJAHl/kf+AOwlaTVJa5JGb36gwXE2Qpm6eILUskLShqSRVB9taJStoVffmy3Zooj6Df/R75Ssi9OA9YFz8pF0ewzAETNL1sWgUKYuIuIBSdcC04GVwHkRUfOyyf6s5OfidOBCSfeRTr+cHBEDbvhxSb8FJgEbSJoL/BcwDFbte9NDeJiZWaFWPfVkZmYtwonCzMwKOVGYmVkhJwozMyvkRGFmZoWcKAaxPLrqtIrHFgVlF/bB/i6U9Fje192S9ujFNs6TNDG//mrVsqmrGmPeTke9zMgjjq7TTfkdJL2nF/vZWNJV+fX6kv4qaaGkH/Uy7lPzyKjTc/y79WY7Bdu/pqMuJH1B0gOSLpL0/q5Gr61Yd2p+3kLSh0vs62BJ/69PArdV5stjBzFJCyNiZF+XLdjGhcBVEfE7SQcAZ0TEdquwvVWOqbvtSvoF8FBE/HdB+WOAnSPi8z3cz/eAv0XEHyStBewIvAV4Sy+2tQfwfWBSRCyVtAFpdNS6jFYg6UHSKACP9XC9ScCXI+LgbsoJuBt4e0Qs7m2c1jfcorBXSRop6S/5aP8+Sa8bmTUfBU+pOOLeK88/QNLf87qXSuruC3wK8Oa87kl5WzMknZDnrSXpaqX7B8yQdESe3yZpZ0nfAUbkOC7Kyxbm50sqj/BzS+YwSUMlfU/SHfmo+9MlquXv5EHTJO2qdL+Pe/LzBKVfAn8DOCLHckSO/fy8n3tq1WN2GHAtQEQsioi/Aa+UiKmWjUnDdSzN23u+I0lImiPpu5Juz4+Oeh8j6bIc5x2S3p7nj5R0Qf4MTJd0WMV2NpB0LmlI7yslnSjpmI5WkKQNJV2R/273Stozz+9okX6H9GvxaXndmyXt0PEmJN0iabs81EYbUJhQrEEaPV66H63zAFaQBkqbBlxB+qX+qLxsA9KvNztanQvz85eAU/ProcDauewUYK08/2TgtBr7u5B8fwjgg8BtpEHr7gPWIg3/PJN0ZH0Y8LOKdUfn5zbS0furMVWU6YjxUOAX+fXqpNEyRwDHAl/L89cA7gTG1YhzYcX7uxQ4ME+PAlbLr98FXJZfHwP8qGL9bwEfza/XIY2ttFbVPsYBd9XY92u21YO/5cj8d3wIOAd4Z8WyORV/s4+RWnUAvwHekV9vDjyQX38X+GHF+utWbGeDGq9fjRm4BDihov46/m4ddTqpY/95+uMd+yKNdntnxbKPAGc3+//Ej2jNITysYZZExA4dE5KGAd+StDdpyIexwIbAsxXr3AGcn8v+PiKmSXonMBG4JZ0xYHXSkXgt35P0NWAeaaTb/YArIg1ch6TLgb1IR9pnSPou6Yvl5h68rz8BZ0laAzgQmBIRS/Lpru3Uede70cB4oPr0yQhJ04AtgLuA6yvK/0LSeNKIm8O62P8BwPslfTlPDyd/EVeU2TjXQZ+IiIWS3kaqu32ASySdEhEX5iK/rXj+QX79LmCiOkfZHSVp7Tz/yIptd9zrpIx9ScmIiFgBvNxN+UuB/5T0FeCTpIOJDs8Bm/Rg31YnThRW6SOku3+9LSKWS5pD+pJ7VURMyYnkvcCv8nn2l4DrI+KoEvv4SkT8rmNC0rtqFYqIh/IX33uAb0v6c0R8o8ybiIhXJLWRhpY+gs4vSQHHR8R13WxiSUTsIGk0cBXwOeAs0nhBf42IQ5U6/tu6WF/AYRExq2gfVNVtd5Q6p3+aJ0+LiOoBEVfkmNqUxjT6OJ1fvJWdkR2vhwB7RMSSqv2IBg3ZHxGLJV1PuqHOh0ij/3YYTqonazL3UVil0cBzOUnsA7yxuoCkN+YyPwN+Trrt4q3A2yvOfa8paauS+5wCfCCvsxbptNHNkjYBFkfEr4Ez8n6qLc8tm1ouJg14thdpsDjy82c61pG0Vd5nTRHxMvAF4Mt5ndHAU3nxMRVFF5BOwXW4Djg+f+Eiaccam3+I1GIpLSJui4gd8qN6BOEJuaXTYQfg8YrpIyqeO1p7fwZe7TSv6Cuonr9uD8L8C/CZvN5QSaOqllfXFaTh8c8C7oiIyruzbQUMuEEM+yMnCqt0EbCzpDtJrYsHa5SZBEyTdA+pH+HMiJhH+uL8raTppMSxdZkdRsTdpKPe20l9FudFxD3AW4Hb8ymgU4Fv1lh9MjC9ozO7yp9J9w++IdLtMSF9Id0P3K108/mf0k2rOsdyL+lUzP+QWje3kM6/d/gr6RTONKVO99NJp6Wm5/2cXmO7i4BHOpIrpM5i0pVLx0iaq3wZcEkjSafF7s9/g4nA1yuWryHpNuCLwIl53hdIf+/pku4Hjsvzv0m6M94MSfeSTmWV9UVgn9yiuQvYtmr5dKA9d3SfCBARdwHzgQuqyu4DXN2DfVud+PJYsyaRdCjpNN/X6ryfOaQLAFpyWO3cemwDto58e1Kle0b8JiL2a2ZslrhFYdYkEXEF6eqhQUvpPt63ka7KqryH9eakK+ysBbhFYWZmhdyiMDOzQk4UZmZWyInCzMwKOVGYmVkhJwozMyv0/wEaKXxwsLa3yAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for diabetes classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "153c5f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.4\n",
      "Specificity: 0.75\n",
      "None\n",
      "Sensitivity: 0.7333333333333333\n",
      "Specificity: 0.1029411764705882\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define a function that accepts a threshold and prints sensitivity and specificity\n",
    "def evaluate_threshold(threshold):\n",
    "    print('Sensitivity:', tpr[thresholds > threshold][-1])\n",
    "    print('Specificity:', 1 - fpr[thresholds > threshold][-1])\n",
    "\n",
    "print(evaluate_threshold(0.5))\n",
    "print(evaluate_threshold(0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f53a58",
   "metadata": {},
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f172e42",
   "metadata": {},
   "source": [
    "AUC is the **percentage** of the ROC plot that is **underneath the curve**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d03020d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5764705882352941\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "print(metrics.roc_auc_score(actual_labels, pred_prob))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
