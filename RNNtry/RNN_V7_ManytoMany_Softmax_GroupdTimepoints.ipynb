{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c842d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f06511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directory\n",
    "# alpha_dir     = '/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/training_data_2022-05-27/alpha_diversity/alpha_diversity.csv'\n",
    "# cst_dir       = '/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/training_data_2022-05-27/community_state_types/cst_valencia.csv'\n",
    "meta_dir      = '/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/metadata_imputed1.csv'\n",
    "# krdlong_dir   = '/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/training_data_2022-05-27/pairwise_distance/krd_distance_long.csv'\n",
    "# krdwide_dir   = '/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/training_data_2022-05-27/pairwise_distance/krd_distance_wide.csv'\n",
    "phylotype_dir = '/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/training_data_2022-05-27/phylotypes/phylotype_relabd.1e0.csv'\n",
    "# taxonomy_dir  = '/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/training_data_2022-05-27/taxonomy/taxonomy_relabd.family.csv'\n",
    "\n",
    "meta_data = pd.DataFrame(pd.read_csv(meta_dir, delimiter=','))\n",
    "phylotype_data = pd.DataFrame(pd.read_csv(phylotype_dir, delimiter=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9c8e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3578, 16)\n",
      "(3578, 1845)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specimen</th>\n",
       "      <th>pt__00001</th>\n",
       "      <th>pt__00002</th>\n",
       "      <th>pt__00003</th>\n",
       "      <th>pt__00004</th>\n",
       "      <th>pt__00005</th>\n",
       "      <th>pt__00006</th>\n",
       "      <th>pt__00007</th>\n",
       "      <th>pt__00008</th>\n",
       "      <th>pt__00009</th>\n",
       "      <th>...</th>\n",
       "      <th>pt__01835</th>\n",
       "      <th>pt__01836</th>\n",
       "      <th>pt__01837</th>\n",
       "      <th>pt__01838</th>\n",
       "      <th>pt__01839</th>\n",
       "      <th>pt__01840</th>\n",
       "      <th>pt__01841</th>\n",
       "      <th>pt__01842</th>\n",
       "      <th>pt__01843</th>\n",
       "      <th>pt__01844</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00001-05</td>\n",
       "      <td>0.797900</td>\n",
       "      <td>0.023097</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.008924</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00002-01</td>\n",
       "      <td>0.805641</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.006131</td>\n",
       "      <td>0.042305</td>\n",
       "      <td>0.010423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00003-02</td>\n",
       "      <td>0.963299</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00004-08</td>\n",
       "      <td>0.927544</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00004-12</td>\n",
       "      <td>0.806593</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>J00111-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>J00112-01</td>\n",
       "      <td>0.999644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3575</th>\n",
       "      <td>J00113-01</td>\n",
       "      <td>0.483433</td>\n",
       "      <td>0.038340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576</th>\n",
       "      <td>J00115-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>J00116-01</td>\n",
       "      <td>0.832747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3578 rows × 1845 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       specimen  pt__00001  pt__00002  pt__00003  pt__00004  pt__00005  \\\n",
       "0     A00001-05   0.797900   0.023097   0.002100   0.008924   0.007349   \n",
       "1     A00002-01   0.805641   0.000613   0.006131   0.042305   0.010423   \n",
       "2     A00003-02   0.963299   0.000648   0.001079   0.000000   0.011658   \n",
       "3     A00004-08   0.927544   0.000514   0.001028   0.009250   0.004625   \n",
       "4     A00004-12   0.806593   0.000366   0.000549   0.014286   0.000549   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "3573  J00111-01   1.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3574  J00112-01   0.999644   0.000000   0.000000   0.000000   0.000000   \n",
       "3575  J00113-01   0.483433   0.038340   0.000000   0.000000   0.000631   \n",
       "3576  J00115-01   1.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3577  J00116-01   0.832747   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "      pt__00006  pt__00007  pt__00008  pt__00009  ...  pt__01835  pt__01836  \\\n",
       "0      0.000000   0.106037        0.0   0.009449  ...        0.0        0.0   \n",
       "1      0.000000   0.000613        0.0   0.001839  ...        0.0        0.0   \n",
       "2      0.000000   0.000216        0.0   0.001079  ...        0.0        0.0   \n",
       "3      0.000000   0.027235        0.0   0.000000  ...        0.0        0.0   \n",
       "4      0.000366   0.142857        0.0   0.000916  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "3573   0.000000   0.000000        0.0   0.000000  ...        0.0        0.0   \n",
       "3574   0.000000   0.000000        0.0   0.000000  ...        0.0        0.0   \n",
       "3575   0.000000   0.000000        0.0   0.000000  ...        0.0        0.0   \n",
       "3576   0.000000   0.000000        0.0   0.000000  ...        0.0        0.0   \n",
       "3577   0.000000   0.000000        0.0   0.000000  ...        0.0        0.0   \n",
       "\n",
       "      pt__01837  pt__01838  pt__01839  pt__01840  pt__01841  pt__01842  \\\n",
       "0           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "3573        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3574        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3575        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3576        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3577        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "      pt__01843  pt__01844  \n",
       "0           0.0        0.0  \n",
       "1           0.0        0.0  \n",
       "2           0.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  \n",
       "...         ...        ...  \n",
       "3573        0.0        0.0  \n",
       "3574        0.0        0.0  \n",
       "3575        0.0        0.0  \n",
       "3576        0.0        0.0  \n",
       "3577        0.0        0.0  \n",
       "\n",
       "[3578 rows x 1845 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(meta_data.shape)\n",
    "print(phylotype_data.shape)\n",
    "phylotype_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccbbe970",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = meta_data[['participant_id', 'project', 'delivery_wk', 'collect_wk', 'age_imp', 'race_imp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b780179",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,meta_data.shape[1]):\n",
    "    if meta_data.iloc[:,i].dtypes == object:\n",
    "        meta_data.iloc[:,i] = meta_data.iloc[:,i].astype('category').cat.codes + 1\n",
    "        meta_data.iloc[:,i] = meta_data.iloc[:,i].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a19ce76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_14906/3498266638.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meta_data['collect_period'][(meta_data['collect_wk']>=9)  & (meta_data['collect_wk']<=16)] = 2\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_14906/3498266638.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meta_data['collect_period'][(meta_data['collect_wk']>=17) & (meta_data['collect_wk']<=24)] = 3\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_14906/3498266638.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meta_data['collect_period'][(meta_data['collect_wk']>=25) & (meta_data['collect_wk']<=32)] = 4\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_14906/3498266638.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meta_data['collect_period'][(meta_data['collect_wk']>32)]                                  = 5\n"
     ]
    }
   ],
   "source": [
    "meta_data['collect_period'] = 1\n",
    "meta_data['collect_period'][(meta_data['collect_wk']>=9)  & (meta_data['collect_wk']<=16)] = 2\n",
    "meta_data['collect_period'][(meta_data['collect_wk']>=17) & (meta_data['collect_wk']<=24)] = 3\n",
    "meta_data['collect_period'][(meta_data['collect_wk']>=25) & (meta_data['collect_wk']<=32)] = 4\n",
    "meta_data['collect_period'][(meta_data['collect_wk']>32)]                                  = 5\n",
    "\n",
    "meta_data['classlabel'] = 1*(meta_data['delivery_wk'] < 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a967c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the specimen_id column\n",
    "phylotype_data = phylotype_data.drop('specimen', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab2533c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = pd.concat([meta_data, phylotype_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf40846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out all samples with collection <= 32\n",
    "mydata = mydata[mydata['collect_wk']<=32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f774697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>project</th>\n",
       "      <th>delivery_wk</th>\n",
       "      <th>collect_wk</th>\n",
       "      <th>age_imp</th>\n",
       "      <th>race_imp</th>\n",
       "      <th>collect_period</th>\n",
       "      <th>classlabel</th>\n",
       "      <th>pt__00001</th>\n",
       "      <th>pt__00002</th>\n",
       "      <th>...</th>\n",
       "      <th>pt__01835</th>\n",
       "      <th>pt__01836</th>\n",
       "      <th>pt__01837</th>\n",
       "      <th>pt__01838</th>\n",
       "      <th>pt__01839</th>\n",
       "      <th>pt__01840</th>\n",
       "      <th>pt__01841</th>\n",
       "      <th>pt__01842</th>\n",
       "      <th>pt__01843</th>\n",
       "      <th>pt__01844</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.963299</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.927544</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.806593</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686465</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.755714</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>J00111</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>J00112</td>\n",
       "      <td>10.0</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3575</th>\n",
       "      <td>J00113</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.483433</td>\n",
       "      <td>0.038340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576</th>\n",
       "      <td>J00115</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>J00116</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.832747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3189 rows × 1852 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant_id  project  delivery_wk  collect_wk  age_imp  race_imp  \\\n",
       "2            A00003      1.0           40          30       32       2.0   \n",
       "3            A00004      1.0           40          27       25       5.0   \n",
       "4            A00004      1.0           40          29       25       5.0   \n",
       "5            A00004      1.0           40          30       25       5.0   \n",
       "10           A00005      1.0           41          26       31       5.0   \n",
       "...             ...      ...          ...         ...      ...       ...   \n",
       "3573         J00111     10.0           40          17       27       5.0   \n",
       "3574         J00112     10.0           39          19       27       5.0   \n",
       "3575         J00113     10.0           41          16       32       5.0   \n",
       "3576         J00115     10.0           42          18       35       5.0   \n",
       "3577         J00116     10.0           40          17       26       5.0   \n",
       "\n",
       "      collect_period  classlabel  pt__00001  pt__00002  ...  pt__01835  \\\n",
       "2                  4           0   0.963299   0.000648  ...        0.0   \n",
       "3                  4           0   0.927544   0.000514  ...        0.0   \n",
       "4                  4           0   0.806593   0.000366  ...        0.0   \n",
       "5                  4           0   0.686465   0.000853  ...        0.0   \n",
       "10                 4           0   0.755714   0.003333  ...        0.0   \n",
       "...              ...         ...        ...        ...  ...        ...   \n",
       "3573               3           0   1.000000   0.000000  ...        0.0   \n",
       "3574               3           0   0.999644   0.000000  ...        0.0   \n",
       "3575               2           0   0.483433   0.038340  ...        0.0   \n",
       "3576               3           0   1.000000   0.000000  ...        0.0   \n",
       "3577               3           0   0.832747   0.000000  ...        0.0   \n",
       "\n",
       "      pt__01836  pt__01837  pt__01838  pt__01839  pt__01840  pt__01841  \\\n",
       "2           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "5           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "10          0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "3573        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3574        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3575        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3576        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3577        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "      pt__01842  pt__01843  pt__01844  \n",
       "2           0.0        0.0        0.0  \n",
       "3           0.0        0.0        0.0  \n",
       "4           0.0        0.0        0.0  \n",
       "5           0.0        0.0        0.0  \n",
       "10          0.0        0.0        0.0  \n",
       "...         ...        ...        ...  \n",
       "3573        0.0        0.0        0.0  \n",
       "3574        0.0        0.0        0.0  \n",
       "3575        0.0        0.0        0.0  \n",
       "3576        0.0        0.0        0.0  \n",
       "3577        0.0        0.0        0.0  \n",
       "\n",
       "[3189 rows x 1852 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2222c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.groupby(['participant_id', 'collect_period'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7262ec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testproject = 10\n",
    "mytraindata = mydata[mydata['project']!=testproject]\n",
    "mytestdata  = mydata[mydata['project']==testproject]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52f4ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytrain_input = mytraindata.drop('classlabel', axis=1)\n",
    "mytrain_output = mytraindata[['participant_id', 'collect_period', 'classlabel']]\n",
    "\n",
    "mytest_input = mytestdata.drop('classlabel', axis=1)\n",
    "mytest_output = mytestdata[['participant_id', 'collect_period', 'classlabel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a42c7523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Reshaper_Input(data, seq_length):\n",
    "    num_samples = len(np.unique(data['participant_id']))\n",
    "    myvary = list(data.columns.values)[5:data.shape[1]]\n",
    "    num_covariates = len(myvary)\n",
    "    \n",
    "    myinput = np.zeros((num_samples, seq_length, num_covariates), dtype=np.float32)\n",
    "    \n",
    "    for i in range(num_covariates):\n",
    "        data_wide = data.pivot_table(index=['participant_id'], columns='collect_period', values=myvary[i])\n",
    "        data_wide = data_wide.sort_index(axis=1)\n",
    "        data_wide = data_wide.fillna(0)\n",
    "        tmpindex = data_wide._get_numeric_data().columns.values - 1\n",
    "        tmpindex = tmpindex.tolist()\n",
    "        # time varying variables need to impute all and no records are denoted as 0\n",
    "        for j in range(num_samples):\n",
    "                myinput[j,tmpindex,i] = data_wide.iloc[[j]]\n",
    "    return myinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d21fcf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: longer time running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "454548c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1131, 4, 1846)\n"
     ]
    }
   ],
   "source": [
    "mytrain_input = Data_Reshaper_Input(mytrain_input, seq_length=4)\n",
    "print(mytrain_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaeb017f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 4, 1846)\n"
     ]
    }
   ],
   "source": [
    "mytest_input = Data_Reshaper_Input(mytest_input, seq_length=4)\n",
    "print(mytest_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde891e1",
   "metadata": {},
   "source": [
    "**Data_Reshaper_Output_ManytoMany**\n",
    "- reshape patients class labels from long to wide form\n",
    "- output array formulation, two columns, \n",
    " - (0,0) indicating missing values;\n",
    " - (1,0) indicating preterm classes;\n",
    " - (0,1) indicating not preterm classes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0e26768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Reshaper_Output_ManytoMany(data, seq_length, num_covariates):\n",
    "    \n",
    "    num_samples = len(np.unique(data['participant_id']))\n",
    "\n",
    "    data_wide = data.pivot_table(index=['participant_id'], columns='collect_period', values=\"classlabel\")\n",
    "    data_wide = data_wide.sort_index(axis=1)\n",
    "\n",
    "    myoutput = np.zeros((num_samples, seq_length, num_covariates), dtype=np.float32)\n",
    "\n",
    "    myoutput[:,data_wide.columns.values-1,0] = data_wide\n",
    "    myoutput[:,data_wide.columns.values-1,1] = 1 - data_wide\n",
    "    myoutput[np.isnan(myoutput)] = 0\n",
    "    \n",
    "    return myoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7493e810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1131, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "mytrain_output = Data_Reshaper_Output_ManytoMany(mytraindata, seq_length=seq_length, num_covariates=2)\n",
    "print(mytrain_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ceec3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>collect_period</th>\n",
       "      <th>project</th>\n",
       "      <th>delivery_wk</th>\n",
       "      <th>collect_wk</th>\n",
       "      <th>age_imp</th>\n",
       "      <th>race_imp</th>\n",
       "      <th>classlabel</th>\n",
       "      <th>pt__00001</th>\n",
       "      <th>pt__00002</th>\n",
       "      <th>...</th>\n",
       "      <th>pt__01835</th>\n",
       "      <th>pt__01836</th>\n",
       "      <th>pt__01837</th>\n",
       "      <th>pt__01838</th>\n",
       "      <th>pt__01839</th>\n",
       "      <th>pt__01840</th>\n",
       "      <th>pt__01841</th>\n",
       "      <th>pt__01842</th>\n",
       "      <th>pt__01843</th>\n",
       "      <th>pt__01844</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00003</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.963299</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00004</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.806867</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00005</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.834559</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00006</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.762941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00008</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.156391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A00008</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.308081</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A00009</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563436</td>\n",
       "      <td>0.009292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A00010</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.441841</td>\n",
       "      <td>0.089073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A00011</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165963</td>\n",
       "      <td>0.052743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A00011</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506906</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A00012</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060966</td>\n",
       "      <td>0.035286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A00012</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>19.833333</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055246</td>\n",
       "      <td>0.030627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A00012</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28.833333</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.227140</td>\n",
       "      <td>0.015976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A00013</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A00013</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>27.333333</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755749</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A00014</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888732</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A00014</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A00014</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470951</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A00015</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.986939</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A00016</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.892781</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A00017</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.854881</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A00017</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.910515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A00017</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A00018</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.267483</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A00018</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309963</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 1852 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  collect_period  project  delivery_wk  collect_wk  age_imp  \\\n",
       "0          A00003               4      1.0         40.0   30.000000     32.0   \n",
       "1          A00004               4      1.0         40.0   28.666667     25.0   \n",
       "2          A00005               4      1.0         41.0   27.500000     31.0   \n",
       "3          A00006               4      1.0         41.0   31.000000     28.0   \n",
       "4          A00008               3      1.0         35.0   17.000000     38.0   \n",
       "5          A00008               4      1.0         35.0   29.750000     38.0   \n",
       "6          A00009               4      1.0         37.0   29.333333     32.0   \n",
       "7          A00010               4      1.0         38.0   29.250000     30.0   \n",
       "8          A00011               3      1.0         38.0   24.000000     30.0   \n",
       "9          A00011               4      1.0         38.0   28.666667     30.0   \n",
       "10         A00012               2      1.0         36.0   13.750000     36.0   \n",
       "11         A00012               3      1.0         36.0   19.833333     36.0   \n",
       "12         A00012               4      1.0         36.0   28.833333     36.0   \n",
       "13         A00013               3      1.0         38.0   23.000000     31.0   \n",
       "14         A00013               4      1.0         38.0   27.333333     31.0   \n",
       "15         A00014               2      1.0         41.0   14.333333     32.0   \n",
       "16         A00014               3      1.0         41.0   23.000000     32.0   \n",
       "17         A00014               4      1.0         41.0   29.250000     32.0   \n",
       "18         A00015               4      1.0         40.0   30.000000     28.0   \n",
       "19         A00016               2      1.0         40.0   14.000000     28.0   \n",
       "20         A00017               2      1.0         38.0   12.000000     31.0   \n",
       "21         A00017               3      1.0         38.0   24.000000     31.0   \n",
       "22         A00017               4      1.0         38.0   26.000000     31.0   \n",
       "23         A00018               2      1.0         39.0   12.333333     29.0   \n",
       "24         A00018               3      1.0         39.0   21.500000     29.0   \n",
       "\n",
       "    race_imp  classlabel  pt__00001  pt__00002  ...  pt__01835  pt__01836  \\\n",
       "0        2.0         0.0   0.963299   0.000648  ...        0.0        0.0   \n",
       "1        5.0         0.0   0.806867   0.000578  ...        0.0        0.0   \n",
       "2        5.0         0.0   0.834559   0.002062  ...        0.0        0.0   \n",
       "3        5.0         0.0   0.762941   0.000000  ...        0.0        0.0   \n",
       "4        5.0         1.0   0.156391   0.000000  ...        0.0        0.0   \n",
       "5        5.0         1.0   0.308081   0.000461  ...        0.0        0.0   \n",
       "6        2.0         0.0   0.563436   0.009292  ...        0.0        0.0   \n",
       "7        5.0         0.0   0.441841   0.089073  ...        0.0        0.0   \n",
       "8        4.0         0.0   0.165963   0.052743  ...        0.0        0.0   \n",
       "9        4.0         0.0   0.506906   0.003719  ...        0.0        0.0   \n",
       "10       1.0         1.0   0.060966   0.035286  ...        0.0        0.0   \n",
       "11       1.0         1.0   0.055246   0.030627  ...        0.0        0.0   \n",
       "12       1.0         1.0   0.227140   0.015976  ...        0.0        0.0   \n",
       "13       3.0         0.0   0.181818   0.000000  ...        0.0        0.0   \n",
       "14       3.0         0.0   0.755749   0.000087  ...        0.0        0.0   \n",
       "15       5.0         0.0   0.888732   0.000387  ...        0.0        0.0   \n",
       "16       5.0         0.0   0.983239   0.000000  ...        0.0        0.0   \n",
       "17       5.0         0.0   0.470951   0.001358  ...        0.0        0.0   \n",
       "18       5.0         0.0   0.986939   0.000102  ...        0.0        0.0   \n",
       "19       5.0         0.0   0.892781   0.000390  ...        0.0        0.0   \n",
       "20       5.0         0.0   0.854881   0.000176  ...        0.0        0.0   \n",
       "21       5.0         0.0   0.910515   0.000000  ...        0.0        0.0   \n",
       "22       5.0         0.0   0.927938   0.000000  ...        0.0        0.0   \n",
       "23       5.0         0.0   0.267483   0.003694  ...        0.0        0.0   \n",
       "24       5.0         0.0   0.309963   0.001876  ...        0.0        0.0   \n",
       "\n",
       "    pt__01837  pt__01838  pt__01839  pt__01840  pt__01841  pt__01842  \\\n",
       "0         0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1         0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2         0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3         0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4         0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "5         0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "6         0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "7         0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "8         0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9         0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "10        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "11        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "12        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "13        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "14        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "15        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "16        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "17        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "18        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "19        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "20        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "21        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "22        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "23        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "24        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "    pt__01843  pt__01844  \n",
       "0         0.0        0.0  \n",
       "1         0.0        0.0  \n",
       "2         0.0        0.0  \n",
       "3         0.0        0.0  \n",
       "4         0.0        0.0  \n",
       "5         0.0        0.0  \n",
       "6         0.0        0.0  \n",
       "7         0.0        0.0  \n",
       "8         0.0        0.0  \n",
       "9         0.0        0.0  \n",
       "10        0.0        0.0  \n",
       "11        0.0        0.0  \n",
       "12        0.0        0.0  \n",
       "13        0.0        0.0  \n",
       "14        0.0        0.0  \n",
       "15        0.0        0.0  \n",
       "16        0.0        0.0  \n",
       "17        0.0        0.0  \n",
       "18        0.0        0.0  \n",
       "19        0.0        0.0  \n",
       "20        0.0        0.0  \n",
       "21        0.0        0.0  \n",
       "22        0.0        0.0  \n",
       "23        0.0        0.0  \n",
       "24        0.0        0.0  \n",
       "\n",
       "[25 rows x 1852 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytraindata[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84cf8091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytrain_output[4,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f8552b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytrain_output[7,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dce4887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytrain_output[11,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72046686",
   "metadata": {},
   "source": [
    "### Defining RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4240fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model1, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9df77d",
   "metadata": {},
   "source": [
    "# RNN batch-training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c859bf6",
   "metadata": {},
   "source": [
    "### Model hyperparameters set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "703c6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "lr = 0.0001\n",
    "verbose = True\n",
    "\n",
    "# Setup the RNN and training settings\n",
    "hidden_dim = 30\n",
    "n_layers = 1\n",
    "max_epochs = 500\n",
    "\n",
    "model = Model1(input_size=mytrain_input.shape[2], output_size=mytrain_output.shape[2], hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "\n",
    "# # better to use when train binary classification (Many to One)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# better to use when many to many cases\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "321c9554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically determine the device that PyTorch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Track the value of the loss function and model accuracy across epochs\n",
    "history_train = {'loss': [], 'acc': []}\n",
    "\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9bc8fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to training mode. This will turn on layers that would\n",
    "# otherwise behave differently during evaluation, such as dropout\n",
    "model.train()\n",
    "\n",
    "# Store the number of sequences that were classified correctly\n",
    "num_correct = 0\n",
    "\n",
    "batch_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e35911d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset a batch of sequences and class labels\n",
    "tmpindex = list(range(batch_idx, min(batch_idx+batch_size, mytrain_input.shape[0])))\n",
    "mytrain_input_batch  = mytrain_input[tmpindex,:]\n",
    "mytrain_output_batch = mytrain_output[tmpindex,:]\n",
    "\n",
    "# convert them into tensors object for Pytorch and send them to the selected device\n",
    "mytrain_input_batch  = torch.from_numpy(mytrain_input_batch).float().to(device)\n",
    "mytrain_output_batch = torch.from_numpy(mytrain_output_batch).float().to(device)\n",
    "        \n",
    "# forward pass of RNN model\n",
    "output, hidden = model(mytrain_input_batch)\n",
    "output_prob = nn.functional.softmax(output, dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a98bd9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5486, 0.4514],\n",
       "        [0.5708, 0.4292],\n",
       "        [0.7927, 0.2073],\n",
       "        [0.8019, 0.1981]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii = 4\n",
    "output_prob[ii,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "29e9c58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytrain_output_batch[ii,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eda8c652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8019, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output_prob[ii,3,0])\n",
    "tmppred = 1*(output_prob[ii,3,0] > 0.5)\n",
    "tmppred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0b9b6798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmptrainoutput = max(mytrain_output_batch[ii,:,0])\n",
    "tmptrainoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "58431a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batch_Train(model, mytrain_input, mytrain_output, criterion, optimizer, device, batch_size):\n",
    "    # Set the model to training mode. This will turn on layers that would\n",
    "    # otherwise behave differently during evaluation, such as dropout\n",
    "    model.train()\n",
    "    \n",
    "    # Store the number of sequences that were classified correctly\n",
    "    num_correct = 0\n",
    "    \n",
    "    # Iterate over every batch of sequences\n",
    "    for batch_idx in range(0, mytrain_input.shape[0], batch_size):\n",
    "        \n",
    "        # subset a batch of sequences and class labels\n",
    "        tmpindex = list(range(batch_idx, min(batch_idx+batch_size, mytrain_input.shape[0])))\n",
    "        mytrain_input_batch  = mytrain_input[tmpindex,:]\n",
    "        mytrain_output_batch = mytrain_output[tmpindex,:]\n",
    "        \n",
    "        # convert them into tensors object for Pytorch and send them to the selected device\n",
    "        mytrain_input_batch  = torch.from_numpy(mytrain_input_batch).float().to(device)\n",
    "        mytrain_output_batch = torch.from_numpy(mytrain_output_batch).float().to(device)\n",
    "        \n",
    "        # forward pass of RNN model\n",
    "        output, hidden = model(mytrain_input_batch)\n",
    "        output_prob = nn.functional.softmax(output, dim=2)\n",
    "\n",
    "        # using softmax() to form class probabilities on last dim of tensor (2)\n",
    "        loss = criterion(output_prob, mytrain_output_batch)\n",
    "        \n",
    "        # Clear existing gradients from previous epoch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backpropagation and gradients calculation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updates the weights\n",
    "        optimizer.step()    \n",
    "        \n",
    "        # change to class probabilities\n",
    "        for ii in range(mytrain_input_batch.shape[0]):\n",
    "            # tmppred = 1*(output_prob[ii,3,0] > 0.5) + 1\n",
    "            tmppred = 1*(output_prob[ii,3,0] > 0.5)\n",
    "            tmptrainoutput = max(mytrain_output_batch[ii,:,0])\n",
    "            num_correct += 1*(tmptrainoutput == tmppred)\n",
    "        \n",
    "    return num_correct, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4c0ba675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/500] loss: 0.3226, acc: 33.07%\n",
      "[Epoch 2/500] loss: 0.3159, acc: 33.07%\n",
      "[Epoch 3/500] loss: 0.3093, acc: 33.07%\n",
      "[Epoch 4/500] loss: 0.3028, acc: 33.07%\n",
      "[Epoch 5/500] loss: 0.2965, acc: 33.07%\n",
      "[Epoch 6/500] loss: 0.2904, acc: 33.07%\n",
      "[Epoch 7/500] loss: 0.2845, acc: 33.16%\n",
      "[Epoch 8/500] loss: 0.2788, acc: 37.22%\n",
      "[Epoch 9/500] loss: 0.2734, acc: 47.75%\n",
      "[Epoch 10/500] loss: 0.2684, acc: 54.73%\n",
      "[Epoch 11/500] loss: 0.2638, acc: 57.38%\n",
      "[Epoch 12/500] loss: 0.2595, acc: 58.97%\n",
      "[Epoch 13/500] loss: 0.2556, acc: 58.97%\n",
      "[Epoch 14/500] loss: 0.2521, acc: 59.06%\n",
      "[Epoch 15/500] loss: 0.2490, acc: 56.94%\n",
      "[Epoch 16/500] loss: 0.2463, acc: 59.86%\n",
      "[Epoch 17/500] loss: 0.2438, acc: 64.01%\n",
      "[Epoch 18/500] loss: 0.2417, acc: 64.46%\n",
      "[Epoch 19/500] loss: 0.2398, acc: 62.95%\n",
      "[Epoch 20/500] loss: 0.2381, acc: 62.07%\n",
      "[Epoch 21/500] loss: 0.2366, acc: 61.54%\n",
      "[Epoch 22/500] loss: 0.2353, acc: 60.04%\n",
      "[Epoch 23/500] loss: 0.2342, acc: 59.86%\n",
      "[Epoch 24/500] loss: 0.2332, acc: 59.50%\n",
      "[Epoch 25/500] loss: 0.2323, acc: 59.15%\n",
      "[Epoch 26/500] loss: 0.2315, acc: 58.36%\n",
      "[Epoch 27/500] loss: 0.2308, acc: 57.91%\n",
      "[Epoch 28/500] loss: 0.2302, acc: 57.65%\n",
      "[Epoch 29/500] loss: 0.2297, acc: 57.21%\n",
      "[Epoch 30/500] loss: 0.2292, acc: 56.50%\n",
      "[Epoch 31/500] loss: 0.2288, acc: 55.88%\n",
      "[Epoch 32/500] loss: 0.2284, acc: 55.53%\n",
      "[Epoch 33/500] loss: 0.2280, acc: 55.00%\n",
      "[Epoch 34/500] loss: 0.2277, acc: 55.17%\n",
      "[Epoch 35/500] loss: 0.2274, acc: 55.44%\n",
      "[Epoch 36/500] loss: 0.2272, acc: 55.08%\n",
      "[Epoch 37/500] loss: 0.2270, acc: 55.00%\n",
      "[Epoch 38/500] loss: 0.2268, acc: 54.47%\n",
      "[Epoch 39/500] loss: 0.2266, acc: 54.20%\n",
      "[Epoch 40/500] loss: 0.2264, acc: 53.93%\n",
      "[Epoch 41/500] loss: 0.2263, acc: 53.76%\n",
      "[Epoch 42/500] loss: 0.2261, acc: 53.76%\n",
      "[Epoch 43/500] loss: 0.2260, acc: 53.67%\n",
      "[Epoch 44/500] loss: 0.2259, acc: 53.58%\n",
      "[Epoch 45/500] loss: 0.2258, acc: 53.58%\n",
      "[Epoch 46/500] loss: 0.2257, acc: 53.58%\n",
      "[Epoch 47/500] loss: 0.2256, acc: 53.49%\n",
      "[Epoch 48/500] loss: 0.2256, acc: 53.40%\n",
      "[Epoch 49/500] loss: 0.2255, acc: 53.49%\n",
      "[Epoch 50/500] loss: 0.2254, acc: 53.40%\n",
      "[Epoch 51/500] loss: 0.2254, acc: 53.32%\n",
      "[Epoch 52/500] loss: 0.2253, acc: 53.32%\n",
      "[Epoch 53/500] loss: 0.2253, acc: 53.40%\n",
      "[Epoch 54/500] loss: 0.2252, acc: 53.40%\n",
      "[Epoch 55/500] loss: 0.2252, acc: 53.40%\n",
      "[Epoch 56/500] loss: 0.2251, acc: 53.40%\n",
      "[Epoch 57/500] loss: 0.2251, acc: 53.40%\n",
      "[Epoch 58/500] loss: 0.2251, acc: 53.40%\n",
      "[Epoch 59/500] loss: 0.2250, acc: 53.40%\n",
      "[Epoch 60/500] loss: 0.2250, acc: 53.49%\n",
      "[Epoch 61/500] loss: 0.2250, acc: 53.40%\n",
      "[Epoch 62/500] loss: 0.2250, acc: 53.40%\n",
      "[Epoch 63/500] loss: 0.2249, acc: 53.32%\n",
      "[Epoch 64/500] loss: 0.2249, acc: 53.40%\n",
      "[Epoch 65/500] loss: 0.2249, acc: 53.32%\n",
      "[Epoch 66/500] loss: 0.2249, acc: 53.23%\n",
      "[Epoch 67/500] loss: 0.2249, acc: 53.40%\n",
      "[Epoch 68/500] loss: 0.2248, acc: 53.58%\n",
      "[Epoch 69/500] loss: 0.2248, acc: 53.58%\n",
      "[Epoch 70/500] loss: 0.2248, acc: 53.58%\n",
      "[Epoch 71/500] loss: 0.2248, acc: 53.58%\n",
      "[Epoch 72/500] loss: 0.2248, acc: 53.49%\n",
      "[Epoch 73/500] loss: 0.2248, acc: 53.49%\n",
      "[Epoch 74/500] loss: 0.2247, acc: 53.67%\n",
      "[Epoch 75/500] loss: 0.2247, acc: 53.67%\n",
      "[Epoch 76/500] loss: 0.2247, acc: 53.67%\n",
      "[Epoch 77/500] loss: 0.2247, acc: 53.67%\n",
      "[Epoch 78/500] loss: 0.2247, acc: 53.67%\n",
      "[Epoch 79/500] loss: 0.2247, acc: 53.76%\n",
      "[Epoch 80/500] loss: 0.2247, acc: 53.76%\n",
      "[Epoch 81/500] loss: 0.2246, acc: 53.76%\n",
      "[Epoch 82/500] loss: 0.2246, acc: 53.76%\n",
      "[Epoch 83/500] loss: 0.2246, acc: 53.76%\n",
      "[Epoch 84/500] loss: 0.2246, acc: 53.85%\n",
      "[Epoch 85/500] loss: 0.2246, acc: 53.85%\n",
      "[Epoch 86/500] loss: 0.2246, acc: 53.93%\n",
      "[Epoch 87/500] loss: 0.2246, acc: 53.93%\n",
      "[Epoch 88/500] loss: 0.2246, acc: 53.93%\n",
      "[Epoch 89/500] loss: 0.2246, acc: 53.93%\n",
      "[Epoch 90/500] loss: 0.2245, acc: 54.02%\n",
      "[Epoch 91/500] loss: 0.2245, acc: 54.11%\n",
      "[Epoch 92/500] loss: 0.2245, acc: 54.20%\n",
      "[Epoch 93/500] loss: 0.2245, acc: 54.20%\n",
      "[Epoch 94/500] loss: 0.2245, acc: 54.20%\n",
      "[Epoch 95/500] loss: 0.2245, acc: 54.29%\n",
      "[Epoch 96/500] loss: 0.2245, acc: 54.29%\n",
      "[Epoch 97/500] loss: 0.2245, acc: 54.29%\n",
      "[Epoch 98/500] loss: 0.2245, acc: 54.29%\n",
      "[Epoch 99/500] loss: 0.2245, acc: 54.38%\n",
      "[Epoch 100/500] loss: 0.2245, acc: 54.38%\n",
      "[Epoch 101/500] loss: 0.2244, acc: 54.29%\n",
      "[Epoch 102/500] loss: 0.2244, acc: 54.20%\n",
      "[Epoch 103/500] loss: 0.2244, acc: 54.20%\n",
      "[Epoch 104/500] loss: 0.2244, acc: 54.20%\n",
      "[Epoch 105/500] loss: 0.2244, acc: 54.11%\n",
      "[Epoch 106/500] loss: 0.2244, acc: 54.11%\n",
      "[Epoch 107/500] loss: 0.2244, acc: 54.20%\n",
      "[Epoch 108/500] loss: 0.2244, acc: 54.20%\n",
      "[Epoch 109/500] loss: 0.2244, acc: 54.20%\n",
      "[Epoch 110/500] loss: 0.2244, acc: 54.11%\n",
      "[Epoch 111/500] loss: 0.2244, acc: 54.11%\n",
      "[Epoch 112/500] loss: 0.2244, acc: 54.11%\n",
      "[Epoch 113/500] loss: 0.2243, acc: 54.11%\n",
      "[Epoch 114/500] loss: 0.2243, acc: 54.11%\n",
      "[Epoch 115/500] loss: 0.2243, acc: 54.11%\n",
      "[Epoch 116/500] loss: 0.2243, acc: 54.11%\n",
      "[Epoch 117/500] loss: 0.2243, acc: 54.02%\n",
      "[Epoch 118/500] loss: 0.2243, acc: 54.02%\n",
      "[Epoch 119/500] loss: 0.2243, acc: 54.02%\n",
      "[Epoch 120/500] loss: 0.2243, acc: 54.11%\n",
      "[Epoch 121/500] loss: 0.2243, acc: 54.11%\n",
      "[Epoch 122/500] loss: 0.2243, acc: 54.11%\n",
      "[Epoch 123/500] loss: 0.2243, acc: 54.20%\n",
      "[Epoch 124/500] loss: 0.2243, acc: 54.38%\n",
      "[Epoch 125/500] loss: 0.2243, acc: 54.29%\n",
      "[Epoch 126/500] loss: 0.2243, acc: 54.29%\n",
      "[Epoch 127/500] loss: 0.2242, acc: 54.20%\n",
      "[Epoch 128/500] loss: 0.2242, acc: 54.11%\n",
      "[Epoch 129/500] loss: 0.2242, acc: 54.11%\n",
      "[Epoch 130/500] loss: 0.2242, acc: 54.11%\n",
      "[Epoch 131/500] loss: 0.2242, acc: 54.11%\n",
      "[Epoch 132/500] loss: 0.2242, acc: 54.11%\n",
      "[Epoch 133/500] loss: 0.2242, acc: 54.20%\n",
      "[Epoch 134/500] loss: 0.2242, acc: 54.20%\n",
      "[Epoch 135/500] loss: 0.2242, acc: 54.29%\n",
      "[Epoch 136/500] loss: 0.2242, acc: 54.29%\n",
      "[Epoch 137/500] loss: 0.2242, acc: 54.29%\n",
      "[Epoch 138/500] loss: 0.2242, acc: 54.29%\n",
      "[Epoch 139/500] loss: 0.2242, acc: 54.02%\n",
      "[Epoch 140/500] loss: 0.2242, acc: 53.85%\n",
      "[Epoch 141/500] loss: 0.2242, acc: 53.76%\n",
      "[Epoch 142/500] loss: 0.2241, acc: 53.85%\n",
      "[Epoch 143/500] loss: 0.2241, acc: 53.85%\n",
      "[Epoch 144/500] loss: 0.2241, acc: 53.76%\n",
      "[Epoch 145/500] loss: 0.2241, acc: 53.49%\n",
      "[Epoch 146/500] loss: 0.2241, acc: 53.49%\n",
      "[Epoch 147/500] loss: 0.2241, acc: 53.58%\n",
      "[Epoch 148/500] loss: 0.2241, acc: 53.40%\n",
      "[Epoch 149/500] loss: 0.2241, acc: 53.40%\n",
      "[Epoch 150/500] loss: 0.2241, acc: 53.32%\n",
      "[Epoch 151/500] loss: 0.2241, acc: 53.23%\n",
      "[Epoch 152/500] loss: 0.2241, acc: 53.32%\n",
      "[Epoch 153/500] loss: 0.2241, acc: 53.14%\n",
      "[Epoch 154/500] loss: 0.2241, acc: 53.05%\n",
      "[Epoch 155/500] loss: 0.2241, acc: 53.05%\n",
      "[Epoch 156/500] loss: 0.2241, acc: 53.14%\n",
      "[Epoch 157/500] loss: 0.2240, acc: 53.05%\n",
      "[Epoch 158/500] loss: 0.2240, acc: 53.05%\n",
      "[Epoch 159/500] loss: 0.2240, acc: 52.79%\n",
      "[Epoch 160/500] loss: 0.2240, acc: 52.87%\n",
      "[Epoch 161/500] loss: 0.2240, acc: 52.87%\n",
      "[Epoch 162/500] loss: 0.2240, acc: 52.70%\n",
      "[Epoch 163/500] loss: 0.2240, acc: 52.61%\n",
      "[Epoch 164/500] loss: 0.2240, acc: 52.25%\n",
      "[Epoch 165/500] loss: 0.2240, acc: 51.90%\n",
      "[Epoch 166/500] loss: 0.2240, acc: 51.99%\n",
      "[Epoch 167/500] loss: 0.2240, acc: 52.08%\n",
      "[Epoch 168/500] loss: 0.2240, acc: 51.99%\n",
      "[Epoch 169/500] loss: 0.2240, acc: 52.08%\n",
      "[Epoch 170/500] loss: 0.2240, acc: 51.90%\n",
      "[Epoch 171/500] loss: 0.2239, acc: 51.90%\n",
      "[Epoch 172/500] loss: 0.2239, acc: 51.99%\n",
      "[Epoch 173/500] loss: 0.2239, acc: 51.64%\n",
      "[Epoch 174/500] loss: 0.2239, acc: 51.55%\n",
      "[Epoch 175/500] loss: 0.2239, acc: 51.37%\n",
      "[Epoch 176/500] loss: 0.2239, acc: 51.28%\n",
      "[Epoch 177/500] loss: 0.2239, acc: 50.84%\n",
      "[Epoch 178/500] loss: 0.2239, acc: 51.02%\n",
      "[Epoch 179/500] loss: 0.2239, acc: 51.02%\n",
      "[Epoch 180/500] loss: 0.2239, acc: 50.49%\n",
      "[Epoch 181/500] loss: 0.2239, acc: 50.40%\n",
      "[Epoch 182/500] loss: 0.2239, acc: 50.40%\n",
      "[Epoch 183/500] loss: 0.2238, acc: 50.40%\n",
      "[Epoch 184/500] loss: 0.2238, acc: 49.69%\n",
      "[Epoch 185/500] loss: 0.2238, acc: 49.43%\n",
      "[Epoch 186/500] loss: 0.2238, acc: 49.07%\n",
      "[Epoch 187/500] loss: 0.2238, acc: 49.07%\n",
      "[Epoch 188/500] loss: 0.2238, acc: 48.63%\n",
      "[Epoch 189/500] loss: 0.2238, acc: 48.54%\n",
      "[Epoch 190/500] loss: 0.2238, acc: 48.01%\n",
      "[Epoch 191/500] loss: 0.2238, acc: 48.01%\n",
      "[Epoch 192/500] loss: 0.2238, acc: 47.75%\n",
      "[Epoch 193/500] loss: 0.2238, acc: 47.66%\n",
      "[Epoch 194/500] loss: 0.2237, acc: 47.39%\n",
      "[Epoch 195/500] loss: 0.2237, acc: 47.48%\n",
      "[Epoch 196/500] loss: 0.2237, acc: 46.77%\n",
      "[Epoch 197/500] loss: 0.2237, acc: 46.24%\n",
      "[Epoch 198/500] loss: 0.2237, acc: 46.51%\n",
      "[Epoch 199/500] loss: 0.2237, acc: 45.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 200/500] loss: 0.2237, acc: 45.18%\n",
      "[Epoch 201/500] loss: 0.2237, acc: 44.92%\n",
      "[Epoch 202/500] loss: 0.2236, acc: 44.83%\n",
      "[Epoch 203/500] loss: 0.2236, acc: 44.74%\n",
      "[Epoch 204/500] loss: 0.2236, acc: 43.77%\n",
      "[Epoch 205/500] loss: 0.2236, acc: 43.41%\n",
      "[Epoch 206/500] loss: 0.2236, acc: 43.06%\n",
      "[Epoch 207/500] loss: 0.2236, acc: 42.09%\n",
      "[Epoch 208/500] loss: 0.2236, acc: 41.73%\n",
      "[Epoch 209/500] loss: 0.2236, acc: 41.20%\n",
      "[Epoch 210/500] loss: 0.2235, acc: 40.41%\n",
      "[Epoch 211/500] loss: 0.2235, acc: 39.61%\n",
      "[Epoch 212/500] loss: 0.2235, acc: 39.43%\n",
      "[Epoch 213/500] loss: 0.2235, acc: 39.26%\n",
      "[Epoch 214/500] loss: 0.2235, acc: 39.26%\n",
      "[Epoch 215/500] loss: 0.2235, acc: 39.17%\n",
      "[Epoch 216/500] loss: 0.2234, acc: 39.52%\n",
      "[Epoch 217/500] loss: 0.2234, acc: 40.05%\n",
      "[Epoch 218/500] loss: 0.2234, acc: 40.58%\n",
      "[Epoch 219/500] loss: 0.2234, acc: 41.20%\n",
      "[Epoch 220/500] loss: 0.2234, acc: 41.38%\n",
      "[Epoch 221/500] loss: 0.2234, acc: 41.38%\n",
      "[Epoch 222/500] loss: 0.2233, acc: 41.38%\n",
      "[Epoch 223/500] loss: 0.2233, acc: 41.38%\n",
      "[Epoch 224/500] loss: 0.2233, acc: 41.73%\n",
      "[Epoch 225/500] loss: 0.2233, acc: 42.00%\n",
      "[Epoch 226/500] loss: 0.2233, acc: 41.82%\n",
      "[Epoch 227/500] loss: 0.2232, acc: 41.91%\n",
      "[Epoch 228/500] loss: 0.2232, acc: 41.82%\n",
      "[Epoch 229/500] loss: 0.2232, acc: 41.82%\n",
      "[Epoch 230/500] loss: 0.2232, acc: 41.73%\n",
      "[Epoch 231/500] loss: 0.2232, acc: 42.09%\n",
      "[Epoch 232/500] loss: 0.2231, acc: 42.18%\n",
      "[Epoch 233/500] loss: 0.2231, acc: 42.35%\n",
      "[Epoch 234/500] loss: 0.2231, acc: 42.26%\n",
      "[Epoch 235/500] loss: 0.2231, acc: 42.26%\n",
      "[Epoch 236/500] loss: 0.2231, acc: 42.26%\n",
      "[Epoch 237/500] loss: 0.2230, acc: 42.35%\n",
      "[Epoch 238/500] loss: 0.2230, acc: 42.26%\n",
      "[Epoch 239/500] loss: 0.2230, acc: 42.18%\n",
      "[Epoch 240/500] loss: 0.2230, acc: 42.26%\n",
      "[Epoch 241/500] loss: 0.2229, acc: 42.26%\n",
      "[Epoch 242/500] loss: 0.2229, acc: 42.79%\n",
      "[Epoch 243/500] loss: 0.2229, acc: 42.79%\n",
      "[Epoch 244/500] loss: 0.2229, acc: 42.79%\n",
      "[Epoch 245/500] loss: 0.2228, acc: 42.71%\n",
      "[Epoch 246/500] loss: 0.2228, acc: 42.71%\n",
      "[Epoch 247/500] loss: 0.2228, acc: 42.79%\n",
      "[Epoch 248/500] loss: 0.2228, acc: 42.88%\n",
      "[Epoch 249/500] loss: 0.2227, acc: 42.97%\n",
      "[Epoch 250/500] loss: 0.2227, acc: 42.88%\n",
      "[Epoch 251/500] loss: 0.2227, acc: 42.79%\n",
      "[Epoch 252/500] loss: 0.2227, acc: 43.15%\n",
      "[Epoch 253/500] loss: 0.2226, acc: 43.06%\n",
      "[Epoch 254/500] loss: 0.2226, acc: 43.32%\n",
      "[Epoch 255/500] loss: 0.2226, acc: 43.41%\n",
      "[Epoch 256/500] loss: 0.2225, acc: 43.32%\n",
      "[Epoch 257/500] loss: 0.2225, acc: 43.59%\n",
      "[Epoch 258/500] loss: 0.2225, acc: 43.59%\n",
      "[Epoch 259/500] loss: 0.2225, acc: 43.68%\n",
      "[Epoch 260/500] loss: 0.2224, acc: 43.94%\n",
      "[Epoch 261/500] loss: 0.2224, acc: 44.12%\n",
      "[Epoch 262/500] loss: 0.2224, acc: 44.21%\n",
      "[Epoch 263/500] loss: 0.2224, acc: 44.12%\n",
      "[Epoch 264/500] loss: 0.2223, acc: 44.21%\n",
      "[Epoch 265/500] loss: 0.2223, acc: 44.30%\n",
      "[Epoch 266/500] loss: 0.2223, acc: 44.39%\n",
      "[Epoch 267/500] loss: 0.2222, acc: 44.39%\n",
      "[Epoch 268/500] loss: 0.2222, acc: 44.56%\n",
      "[Epoch 269/500] loss: 0.2222, acc: 44.56%\n",
      "[Epoch 270/500] loss: 0.2222, acc: 44.74%\n",
      "[Epoch 271/500] loss: 0.2221, acc: 44.74%\n",
      "[Epoch 272/500] loss: 0.2221, acc: 44.83%\n",
      "[Epoch 273/500] loss: 0.2221, acc: 45.00%\n",
      "[Epoch 274/500] loss: 0.2221, acc: 45.09%\n",
      "[Epoch 275/500] loss: 0.2220, acc: 45.09%\n",
      "[Epoch 276/500] loss: 0.2220, acc: 45.00%\n",
      "[Epoch 277/500] loss: 0.2220, acc: 45.00%\n",
      "[Epoch 278/500] loss: 0.2219, acc: 45.09%\n",
      "[Epoch 279/500] loss: 0.2219, acc: 45.18%\n",
      "[Epoch 280/500] loss: 0.2219, acc: 45.09%\n",
      "[Epoch 281/500] loss: 0.2219, acc: 45.27%\n",
      "[Epoch 282/500] loss: 0.2218, acc: 45.27%\n",
      "[Epoch 283/500] loss: 0.2218, acc: 45.09%\n",
      "[Epoch 284/500] loss: 0.2218, acc: 45.27%\n",
      "[Epoch 285/500] loss: 0.2218, acc: 45.27%\n",
      "[Epoch 286/500] loss: 0.2217, acc: 45.36%\n",
      "[Epoch 287/500] loss: 0.2217, acc: 45.45%\n",
      "[Epoch 288/500] loss: 0.2217, acc: 45.45%\n",
      "[Epoch 289/500] loss: 0.2217, acc: 45.71%\n",
      "[Epoch 290/500] loss: 0.2216, acc: 45.71%\n",
      "[Epoch 291/500] loss: 0.2216, acc: 45.80%\n",
      "[Epoch 292/500] loss: 0.2216, acc: 45.89%\n",
      "[Epoch 293/500] loss: 0.2216, acc: 45.89%\n",
      "[Epoch 294/500] loss: 0.2216, acc: 45.89%\n",
      "[Epoch 295/500] loss: 0.2215, acc: 45.89%\n",
      "[Epoch 296/500] loss: 0.2215, acc: 45.98%\n",
      "[Epoch 297/500] loss: 0.2215, acc: 46.07%\n",
      "[Epoch 298/500] loss: 0.2215, acc: 46.15%\n",
      "[Epoch 299/500] loss: 0.2214, acc: 46.42%\n",
      "[Epoch 300/500] loss: 0.2214, acc: 46.60%\n",
      "[Epoch 301/500] loss: 0.2214, acc: 46.60%\n",
      "[Epoch 302/500] loss: 0.2214, acc: 46.60%\n",
      "[Epoch 303/500] loss: 0.2214, acc: 46.60%\n",
      "[Epoch 304/500] loss: 0.2213, acc: 46.77%\n",
      "[Epoch 305/500] loss: 0.2213, acc: 46.95%\n",
      "[Epoch 306/500] loss: 0.2213, acc: 47.13%\n",
      "[Epoch 307/500] loss: 0.2213, acc: 47.83%\n",
      "[Epoch 308/500] loss: 0.2213, acc: 48.28%\n",
      "[Epoch 309/500] loss: 0.2213, acc: 48.89%\n",
      "[Epoch 310/500] loss: 0.2212, acc: 49.16%\n",
      "[Epoch 311/500] loss: 0.2212, acc: 49.87%\n",
      "[Epoch 312/500] loss: 0.2212, acc: 50.49%\n",
      "[Epoch 313/500] loss: 0.2212, acc: 50.57%\n",
      "[Epoch 314/500] loss: 0.2212, acc: 51.19%\n",
      "[Epoch 315/500] loss: 0.2212, acc: 51.81%\n",
      "[Epoch 316/500] loss: 0.2211, acc: 52.25%\n",
      "[Epoch 317/500] loss: 0.2211, acc: 52.70%\n",
      "[Epoch 318/500] loss: 0.2211, acc: 52.87%\n",
      "[Epoch 319/500] loss: 0.2211, acc: 53.23%\n",
      "[Epoch 320/500] loss: 0.2211, acc: 53.49%\n",
      "[Epoch 321/500] loss: 0.2211, acc: 54.11%\n",
      "[Epoch 322/500] loss: 0.2210, acc: 54.82%\n",
      "[Epoch 323/500] loss: 0.2210, acc: 55.08%\n",
      "[Epoch 324/500] loss: 0.2210, acc: 55.44%\n",
      "[Epoch 325/500] loss: 0.2210, acc: 55.61%\n",
      "[Epoch 326/500] loss: 0.2210, acc: 55.44%\n",
      "[Epoch 327/500] loss: 0.2210, acc: 55.61%\n",
      "[Epoch 328/500] loss: 0.2210, acc: 55.61%\n",
      "[Epoch 329/500] loss: 0.2210, acc: 55.97%\n",
      "[Epoch 330/500] loss: 0.2209, acc: 55.79%\n",
      "[Epoch 331/500] loss: 0.2209, acc: 55.97%\n",
      "[Epoch 332/500] loss: 0.2209, acc: 56.23%\n",
      "[Epoch 333/500] loss: 0.2209, acc: 56.50%\n",
      "[Epoch 334/500] loss: 0.2209, acc: 56.76%\n",
      "[Epoch 335/500] loss: 0.2209, acc: 57.12%\n",
      "[Epoch 336/500] loss: 0.2209, acc: 57.29%\n",
      "[Epoch 337/500] loss: 0.2209, acc: 57.12%\n",
      "[Epoch 338/500] loss: 0.2209, acc: 57.38%\n",
      "[Epoch 339/500] loss: 0.2208, acc: 57.74%\n",
      "[Epoch 340/500] loss: 0.2208, acc: 58.00%\n",
      "[Epoch 341/500] loss: 0.2208, acc: 58.18%\n",
      "[Epoch 342/500] loss: 0.2208, acc: 58.44%\n",
      "[Epoch 343/500] loss: 0.2208, acc: 58.62%\n",
      "[Epoch 344/500] loss: 0.2208, acc: 58.80%\n",
      "[Epoch 345/500] loss: 0.2208, acc: 58.80%\n",
      "[Epoch 346/500] loss: 0.2208, acc: 58.89%\n",
      "[Epoch 347/500] loss: 0.2208, acc: 58.89%\n",
      "[Epoch 348/500] loss: 0.2208, acc: 58.89%\n",
      "[Epoch 349/500] loss: 0.2208, acc: 59.15%\n",
      "[Epoch 350/500] loss: 0.2207, acc: 59.15%\n",
      "[Epoch 351/500] loss: 0.2207, acc: 59.24%\n",
      "[Epoch 352/500] loss: 0.2207, acc: 59.59%\n",
      "[Epoch 353/500] loss: 0.2207, acc: 59.59%\n",
      "[Epoch 354/500] loss: 0.2207, acc: 59.50%\n",
      "[Epoch 355/500] loss: 0.2207, acc: 59.77%\n",
      "[Epoch 356/500] loss: 0.2207, acc: 59.86%\n",
      "[Epoch 357/500] loss: 0.2207, acc: 59.86%\n",
      "[Epoch 358/500] loss: 0.2207, acc: 60.04%\n",
      "[Epoch 359/500] loss: 0.2207, acc: 60.12%\n",
      "[Epoch 360/500] loss: 0.2207, acc: 60.12%\n",
      "[Epoch 361/500] loss: 0.2207, acc: 60.04%\n",
      "[Epoch 362/500] loss: 0.2207, acc: 60.21%\n",
      "[Epoch 363/500] loss: 0.2207, acc: 60.74%\n",
      "[Epoch 364/500] loss: 0.2206, acc: 60.83%\n",
      "[Epoch 365/500] loss: 0.2206, acc: 60.92%\n",
      "[Epoch 366/500] loss: 0.2206, acc: 60.92%\n",
      "[Epoch 367/500] loss: 0.2206, acc: 61.10%\n",
      "[Epoch 368/500] loss: 0.2206, acc: 61.10%\n",
      "[Epoch 369/500] loss: 0.2206, acc: 61.10%\n",
      "[Epoch 370/500] loss: 0.2206, acc: 61.27%\n",
      "[Epoch 371/500] loss: 0.2206, acc: 61.45%\n",
      "[Epoch 372/500] loss: 0.2206, acc: 61.72%\n",
      "[Epoch 373/500] loss: 0.2206, acc: 61.80%\n",
      "[Epoch 374/500] loss: 0.2206, acc: 61.80%\n",
      "[Epoch 375/500] loss: 0.2206, acc: 61.89%\n",
      "[Epoch 376/500] loss: 0.2206, acc: 62.16%\n",
      "[Epoch 377/500] loss: 0.2206, acc: 62.25%\n",
      "[Epoch 378/500] loss: 0.2206, acc: 63.04%\n",
      "[Epoch 379/500] loss: 0.2206, acc: 63.13%\n",
      "[Epoch 380/500] loss: 0.2206, acc: 63.13%\n",
      "[Epoch 381/500] loss: 0.2205, acc: 63.13%\n",
      "[Epoch 382/500] loss: 0.2205, acc: 63.22%\n",
      "[Epoch 383/500] loss: 0.2205, acc: 63.48%\n",
      "[Epoch 384/500] loss: 0.2205, acc: 63.57%\n",
      "[Epoch 385/500] loss: 0.2205, acc: 63.57%\n",
      "[Epoch 386/500] loss: 0.2205, acc: 63.57%\n",
      "[Epoch 387/500] loss: 0.2205, acc: 63.66%\n",
      "[Epoch 388/500] loss: 0.2205, acc: 63.57%\n",
      "[Epoch 389/500] loss: 0.2205, acc: 63.75%\n",
      "[Epoch 390/500] loss: 0.2205, acc: 63.75%\n",
      "[Epoch 391/500] loss: 0.2205, acc: 63.93%\n",
      "[Epoch 392/500] loss: 0.2205, acc: 64.01%\n",
      "[Epoch 393/500] loss: 0.2205, acc: 63.93%\n",
      "[Epoch 394/500] loss: 0.2205, acc: 63.93%\n",
      "[Epoch 395/500] loss: 0.2205, acc: 63.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 396/500] loss: 0.2205, acc: 64.10%\n",
      "[Epoch 397/500] loss: 0.2205, acc: 64.01%\n",
      "[Epoch 398/500] loss: 0.2205, acc: 63.93%\n",
      "[Epoch 399/500] loss: 0.2205, acc: 64.01%\n",
      "[Epoch 400/500] loss: 0.2205, acc: 64.01%\n",
      "[Epoch 401/500] loss: 0.2205, acc: 64.10%\n",
      "[Epoch 402/500] loss: 0.2205, acc: 64.28%\n",
      "[Epoch 403/500] loss: 0.2204, acc: 64.28%\n",
      "[Epoch 404/500] loss: 0.2204, acc: 64.72%\n",
      "[Epoch 405/500] loss: 0.2204, acc: 64.63%\n",
      "[Epoch 406/500] loss: 0.2204, acc: 64.99%\n",
      "[Epoch 407/500] loss: 0.2204, acc: 65.16%\n",
      "[Epoch 408/500] loss: 0.2204, acc: 65.25%\n",
      "[Epoch 409/500] loss: 0.2204, acc: 65.25%\n",
      "[Epoch 410/500] loss: 0.2204, acc: 65.16%\n",
      "[Epoch 411/500] loss: 0.2204, acc: 65.16%\n",
      "[Epoch 412/500] loss: 0.2204, acc: 65.43%\n",
      "[Epoch 413/500] loss: 0.2204, acc: 65.34%\n",
      "[Epoch 414/500] loss: 0.2204, acc: 65.34%\n",
      "[Epoch 415/500] loss: 0.2204, acc: 65.52%\n",
      "[Epoch 416/500] loss: 0.2204, acc: 65.52%\n",
      "[Epoch 417/500] loss: 0.2204, acc: 65.69%\n",
      "[Epoch 418/500] loss: 0.2204, acc: 65.78%\n",
      "[Epoch 419/500] loss: 0.2204, acc: 65.78%\n",
      "[Epoch 420/500] loss: 0.2204, acc: 65.96%\n",
      "[Epoch 421/500] loss: 0.2204, acc: 66.14%\n",
      "[Epoch 422/500] loss: 0.2204, acc: 66.14%\n",
      "[Epoch 423/500] loss: 0.2204, acc: 66.14%\n",
      "[Epoch 424/500] loss: 0.2204, acc: 66.14%\n",
      "[Epoch 425/500] loss: 0.2204, acc: 66.05%\n",
      "[Epoch 426/500] loss: 0.2204, acc: 66.05%\n",
      "[Epoch 427/500] loss: 0.2204, acc: 66.05%\n",
      "[Epoch 428/500] loss: 0.2204, acc: 66.31%\n",
      "[Epoch 429/500] loss: 0.2204, acc: 66.49%\n",
      "[Epoch 430/500] loss: 0.2204, acc: 66.58%\n",
      "[Epoch 431/500] loss: 0.2203, acc: 66.84%\n",
      "[Epoch 432/500] loss: 0.2203, acc: 66.84%\n",
      "[Epoch 433/500] loss: 0.2203, acc: 66.84%\n",
      "[Epoch 434/500] loss: 0.2203, acc: 66.84%\n",
      "[Epoch 435/500] loss: 0.2203, acc: 66.93%\n",
      "[Epoch 436/500] loss: 0.2203, acc: 66.84%\n",
      "[Epoch 437/500] loss: 0.2203, acc: 66.76%\n",
      "[Epoch 438/500] loss: 0.2203, acc: 66.93%\n",
      "[Epoch 439/500] loss: 0.2203, acc: 66.84%\n",
      "[Epoch 440/500] loss: 0.2203, acc: 66.93%\n",
      "[Epoch 441/500] loss: 0.2203, acc: 66.93%\n",
      "[Epoch 442/500] loss: 0.2203, acc: 67.02%\n",
      "[Epoch 443/500] loss: 0.2203, acc: 67.02%\n",
      "[Epoch 444/500] loss: 0.2203, acc: 67.11%\n",
      "[Epoch 445/500] loss: 0.2203, acc: 67.11%\n",
      "[Epoch 446/500] loss: 0.2203, acc: 67.20%\n",
      "[Epoch 447/500] loss: 0.2203, acc: 67.11%\n",
      "[Epoch 448/500] loss: 0.2203, acc: 67.20%\n",
      "[Epoch 449/500] loss: 0.2203, acc: 67.11%\n",
      "[Epoch 450/500] loss: 0.2203, acc: 67.11%\n",
      "[Epoch 451/500] loss: 0.2203, acc: 67.02%\n",
      "[Epoch 452/500] loss: 0.2203, acc: 67.02%\n",
      "[Epoch 453/500] loss: 0.2203, acc: 67.02%\n",
      "[Epoch 454/500] loss: 0.2203, acc: 67.11%\n",
      "[Epoch 455/500] loss: 0.2203, acc: 67.02%\n",
      "[Epoch 456/500] loss: 0.2203, acc: 66.93%\n",
      "[Epoch 457/500] loss: 0.2203, acc: 67.02%\n",
      "[Epoch 458/500] loss: 0.2203, acc: 67.02%\n",
      "[Epoch 459/500] loss: 0.2203, acc: 67.11%\n",
      "[Epoch 460/500] loss: 0.2203, acc: 67.11%\n",
      "[Epoch 461/500] loss: 0.2203, acc: 67.02%\n",
      "[Epoch 462/500] loss: 0.2203, acc: 67.11%\n",
      "[Epoch 463/500] loss: 0.2203, acc: 67.02%\n",
      "[Epoch 464/500] loss: 0.2203, acc: 67.11%\n",
      "[Epoch 465/500] loss: 0.2203, acc: 67.20%\n",
      "[Epoch 466/500] loss: 0.2203, acc: 67.37%\n",
      "[Epoch 467/500] loss: 0.2203, acc: 67.37%\n",
      "[Epoch 468/500] loss: 0.2203, acc: 67.20%\n",
      "[Epoch 469/500] loss: 0.2203, acc: 67.11%\n",
      "[Epoch 470/500] loss: 0.2202, acc: 67.11%\n",
      "[Epoch 471/500] loss: 0.2202, acc: 67.20%\n",
      "[Epoch 472/500] loss: 0.2202, acc: 67.20%\n",
      "[Epoch 473/500] loss: 0.2202, acc: 67.20%\n",
      "[Epoch 474/500] loss: 0.2202, acc: 67.20%\n",
      "[Epoch 475/500] loss: 0.2202, acc: 67.20%\n",
      "[Epoch 476/500] loss: 0.2202, acc: 67.20%\n",
      "[Epoch 477/500] loss: 0.2202, acc: 67.20%\n",
      "[Epoch 478/500] loss: 0.2202, acc: 67.20%\n",
      "[Epoch 479/500] loss: 0.2202, acc: 67.20%\n",
      "[Epoch 480/500] loss: 0.2202, acc: 67.29%\n",
      "[Epoch 481/500] loss: 0.2202, acc: 67.11%\n",
      "[Epoch 482/500] loss: 0.2202, acc: 66.93%\n",
      "[Epoch 483/500] loss: 0.2202, acc: 66.93%\n",
      "[Epoch 484/500] loss: 0.2202, acc: 67.02%\n",
      "[Epoch 485/500] loss: 0.2202, acc: 67.02%\n",
      "[Epoch 486/500] loss: 0.2202, acc: 67.11%\n",
      "[Epoch 487/500] loss: 0.2202, acc: 67.20%\n",
      "[Epoch 488/500] loss: 0.2202, acc: 67.11%\n",
      "[Epoch 489/500] loss: 0.2202, acc: 67.20%\n",
      "[Epoch 490/500] loss: 0.2202, acc: 67.29%\n",
      "[Epoch 491/500] loss: 0.2202, acc: 67.37%\n",
      "[Epoch 492/500] loss: 0.2202, acc: 67.37%\n",
      "[Epoch 493/500] loss: 0.2202, acc: 67.37%\n",
      "[Epoch 494/500] loss: 0.2202, acc: 67.64%\n",
      "[Epoch 495/500] loss: 0.2202, acc: 67.73%\n",
      "[Epoch 496/500] loss: 0.2202, acc: 67.82%\n",
      "[Epoch 497/500] loss: 0.2202, acc: 67.82%\n",
      "[Epoch 498/500] loss: 0.2202, acc: 67.82%\n",
      "[Epoch 499/500] loss: 0.2202, acc: 67.82%\n",
      "[Epoch 500/500] loss: 0.2202, acc: 67.82%\n"
     ]
    }
   ],
   "source": [
    "# Automatically determine the device that PyTorch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Track the value of the loss function and model accuracy across epochs\n",
    "history_train = {'loss': [], 'acc': []}\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    # Run the training loop and calculate the accuracy\n",
    "    num_correct, loss = Batch_Train(model, mytrain_input, mytrain_output, criterion, optimizer, device, batch_size)\n",
    "    accuracy = float(num_correct) / (len(mytrain_input))*100\n",
    "    history_train['loss'].append(loss)\n",
    "    history_train['acc'].append(accuracy)\n",
    "    \n",
    "    if verbose or epoch + 1 == max_epochs:\n",
    "            print(f'[Epoch {epoch + 1}/{max_epochs}]'\n",
    "                  f\" loss: {history_train['loss'][-1]:.4f}, acc: {history_train['acc'][-1]:2.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "52a21f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x324 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(9, 4.5))\n",
    "for ax, metric in zip(axes, ['loss', 'acc']):\n",
    "    ax.plot(history_train[metric])\n",
    "    ax.set_xlabel('epoch', fontsize=12)\n",
    "    ax.set_ylabel(metric, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e9c44",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "56b7a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(model, mytest_input, device, threshold):\n",
    "    \n",
    "    # Set the model to evaluation mode. This will turn off layers that would\n",
    "    # otherwise behave differently during training, such as dropout.\n",
    "    model.eval()\n",
    "    \n",
    "    mytest_input_rnn  = torch.from_numpy(mytest_input).float().to(device)\n",
    "\n",
    "    mytest_output_rnn, hidden = model(mytest_input_rnn)\n",
    "    output_prob = nn.functional.softmax(mytest_output_rnn, dim=2).detach().numpy()\n",
    "    \n",
    "    # the decision is made from the 4th period's probability\n",
    "    pred_res = output_prob[:,3,0]\n",
    "    pred_labels = 1*(pred_res > threshold)\n",
    "    \n",
    "    return pred_labels, pred_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2fef0374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels, pred_res = Test(model, mytest_input, device, threshold=0.5)\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "532b1be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50638145, 0.48395917, 0.48223758, 0.47666153, 0.49958035,\n",
       "       0.5089327 , 0.47645345, 0.4652291 , 0.51044583, 0.4773967 ,\n",
       "       0.5000169 , 0.49034044, 0.49865344, 0.49748254, 0.4749795 ,\n",
       "       0.4773967 , 0.48224148, 0.50724053, 0.48108786, 0.47431886,\n",
       "       0.5079281 , 0.49748254, 0.49663523, 0.47522283, 0.47803485,\n",
       "       0.5099947 , 0.51396406, 0.48343548, 0.47441623, 0.4746631 ,\n",
       "       0.49881092, 0.5310752 , 0.4761132 , 0.48347315, 0.47570622,\n",
       "       0.50566345, 0.49092633, 0.47877824, 0.556627  , 0.47803167,\n",
       "       0.47404382, 0.4951779 , 0.47467554, 0.4924293 , 0.48224294,\n",
       "       0.4757214 , 0.4794996 , 0.48075664, 0.48108786, 0.47645235,\n",
       "       0.4773967 , 0.4743597 , 0.49610937, 0.47897854, 0.47803167,\n",
       "       0.51698965, 0.51192683, 0.49114013, 0.4752723 , 0.503235  ,\n",
       "       0.48067442, 0.48797494, 0.4963379 , 0.4817954 , 0.47432122,\n",
       "       0.4740305 , 0.50003076, 0.50566345, 0.47645968, 0.48309293,\n",
       "       0.47662136, 0.50488317, 0.5153777 , 0.4784413 , 0.47742674,\n",
       "       0.48470706, 0.47410482, 0.47708386, 0.47765675, 0.47768402,\n",
       "       0.4780049 , 0.478019  , 0.49003536], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "63e9e9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata_wide = mytestdata.pivot_table(index=['participant_id'], columns='collect_period', values=\"classlabel\")\n",
    "testdata_wide = testdata_wide.sort_index(axis=1)\n",
    "\n",
    "actual_labels = []\n",
    "for i in range(testdata_wide.shape[0]):\n",
    "    actual_labels.append(np.nanmax(testdata_wide.iloc[i,:]))\n",
    "actual_labels = np.array(actual_labels)\n",
    "actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "170ba89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55 13]\n",
      " [10  5]]\n"
     ]
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(actual_labels, pred_labels)\n",
    "print(confusion)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6c4c281d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8088235294117647\n",
      "0.3333333333333333\n",
      "0.2777777777777778\n"
     ]
    }
   ],
   "source": [
    "specificity = TN / (TN + FP)\n",
    "print(specificity)\n",
    "sensitivity = TP / (TP + FN)\n",
    "print(sensitivity)\n",
    "precision = TP/(TP + FP)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "667ccbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "      <th>thresholds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.556627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.516990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.513964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.509995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.506381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.505663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.504883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.503235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.498811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.498653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.497483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.496338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.496109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.492429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.491140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.490035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.487975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.482243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.482241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.481795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.481088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.480757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.480674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.479500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.478979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.478035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.478032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.477427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.477397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.475706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.475272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fpr       tpr  thresholds\n",
       "0   0.000000  0.000000    1.556627\n",
       "1   0.014706  0.000000    0.556627\n",
       "2   0.029412  0.000000    0.531075\n",
       "3   0.029412  0.066667    0.516990\n",
       "4   0.058824  0.066667    0.513964\n",
       "5   0.058824  0.266667    0.509995\n",
       "6   0.117647  0.266667    0.506381\n",
       "7   0.147059  0.266667    0.505663\n",
       "8   0.161765  0.266667    0.504883\n",
       "9   0.161765  0.333333    0.503235\n",
       "10  0.220588  0.333333    0.498811\n",
       "11  0.220588  0.400000    0.498653\n",
       "12  0.235294  0.466667    0.497483\n",
       "13  0.264706  0.466667    0.496338\n",
       "14  0.264706  0.533333    0.496109\n",
       "15  0.294118  0.533333    0.492429\n",
       "16  0.294118  0.600000    0.491140\n",
       "17  0.338235  0.600000    0.490035\n",
       "18  0.338235  0.666667    0.487975\n",
       "19  0.426471  0.666667    0.482243\n",
       "20  0.426471  0.733333    0.482241\n",
       "21  0.455882  0.733333    0.481795\n",
       "22  0.485294  0.733333    0.481088\n",
       "23  0.500000  0.733333    0.480757\n",
       "24  0.500000  0.800000    0.480674\n",
       "25  0.514706  0.800000    0.479500\n",
       "26  0.514706  0.866667    0.478979\n",
       "27  0.558824  0.866667    0.478035\n",
       "28  0.573529  0.933333    0.478032\n",
       "29  0.647059  0.933333    0.477427\n",
       "30  0.691176  0.933333    0.477397\n",
       "31  0.823529  0.933333    0.475706\n",
       "32  0.823529  1.000000    0.475272\n",
       "33  1.000000  1.000000    0.465229"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(actual_labels, pred_res)\n",
    "thresholdData = {'fpr': fpr, 'tpr': tpr, 'thresholds': thresholds}\n",
    "thresholdData = pd.DataFrame(thresholdData)\n",
    "thresholdData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "269dd443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for diabetes classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "50b2cdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6970588235294117\n"
     ]
    }
   ],
   "source": [
    "print(metrics.roc_auc_score(actual_labels, pred_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ec145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087c772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
