{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14fc022b",
   "metadata": {},
   "source": [
    "Install Pytorch package (need to specify the version to get correctly installed. Possible error will lead died kernal.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8dcb538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f0fb9d",
   "metadata": {},
   "source": [
    "The RNN model with PyTorch will be implemented on the Metadata only to farmiliarize myself with the PyTorch library and get starts with RNN. First of all, we need to treat each patient as an observation and get every "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8b25ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43329a84",
   "metadata": {},
   "source": [
    "A better explanation about the RNN example https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b461620",
   "metadata": {},
   "source": [
    "Read in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7299f00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>project</th>\n",
       "      <th>specimen</th>\n",
       "      <th>was_term</th>\n",
       "      <th>delivery_wk</th>\n",
       "      <th>collect_wk</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>NIH.Racial.Category</th>\n",
       "      <th>NIH.Ethnicity.Category</th>\n",
       "      <th>was_preterm</th>\n",
       "      <th>was_early_preterm</th>\n",
       "      <th>collect_tri</th>\n",
       "      <th>age_imp</th>\n",
       "      <th>race_imp</th>\n",
       "      <th>age_imp_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00001</td>\n",
       "      <td>A</td>\n",
       "      <td>A00001-05</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>American Indian</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00002</td>\n",
       "      <td>A</td>\n",
       "      <td>A00002-01</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00003</td>\n",
       "      <td>A</td>\n",
       "      <td>A00003-02</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>Asian-Japanese</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>Asian</td>\n",
       "      <td>from_29_to_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00004</td>\n",
       "      <td>A</td>\n",
       "      <td>A00004-08</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00004</td>\n",
       "      <td>A</td>\n",
       "      <td>A00004-12</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>29</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>J00111</td>\n",
       "      <td>J</td>\n",
       "      <td>J00111-01</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>J00112</td>\n",
       "      <td>J</td>\n",
       "      <td>J00112-01</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3575</th>\n",
       "      <td>J00113</td>\n",
       "      <td>J</td>\n",
       "      <td>J00113-01</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>32</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>White</td>\n",
       "      <td>from_29_to_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576</th>\n",
       "      <td>J00115</td>\n",
       "      <td>J</td>\n",
       "      <td>J00115-01</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>35</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>White</td>\n",
       "      <td>from_29_to_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>J00116</td>\n",
       "      <td>J</td>\n",
       "      <td>J00116-01</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>26</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3578 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant_id project   specimen  was_term  delivery_wk  collect_wk  \\\n",
       "0            A00001       A  A00001-05      True           38          33   \n",
       "1            A00002       A  A00002-01      True           40          38   \n",
       "2            A00003       A  A00003-02      True           40          30   \n",
       "3            A00004       A  A00004-08      True           40          27   \n",
       "4            A00004       A  A00004-12      True           40          29   \n",
       "...             ...     ...        ...       ...          ...         ...   \n",
       "3573         J00111       J  J00111-01      True           40          17   \n",
       "3574         J00112       J  J00112-01      True           39          19   \n",
       "3575         J00113       J  J00113-01      True           41          16   \n",
       "3576         J00115       J  J00115-01      True           42          18   \n",
       "3577         J00116       J  J00116-01      True           40          17   \n",
       "\n",
       "                 race      age               NIH.Racial.Category  \\\n",
       "0     American Indian  Unknown  American Indian or Alaska Native   \n",
       "1               White  Unknown                             White   \n",
       "2      Asian-Japanese  Unknown                             Asian   \n",
       "3               White  Unknown                             White   \n",
       "4               White  Unknown                             White   \n",
       "...               ...      ...                               ...   \n",
       "3573        Caucasian       27                             White   \n",
       "3574        Caucasian       27                             White   \n",
       "3575        Caucasian       32                             White   \n",
       "3576        Caucasian       35                             White   \n",
       "3577        Caucasian       26                             White   \n",
       "\n",
       "     NIH.Ethnicity.Category  was_preterm  was_early_preterm  collect_tri  \\\n",
       "0                   Unknown        False              False            3   \n",
       "1                   Unknown        False              False            3   \n",
       "2                   Unknown        False              False            3   \n",
       "3                   Unknown        False              False            3   \n",
       "4                   Unknown        False              False            3   \n",
       "...                     ...          ...                ...          ...   \n",
       "3573                Unknown        False              False            2   \n",
       "3574                Unknown        False              False            2   \n",
       "3575                Unknown        False              False            2   \n",
       "3576                Unknown        False              False            2   \n",
       "3577                Unknown        False              False            2   \n",
       "\n",
       "      age_imp                          race_imp    age_imp_cat  \n",
       "0          27  American Indian or Alaska Native  from_18_to_28  \n",
       "1          24                             White  from_18_to_28  \n",
       "2          32                             Asian  from_29_to_38  \n",
       "3          25                             White  from_18_to_28  \n",
       "4          25                             White  from_18_to_28  \n",
       "...       ...                               ...            ...  \n",
       "3573       27                             White  from_18_to_28  \n",
       "3574       27                             White  from_18_to_28  \n",
       "3575       32                             White  from_29_to_38  \n",
       "3576       35                             White  from_29_to_38  \n",
       "3577       26                             White  from_18_to_28  \n",
       "\n",
       "[3578 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata = pd.read_csv('test/metadata_imputed.csv', delimiter=',')\n",
    "mydata = pd.DataFrame(mydata)\n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327d6668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sxiao15\\AppData\\Local\\Temp\\ipykernel_15180\\1563144068.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"project\"] = mydata[\"project\"].astype('category')\n",
      "C:\\Users\\sxiao15\\AppData\\Local\\Temp\\ipykernel_15180\\1563144068.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"race_imp\"] = mydata[\"race_imp\"].astype('category')\n",
      "C:\\Users\\sxiao15\\AppData\\Local\\Temp\\ipykernel_15180\\1563144068.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"age_imp_cat\"] = mydata[\"age_imp_cat\"].astype('category')\n",
      "C:\\Users\\sxiao15\\AppData\\Local\\Temp\\ipykernel_15180\\1563144068.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"project\"] = mydata[\"project\"].cat.codes\n",
      "C:\\Users\\sxiao15\\AppData\\Local\\Temp\\ipykernel_15180\\1563144068.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"race_imp\"] = mydata[\"race_imp\"].cat.codes\n",
      "C:\\Users\\sxiao15\\AppData\\Local\\Temp\\ipykernel_15180\\1563144068.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"age_imp_cat\"] = mydata[\"age_imp_cat\"].cat.codes\n",
      "C:\\Users\\sxiao15\\AppData\\Local\\Temp\\ipykernel_15180\\1563144068.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata['was_preterm'] = mydata['was_preterm'].astype('int8')\n",
      "C:\\Users\\sxiao15\\AppData\\Local\\Temp\\ipykernel_15180\\1563144068.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata['was_early_preterm'] = mydata['was_early_preterm'].astype('int8')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "participant_id       object\n",
       "project                int8\n",
       "specimen             object\n",
       "collect_wk            int64\n",
       "was_preterm            int8\n",
       "was_early_preterm      int8\n",
       "race_imp               int8\n",
       "age_imp_cat            int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata = mydata[[\"participant_id\", \"project\", \"specimen\", \"collect_wk\", \n",
    "                 \"was_preterm\", \"was_early_preterm\", \"race_imp\", \"age_imp_cat\" ]]\n",
    "mydata[\"project\"] = mydata[\"project\"].astype('category')\n",
    "mydata[\"race_imp\"] = mydata[\"race_imp\"].astype('category')\n",
    "mydata[\"age_imp_cat\"] = mydata[\"age_imp_cat\"].astype('category')\n",
    "\n",
    "mydata[\"project\"] = mydata[\"project\"].cat.codes\n",
    "mydata[\"race_imp\"] = mydata[\"race_imp\"].cat.codes\n",
    "mydata[\"age_imp_cat\"] = mydata[\"age_imp_cat\"].cat.codes\n",
    "mydata['was_preterm'] = mydata['was_preterm'].astype('int8')\n",
    "mydata['was_early_preterm'] = mydata['was_early_preterm'].astype('int8')\n",
    "mydata.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa51c19",
   "metadata": {},
   "source": [
    "We split the training and testing data set based on *project* J."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b1aabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata_train = mydata[mydata['project']!=9] # Not project J\n",
    "mydata_test  = mydata[mydata['project']==9] # project J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6adfa73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydata_train = mydata_train[[\"participant_id\", \"project\", \"specimen\", \"collect_wk\", \n",
    "#                              \"was_preterm\", \"was_early_preterm\", \"race_imp\", \"age_imp_cat\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1224ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydata1[\"project\"] = mydata1[\"project\"].astype('category')\n",
    "# mydata1[\"race_imp\"] = mydata1[\"race_imp\"].astype('category')\n",
    "# mydata1[\"age_imp_cat\"] = mydata1[\"age_imp_cat\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac97cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydata1[\"project\"] = mydata1[\"project\"].cat.codes\n",
    "# mydata1[\"race_imp\"] = mydata1[\"race_imp\"].cat.codes\n",
    "# mydata1[\"age_imp_cat\"] = mydata1[\"age_imp_cat\"].cat.codes\n",
    "# mydata1['was_preterm'] = mydata1['was_preterm'].astype('int8')\n",
    "# mydata1['was_early_preterm'] = mydata1['was_early_preterm'].astype('int8')\n",
    "# mydata1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca89d4e0",
   "metadata": {},
   "source": [
    "We want to predict the class of preterm birth and early preterm birth for few consecutive specimemns collected. We will have to define the\n",
    "\n",
    "- Input data (2 covariates)\n",
    "    - The meta data (imputed age and race category) for each observation\n",
    "- Output (1 covariate)\n",
    "    - The class label of preterm birth/early preterm birth\n",
    "    \n",
    "via data pre-processing and move the data from numpy arrays to Pytorch data structure - **Torch Tensors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1295b91",
   "metadata": {},
   "source": [
    "## Preterm birth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a11bad",
   "metadata": {},
   "source": [
    "Since the simple RNN only allow one covariates to enter the model, I choose *age_imp_cat* as a starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c4ef4",
   "metadata": {},
   "source": [
    "### Input data from categorical age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85722261",
   "metadata": {},
   "source": [
    "We need to do some data filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f98e4c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2417, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep the rows with collect_wk < 37 for Preterm task\n",
    "mydata1 = mydata_train.loc[mydata_train['collect_wk']<37,]\n",
    "\n",
    "# delete the duplicated samples in the same collection week\n",
    "mydata2 = mydata1.drop_duplicates(subset=['participant_id', 'collect_wk'], keep='first')\n",
    "mydata2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ca36a",
   "metadata": {},
   "source": [
    "Note: Too much samples are deleted, we need to take care of this situation. For metadata table, its OK since the information of duplicates are exactly same. But it will be specimen specific for taxonomy, phylotypes and distance data sets. **We need to discuss it**. We need to either form up some summary statistic for multiple collected sample in the same week or other methods (???)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6843c2e",
   "metadata": {},
   "source": [
    "Since we will give a patient the label of preterm birth as the delievey week < 37, we have 36 as one of the dimension for the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68aadc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of collect_wk       1    2    3    4    5    6    7    8    9    10  ...   27  \\\n",
       "participant_id                                                    ...        \n",
       "A00001          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00003          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00004          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  2.0   \n",
       "A00005          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00006          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "I00534          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "I00535          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "I00536          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "I00537          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "I00538          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "collect_wk       28   29   30   31   32   33   34   35   36  \n",
       "participant_id                                               \n",
       "A00001          0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0  \n",
       "A00003          0.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "A00004          0.0  2.0  2.0  0.0  0.0  2.0  0.0  2.0  0.0  \n",
       "A00005          0.0  3.0  0.0  0.0  0.0  0.0  0.0  3.0  3.0  \n",
       "A00006          0.0  0.0  0.0  2.0  0.0  2.0  0.0  0.0  0.0  \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "I00534          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "I00535          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "I00536          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "I00537          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "I00538          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1174 rows x 36 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata2_wide_age = mydata2.pivot_table(index=['participant_id'], columns='collect_wk', values='age_imp_cat')\n",
    "# sort by collect_wk\n",
    "mydata2_wide_age = mydata2_wide_age.sort_index(axis=1)\n",
    "mydata2_wide_age = mydata2_wide_age.fillna(0)\n",
    "mydata2_wide_age.shape\n",
    "mydata2_wide_age.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b888bd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1174\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "(seq_length, num_feature) = mydata2_wide_age.shape\n",
    "print(seq_length)\n",
    "print(num_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e69b9",
   "metadata": {},
   "source": [
    "### Output data from Preterm birth label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55944bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>collect_wk</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A00001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00006</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C00026</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C00027</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C00028</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C00029</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C00030</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "collect_wk       1    2    3    4    5    6    7    8    9    10  ...   27  \\\n",
       "participant_id                                                    ...        \n",
       "A00001          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00003          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00004          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00005          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00006          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "C00026          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0   \n",
       "C00027          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0   \n",
       "C00028          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0   \n",
       "C00029          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0   \n",
       "C00030          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0   \n",
       "\n",
       "collect_wk       28   29   30   31   32   33   34   35   36  \n",
       "participant_id                                               \n",
       "A00001          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "A00003          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "A00004          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "A00005          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "A00006          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "C00026          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "C00027          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "C00028          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "C00029          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "C00030          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "\n",
       "[100 rows x 36 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata2_wide_Y = mydata2.pivot_table(index=['participant_id'], columns='collect_wk', values='was_preterm')\n",
    "# sort by collect_wk\n",
    "mydata2_wide_Y = mydata2_wide_Y.sort_index(axis=1)\n",
    "mydata2_wide_Y = mydata2_wide_Y.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "mydata2_wide_Y.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbd00600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sxiao15\\AppData\\Local\\Temp\\ipykernel_15180\\1327531968.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:210.)\n",
      "  input_seq = torch.Tensor([mydata2_wide_age.to_numpy()])\n"
     ]
    }
   ],
   "source": [
    "# Creating lists that will hold our input and target sequences\n",
    "input_seq = torch.Tensor([mydata2_wide_age.to_numpy()])\n",
    "target_seq = torch.Tensor([mydata2_wide_Y.to_numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e3d8b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1174, 36])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "868976ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1174, 36])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab1a8060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "301a270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True, nonlinearity='relu')   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7825a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model(input_size=num_feature, output_size=num_feature, hidden_dim=12, n_layers=3)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a958829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100............. Loss: 44.2048\n",
      "Epoch: 20/100............. Loss: 44.1793\n",
      "Epoch: 30/100............. Loss: 44.1754\n",
      "Epoch: 40/100............. Loss: 44.1751\n",
      "Epoch: 50/100............. Loss: 44.1745\n",
      "Epoch: 60/100............. Loss: 44.1744\n",
      "Epoch: 70/100............. Loss: 44.1744\n",
      "Epoch: 80/100............. Loss: 44.1744\n",
      "Epoch: 90/100............. Loss: 44.1744\n",
      "Epoch: 100/100............. Loss: 44.1744\n"
     ]
    }
   ],
   "source": [
    "# Training Run\n",
    "input_seq = input_seq.to(device)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    #input_seq = input_seq.to(device)\n",
    "    output, hidden = model(input_seq)\n",
    "    output = output.to(device)\n",
    "    target_seq = target_seq.to(device)\n",
    "    loss = criterion(output, target_seq.view(-1, num_feature))\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8db619cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1174, 36])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq.view(-1, num_feature).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fdbad9",
   "metadata": {},
   "source": [
    "### Apply the simple RNN on testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "806f84fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant_id       object\n",
      "project                int8\n",
      "specimen             object\n",
      "collect_wk            int64\n",
      "was_preterm            int8\n",
      "was_early_preterm      int8\n",
      "race_imp               int8\n",
      "age_imp_cat            int8\n",
      "dtype: object\n",
      "(83, 8)\n"
     ]
    }
   ],
   "source": [
    "testset = mydata_test[[\"participant_id\", \"project\", \"specimen\", \"collect_wk\", \n",
    "                       \"was_preterm\", \"was_early_preterm\", \"race_imp\", \"age_imp_cat\" ]]\n",
    "print(testset.dtypes)\n",
    "print(testset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9b91e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep the rows with collect_wk < 37 for Preterm task\n",
    "testset1 = testset.loc[testset['collect_wk']<37,]\n",
    "\n",
    "# delete the duplicated samples in the same collection week\n",
    "testset2 = testset1.drop_duplicates(subset=['participant_id', 'collect_wk'], keep='first')\n",
    "testset2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b305c080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of collect_wk       12   13   14   15   16   17   18   19\n",
       "participant_id                                        \n",
       "J00001          0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0\n",
       "J00004          0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0\n",
       "J00007          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "J00008          0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0\n",
       "J00010          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...\n",
       "J00111          0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0\n",
       "J00112          0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       "J00113          0.0  0.0  0.0  0.0  3.0  0.0  0.0  0.0\n",
       "J00115          0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0\n",
       "J00116          0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0\n",
       "\n",
       "[83 rows x 8 columns]>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset2_wide_age = testset2.pivot_table(index=['participant_id'], columns='collect_wk', values='age_imp_cat')\n",
    "# sort by collect_wk\n",
    "testset2_wide_age = testset2_wide_age.sort_index(axis=1)\n",
    "testset2_wide_age = testset2_wide_age.fillna(0)\n",
    "testset2_wide_age.shape\n",
    "testset2_wide_age.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edb25d",
   "metadata": {},
   "source": [
    "Fill-in zeros for empty collection weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4de0833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(seq_length_test, num_feature_test) = testset2_wide_age.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64b0b3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 36)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     0.0\n",
       "4     0.0\n",
       "5     0.0\n",
       "6     0.0\n",
       "7     0.0\n",
       "8     0.0\n",
       "9     0.0\n",
       "10    0.0\n",
       "11    0.0\n",
       "12    0.0\n",
       "13    0.0\n",
       "14    0.0\n",
       "15    0.0\n",
       "16    0.0\n",
       "17    0.0\n",
       "18    3.0\n",
       "19    0.0\n",
       "20    0.0\n",
       "21    0.0\n",
       "22    0.0\n",
       "23    0.0\n",
       "24    0.0\n",
       "25    0.0\n",
       "26    0.0\n",
       "27    0.0\n",
       "28    0.0\n",
       "29    0.0\n",
       "30    0.0\n",
       "31    0.0\n",
       "32    0.0\n",
       "33    0.0\n",
       "34    0.0\n",
       "35    0.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset3 = pd.DataFrame(np.nan, index=range(seq_length_test), columns=range(num_feature))\n",
    "testset3 = testset3.rename(columns={x:y for x,y in zip(testset3.columns,range(0,num_feature))})\n",
    "testset3 = testset3.fillna(0)\n",
    "print(testset3.shape)\n",
    "test_index = testset2_wide_age._get_numeric_data().columns.values.tolist()\n",
    "testset3.iloc[:,test_index] = testset2_wide_age\n",
    "\n",
    "# check: first observation in testing set has value 3.0 at column 19 (index 18)\n",
    "testset3.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37b6e7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 36])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii = 0\n",
    "mytest_input = testset3.iloc[ii]\n",
    "mytest_input = torch.Tensor([[mytest_input.to_numpy()]])\n",
    "mytest_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c0d3775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0281)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval() # eval mode\n",
    "out, hidden = model(mytest_input)\n",
    "prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "# Taking the class with the highest probability score from the output\n",
    "prob_max = torch.max(prob)\n",
    "print(prob_max)\n",
    "pred_label = 1*(prob_max > 0.5)\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a6ea0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028099045157432556\n",
      "0.028104817494750023\n",
      "0.028104789555072784\n",
      "0.028099045157432556\n",
      "0.028104789555072784\n",
      "0.02810567058622837\n",
      "0.028099045157432556\n",
      "0.02809915877878666\n",
      "0.02808426134288311\n",
      "0.028104793280363083\n",
      "0.028104789555072784\n",
      "0.028092756867408752\n",
      "0.028104789555072784\n",
      "0.02810567058622837\n",
      "0.02810567058622837\n",
      "0.028099045157432556\n",
      "0.028104789555072784\n",
      "0.028104793280363083\n",
      "0.028104789555072784\n",
      "0.02810567058622837\n",
      "0.028104789555072784\n",
      "0.02808426134288311\n",
      "0.02809915877878666\n",
      "0.02809915877878666\n",
      "0.02809915877878666\n",
      "0.02809915877878666\n",
      "0.028104793280363083\n",
      "0.028104789555072784\n",
      "0.02810567058622837\n",
      "0.02810567058622837\n",
      "0.02810567058622837\n",
      "0.028104793280363083\n",
      "0.02810577303171158\n",
      "0.028099045157432556\n",
      "0.02810567058622837\n",
      "0.028104793280363083\n",
      "0.02810567058622837\n",
      "0.028098834678530693\n",
      "0.028104793280363083\n",
      "0.02810567058622837\n",
      "0.028092706575989723\n",
      "0.028104817494750023\n",
      "0.02810567058622837\n",
      "0.02810567058622837\n",
      "0.02810148522257805\n",
      "0.02810567058622837\n",
      "0.028104817494750023\n",
      "0.028101855888962746\n",
      "0.028104789555072784\n",
      "0.028098834678530693\n",
      "0.028104793280363083\n",
      "0.02810567058622837\n",
      "0.028104793280363083\n",
      "0.028096657246351242\n",
      "0.02810567058622837\n",
      "0.02810567058622837\n",
      "0.028104789555072784\n",
      "0.028104789555072784\n",
      "0.02810567058622837\n",
      "0.028104793280363083\n",
      "0.028104793280363083\n",
      "0.028092756867408752\n",
      "0.028104793280363083\n",
      "0.028104789555072784\n",
      "0.02810567058622837\n",
      "0.02810577303171158\n",
      "0.028104793280363083\n",
      "0.028104793280363083\n",
      "0.028099045157432556\n",
      "0.028104789555072784\n",
      "0.028104793280363083\n",
      "0.028104817494750023\n",
      "0.028104789555072784\n",
      "0.02810148522257805\n",
      "0.028099045157432556\n",
      "0.028104789555072784\n",
      "0.02810567058622837\n",
      "0.028104793280363083\n",
      "0.028104817494750023\n",
      "0.028101855888962746\n",
      "0.02810567058622837\n",
      "0.028099045157432556\n",
      "0.028104817494750023\n"
     ]
    }
   ],
   "source": [
    "model.eval() # eval mode\n",
    "\n",
    "predicted_labels = []\n",
    "for ii in range(seq_length_test):\n",
    "    mytest_input = testset3.iloc[ii]\n",
    "    mytest_input = torch.Tensor([[mytest_input.to_numpy()]])\n",
    "    out, hidden = model(mytest_input)\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    # Taking the class with the highest probability score from the output\n",
    "    prob_max = torch.max(prob).item()\n",
    "    print(prob_max)\n",
    "    pred_label = 1*(prob_max > 0.5)\n",
    "    predicted_labels.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a5f931f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328bbc1e",
   "metadata": {},
   "source": [
    "Note: since we only involved *age_imp_cat* in this baby RNN model, all patients in project J are poredicted to not have preterm with a very small p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27cdf83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant_id\n",
      "J00004    0.0\n",
      "J00007    0.0\n",
      "J00008    0.0\n",
      "J00010    0.0\n",
      "J00011    0.0\n",
      "         ... \n",
      "J00107    0.0\n",
      "J00108    0.0\n",
      "J00109    0.0\n",
      "J00111    0.0\n",
      "J00112    0.0\n",
      "Length: 79, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "testset2_wide_Y = testset2.pivot_table(index=['participant_id'], columns='collect_wk', values='was_preterm')\n",
    "# sort by collect_wk\n",
    "testset2_wide_Y = testset2_wide_Y.sort_index(axis=1)\n",
    "actual_labels = testset2_wide_Y.mean(axis=1)\n",
    "print(actual_labels.iloc[1:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ceef68b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8192771084337349"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create vectors for actual labels and predicted labels...\n",
    "my_accuracy = accuracy_score(actual_labels, predicted_labels, normalize=False) / float(actual_labels.size)\n",
    "my_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe0e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e733f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f744963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 1174, 1])\n",
      "torch.Size([42264, 2])\n"
     ]
    }
   ],
   "source": [
    "# Creating lists that will hold our input and target sequences\n",
    "input_seq = torch.Tensor([mydata2_wide_age.to_numpy()]).view(mydata2_wide_age.to_numpy().shape[1],-1,1)\n",
    "target_seq = torch.Tensor([np.vstack((mydata2_wide_Y.to_numpy().flatten(),\n",
    "                                    1-mydata2_wide_Y.to_numpy().flatten())).T]).view(-1,2)\n",
    "\n",
    "print(input_seq.shape)\n",
    "print(target_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4e2c6b",
   "metadata": {},
   "source": [
    "### GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fac9de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GRU model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers = 1,drop_prob=0.2):\n",
    "        \n",
    "        \"\"\"\n",
    "            parameters:\n",
    "                input_dim: dimensions of input data (# features)\n",
    "                hidden_dim: dimensions of hidden layer\n",
    "                output_dim: dimensions of output layer (should be two in our analysis)\n",
    "                n_layers: number of layers for GRU structure, default is 1, 2 means stacked GRU\n",
    "                drop_prob: dropout probability\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        #inherit from super class\n",
    "        super(GRUModel, self).__init__()\n",
    "        \n",
    "        #define parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #define layers\n",
    "        \n",
    "        ##GRU layers\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, dropout=drop_prob)\n",
    "        \n",
    "        ##fully connected layer(use one linear layer first, later can customize)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(1)\n",
    "\n",
    "        #Initializing hidden state\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        out, hidden = self.gru(x, hidden)\n",
    "        \n",
    "        print(out.shape)\n",
    "        \n",
    "        #pass out to fully connected layer\n",
    "        out = self.fc(out.reshape(-1,out.shape[-1]))\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros((self.n_layers,batch_size, self.hidden_dim), device = device)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "066dae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "        parameters:\n",
    "            input_dim: dimensions of input data (# features)\n",
    "            hidden_dim: dimensions of hidden layer\n",
    "            output_dim: dimensions of output layer (should be two in our analysis)\n",
    "            n_layers: number of layers for GRU structure, default is 1, 2 means stacked GRU\n",
    "            drop_prob: dropout probability\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers = 1, drop_prob=0.2):\n",
    "        \n",
    "        #inherit from super class\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        #define parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #define layers\n",
    "        \n",
    "        ##LSTM layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, dropout=drop_prob)\n",
    "        \n",
    "        ##fully connected layer(use one linear layer first, later can customize)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(1)\n",
    "\n",
    "        #Initializing hidden state\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        #pass out to fully connected layer\n",
    "        out = self.fc(out.reshape(-1,out.shape[-1]))\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros((self.n_layers,batch_size, self.hidden_dim),device = device),\n",
    "                torch.zeros((self.n_layers,batch_size, self.hidden_dim),device = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "917adf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train function\n",
    "\n",
    "\n",
    "def train_epoch(X_train, y_train, hidden_dim, learn_rate, device, EPOCHS,output_dim = 2, method = \"GRU\"):\n",
    "    \n",
    "    input_dim = X_train.shape[2]\n",
    "    \n",
    "    print(input_dim)\n",
    "    \n",
    "    \n",
    "    if method == \"GRU\":\n",
    "        model = GRUModel(input_dim, hidden_dim, output_dim)\n",
    "    elif method == \"LSTM\":\n",
    "        model = LSTMModel(input_dim, hidden_dim, output_dim)\n",
    "        \n",
    "    model.to(device)\n",
    "    \n",
    "    # loss criterion and optimizer\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learn_rate)\n",
    "\n",
    "    \n",
    "    # train model\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    print('Starting training of {} model'.format(method))\n",
    "    \n",
    "\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    \n",
    "    #Start training loop\n",
    "    \n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        \n",
    "        \n",
    "        # Clears existing gradients from previous epoch\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        predictions = model(X_train)[0]\n",
    "        \n",
    "        predictions = predictions.to(device)\n",
    "        \n",
    "        loss = criterion(predictions, y_train)\n",
    "        # backpropagation\n",
    "        loss.backward() \n",
    "        # Updates the weights accordingly\n",
    "        optimizer.step()\n",
    "    \n",
    "        if epoch%10 == 0:\n",
    "            print('Epoch: {}/{}.............'.format(epoch, EPOCHS), end=' ')\n",
    "            print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4786fce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Starting training of GRU model\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "Epoch: 10/100............. Loss: 0.6407\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "Epoch: 20/100............. Loss: 0.6300\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "Epoch: 30/100............. Loss: 0.6017\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "Epoch: 40/100............. Loss: 0.5855\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "Epoch: 50/100............. Loss: 0.5829\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "Epoch: 60/100............. Loss: 0.5812\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "Epoch: 70/100............. Loss: 0.5793\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "Epoch: 80/100............. Loss: 0.5774\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "Epoch: 90/100............. Loss: 0.5749\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "torch.Size([36, 1174, 12])\n",
      "Epoch: 100/100............. Loss: 0.5718\n"
     ]
    }
   ],
   "source": [
    "GRU_model = train_epoch(X_train = input_seq, y_train = target_seq, hidden_dim = 12, learn_rate = 0.01, device = device, EPOCHS = 100, output_dim = 2, method = \"GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e5abe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Starting training of LSTM model\n",
      "Epoch: 10/100............. Loss: 0.6440\n",
      "Epoch: 20/100............. Loss: 0.6393\n",
      "Epoch: 30/100............. Loss: 0.6159\n",
      "Epoch: 40/100............. Loss: 0.5922\n",
      "Epoch: 50/100............. Loss: 0.5811\n",
      "Epoch: 60/100............. Loss: 0.5748\n",
      "Epoch: 70/100............. Loss: 0.5710\n",
      "Epoch: 80/100............. Loss: 0.5649\n",
      "Epoch: 90/100............. Loss: 0.5587\n",
      "Epoch: 100/100............. Loss: 0.5545\n"
     ]
    }
   ],
   "source": [
    "LSTM_model = train_epoch(X_train = input_seq, y_train = target_seq, hidden_dim = 12, learn_rate = 0.01, device = device, EPOCHS = 100, output_dim = 2, method = \"LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d496fd1",
   "metadata": {},
   "source": [
    "Questions to discuss:\n",
    "\n",
    "1. How many outputs are we expected? I think per my reading, there should be one output for each timepoint. In our case, there should be a preterm/non-preterm outcome at each timepoint right? In the literatures I read these days, I found most of the usage of RNN or modified RNN was in text prediction or longitudinal prediction, where there were different outcomes at each timepoint(or sequence position), but our outcome was kind of static. I was wondering if RNN would work for static outcome. \n",
    "\n",
    "\n",
    "2. After checking Mo's code and pytorch RNN tutorial(GRU and LSTM are similar to RNN), the input data should be in the shape of (N,L,H), where N is the batch size, L is sequence length(time point) and H is the dimension of input features. They should be 1174, 36 and 1 in our toy example with only age, but Mo's input shape is (1,1174,36), which confused me, but it seemed to work as well. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dream_dl",
   "language": "python",
   "name": "dream_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
