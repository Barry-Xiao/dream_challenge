{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2bc8a93",
   "metadata": {},
   "source": [
    "# Start from simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eed8c91",
   "metadata": {},
   "source": [
    "Zero padding requires:\n",
    "- 0 only represent the position holder (missing value in our case);\n",
    "- The none zero values (observed) usually have at least 10% out of all observations;\n",
    "\n",
    "Convert all 36 weeks into 5 different collection periods and taking the within period mean of each covariates (both time varying and not-varying)\n",
    "- Largely reduce the number of padded zeros;\n",
    "- Solves the issues that there are multiple collections in the same week;\n",
    "- Maybe no need to do the label smoothing since only 4 or 5 labels per patient;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "27987cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sklearn as sk\n",
    "\n",
    "# from torch.autograd import Variable \n",
    "\n",
    "from itertools import islice\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from collections import Counter,defaultdict, OrderedDict\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1cae79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e107ba1",
   "metadata": {},
   "source": [
    "# 1. Read-in & clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6972a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directory\n",
    "# alpha_dir     = '/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/training_data_2022-05-27/alpha_diversity/alpha_diversity.csv'\n",
    "# cst_dir       = '/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/training_data_2022-05-27/community_state_types/cst_valencia.csv'\n",
    "meta_dir      = '/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/metadata_imputed1.csv'\n",
    "# krdlong_dir   = '/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/training_data_2022-05-27/pairwise_distance/krd_distance_long.csv'\n",
    "# krdwide_dir   = '/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/training_data_2022-05-27/pairwise_distance/krd_distance_wide.csv'\n",
    "phylotype_dir = '/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/training_data_2022-05-27/phylotypes/phylotype_relabd.1e0.csv'\n",
    "taxonomy_dir  = '/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/training_data_2022-05-27/taxonomy/taxonomy_relabd.family.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf2433",
   "metadata": {},
   "source": [
    "## Meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf013453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3578, 6)\n",
      "1268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_53312/973294587.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meta_data['collect_period'][(meta_data['collect_wk']>=9)  & (meta_data['collect_wk']<=16)] = 2\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_53312/973294587.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meta_data['collect_period'][(meta_data['collect_wk']>=17) & (meta_data['collect_wk']<=24)] = 3\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_53312/973294587.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meta_data['collect_period'][(meta_data['collect_wk']>=25) & (meta_data['collect_wk']<=32)] = 4\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_53312/973294587.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meta_data['collect_period'][(meta_data['collect_wk']>32)]                                  = 5\n"
     ]
    }
   ],
   "source": [
    "meta_data = pd.DataFrame(pd.read_csv(meta_dir, delimiter=','))\n",
    "meta_data = meta_data[['participant_id', 'project', 'delivery_wk', 'collect_wk', 'age_imp', 'race_imp']]\n",
    "\n",
    "print(meta_data.shape)\n",
    "\n",
    "for i in range(1,meta_data.shape[1]):\n",
    "    if meta_data.iloc[:,i].dtypes == object:\n",
    "        meta_data.iloc[:,i] = meta_data.iloc[:,i].astype('category').cat.codes + 1\n",
    "        meta_data.iloc[:,i] = meta_data.iloc[:,i].astype('float64')\n",
    "\n",
    "# create new variable collection period\n",
    "meta_data['collect_period'] = 1\n",
    "meta_data['collect_period'][(meta_data['collect_wk']>=9)  & (meta_data['collect_wk']<=16)] = 2\n",
    "meta_data['collect_period'][(meta_data['collect_wk']>=17) & (meta_data['collect_wk']<=24)] = 3\n",
    "meta_data['collect_period'][(meta_data['collect_wk']>=25) & (meta_data['collect_wk']<=32)] = 4\n",
    "meta_data['collect_period'][(meta_data['collect_wk']>32)]                                  = 5\n",
    "\n",
    "collect_period = meta_data['collect_period']\n",
    "participant_id = meta_data['participant_id']\n",
    "\n",
    "# create class label\n",
    "meta_data['was_preterm'] = 1*(meta_data['delivery_wk'] < 37)\n",
    "meta_data['was_early_preterm'] = 1*(meta_data['delivery_wk'] < 32)\n",
    "\n",
    "# number of patient\n",
    "unique, counts = np.unique(meta_data['participant_id'], return_counts=True)\n",
    "print(len(unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96b3879",
   "metadata": {},
   "source": [
    "- Filtered out observations with collect_wk<=32;\n",
    "- Average within each collection period;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3259c5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 9)\n"
     ]
    }
   ],
   "source": [
    "# Filtered out observations with \"collect_wk<=32\" == \"collect_period<=4\" \n",
    "meta_data = meta_data[meta_data['collect_period']<=4]\n",
    "# Average within each collection period\n",
    "meta_data = meta_data.groupby(['participant_id', 'collect_period'], as_index = False).mean()\n",
    "print(meta_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c0f86",
   "metadata": {},
   "source": [
    "## Taxonomy OTU (RA) data (Family level)\n",
    "- Filtered out observations with collect_wk<=32;\n",
    "- Average within each collection period;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18479c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 527)\n"
     ]
    }
   ],
   "source": [
    "taxonomy_data = pd.DataFrame(pd.read_csv(taxonomy_dir, delimiter=','))\n",
    "taxonomy_data = pd.concat([participant_id, collect_period, taxonomy_data], axis=1)\n",
    "\n",
    "# Filtered out observations with \"collect_wk<=32\" == \"collect_period<=4\" \n",
    "taxonomy_data = taxonomy_data[taxonomy_data['collect_period']<=4]\n",
    "# Average within each collection period\n",
    "taxonomy_data = taxonomy_data.groupby(['participant_id', 'collect_period'], as_index = False).mean()\n",
    "print(taxonomy_data.shape)\n",
    "\n",
    "# # delete the temporary filter-used and ID columns\n",
    "# taxonomy_data = taxonomy_data.drop([\"participant_id\", \"collect_period\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e4e85",
   "metadata": {},
   "source": [
    "## Phylotype data\n",
    "- Filtered out observations with collect_wk<=32;\n",
    "- Average within each collection period;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb76c497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 1846)\n"
     ]
    }
   ],
   "source": [
    "phylotype_data = pd.DataFrame(pd.read_csv(phylotype_dir, delimiter=','))\n",
    "phylotype_data = pd.concat([participant_id, collect_period, phylotype_data], axis=1)\n",
    "\n",
    "# Filtered out observations with \"collect_wk<=32\" == \"collect_period<=4\" \n",
    "phylotype_data = phylotype_data[phylotype_data['collect_period']<=4]\n",
    "# Average within each collection period\n",
    "phylotype_data = phylotype_data.groupby(['participant_id', 'collect_period'], as_index = False).mean()\n",
    "print(phylotype_data.shape)\n",
    "\n",
    "# # delete the temporary filter-used and ID columns\n",
    "# phylotype_data = phylotype_data.drop([\"participant_id\", \"collect_period\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b052c",
   "metadata": {},
   "source": [
    "## Other Datasets (...)\n",
    "- Filtered out observations with collect_wk<=32;\n",
    "- Average within each collection period;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bdf0780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8786037a",
   "metadata": {},
   "source": [
    "## Dimension Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22c0489b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of subjects =  1214\n",
      "# of samples  =  1582\n",
      "# of taxonnomy features =  527\n",
      "# of phylotype features =  1846\n"
     ]
    }
   ],
   "source": [
    "uniquenames, counts = np.unique(meta_data[\"participant_id\"], return_counts=True)\n",
    "subjects = list(uniquenames)\n",
    "seq_max_len = max(counts)\n",
    "\n",
    "print(\"# of subjects = \", len(subjects))\n",
    "print(\"# of samples  = \", meta_data.shape[0])\n",
    "print(\"# of taxonnomy features = \", len(list(taxonomy_data)))\n",
    "print(\"# of phylotype features = \", len(list(phylotype_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e10bc",
   "metadata": {},
   "source": [
    "# 2. Data sets splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ecebd5",
   "metadata": {},
   "source": [
    "Since we have multiple datasets, we will use Index of subjects to guide training, validation and testing set spliter. Also note, Since there are different number of records for each patient, the dimension of train and testing data sets are not follow the proportion 0.8, but the patients will follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ca1396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_splitID(meta_data, subjects, prop, myseed):\n",
    "    \n",
    "    if myseed != None:\n",
    "        random.seed(myseed)\n",
    "        \n",
    "    numsubjects = len(subjects)\n",
    "\n",
    "    subjects_shuffle = random.sample(subjects, numsubjects)\n",
    "    \n",
    "    train_subjects = subjects_shuffle[0:(int(len(subjects)*prop[0])+1)] \n",
    "    valid_subjects = subjects_shuffle[(int(len(subjects)*prop[0])+2):(int(len(subjects)*(prop[0]+prop[1]))+1)]\n",
    "    test_subjects = subjects_shuffle[(int(len(subjects)*(prop[0]+prop[1]))+2):numsubjects]\n",
    "    \n",
    "    splitID_train = meta_data['participant_id'].isin(train_subjects)\n",
    "    splitID_valid = meta_data['participant_id'].isin(valid_subjects)\n",
    "    splitID_test = meta_data['participant_id'].isin(test_subjects)\n",
    "    \n",
    "    return splitID_train, splitID_valid, splitID_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd510be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1098, 9)\n",
      "(326, 9)\n",
      "(156, 9)\n",
      "(1098, 527)\n",
      "(326, 527)\n",
      "(156, 527)\n",
      "(1098, 1846)\n",
      "(326, 1846)\n",
      "(156, 1846)\n"
     ]
    }
   ],
   "source": [
    "# set myseed=None to have complete random state\n",
    "splitID_train, splitID_valid, splitID_test = dataset_splitID(meta_data, subjects, prop = [0.7, 0.2, 0.1], myseed=0)\n",
    "\n",
    "# apply to each data sets\n",
    "meta_data_train = meta_data[splitID_train]\n",
    "meta_data_valid = meta_data[splitID_valid]\n",
    "meta_data_test  = meta_data[splitID_test]\n",
    "\n",
    "print(meta_data_train.shape)\n",
    "print(meta_data_valid.shape)\n",
    "print(meta_data_test.shape)\n",
    "\n",
    "taxonomy_data_train = taxonomy_data[splitID_train]\n",
    "taxonomy_data_valid = taxonomy_data[splitID_valid]\n",
    "taxonomy_data_test  = taxonomy_data[splitID_test]\n",
    "\n",
    "print(taxonomy_data_train.shape)\n",
    "print(taxonomy_data_valid.shape)\n",
    "print(taxonomy_data_test.shape)\n",
    "\n",
    "phylotype_data_train = phylotype_data[splitID_train]\n",
    "phylotype_data_valid = phylotype_data[splitID_valid]\n",
    "phylotype_data_test  = phylotype_data[splitID_test]\n",
    "\n",
    "print(phylotype_data_train.shape)\n",
    "print(phylotype_data_valid.shape)\n",
    "print(phylotype_data_test.shape)\n",
    "\n",
    "# other data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4884f191",
   "metadata": {},
   "source": [
    "# 3. Data Reshaper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabf6326",
   "metadata": {},
   "source": [
    "## Reshape Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdae25e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Reshaper_Input(data, seq_length):\n",
    "    \n",
    "    numsubjects = len(np.unique(data['participant_id']))\n",
    "    myvary = list(data.columns.values)[2:data.shape[1]]\n",
    "    num_covariates = len(myvary)\n",
    "    \n",
    "    myinput = np.zeros((numsubjects, seq_length, num_covariates), dtype=np.float32)\n",
    "    for i in range(num_covariates):\n",
    "        data_wide = data.pivot_table(index=['participant_id'], columns='collect_period', values=myvary[i])\n",
    "        data_wide = data_wide.sort_index(axis=1)\n",
    "        data_wide = data_wide.fillna(0)\n",
    "        tmpindex = data_wide._get_numeric_data().columns.values - 1\n",
    "        tmpindex = tmpindex.tolist()\n",
    "        # time varying variables need to impute all and no records are denoted as 0\n",
    "        for j in range(numsubjects):\n",
    "                myinput[j,tmpindex,i] = data_wide.iloc[[j]]\n",
    "    return myinput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d19af1",
   "metadata": {},
   "source": [
    "**Warning**: *Longer running time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6a75910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(850, 4, 525)\n",
      "(242, 4, 525)\n",
      "(120, 4, 525)\n",
      "(850, 4, 1844)\n",
      "(242, 4, 1844)\n",
      "(120, 4, 1844)\n"
     ]
    }
   ],
   "source": [
    "taxonomytrain_input = Data_Reshaper_Input(data=taxonomy_data_train, seq_length=4)\n",
    "print(taxonomytrain_input.shape)\n",
    "taxonomyvalid_input = Data_Reshaper_Input(data=taxonomy_data_valid, seq_length=4)\n",
    "print(taxonomyvalid_input.shape)\n",
    "taxonomytest_input = Data_Reshaper_Input(data=taxonomy_data_test, seq_length=4)\n",
    "print(taxonomytest_input.shape)\n",
    "\n",
    "phylotypetrain_input = Data_Reshaper_Input(data=phylotype_data_train, seq_length=4)\n",
    "print(phylotypetrain_input.shape)\n",
    "phylotypevalid_input = Data_Reshaper_Input(data=phylotype_data_valid, seq_length=4)\n",
    "print(phylotypevalid_input.shape)\n",
    "phylotypetest_input = Data_Reshaper_Input(data=phylotype_data_test, seq_length=4)\n",
    "print(phylotypetest_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f969714a",
   "metadata": {},
   "source": [
    "## Reshape output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e63be",
   "metadata": {},
   "source": [
    "### 1). Data_Reshaper_Output_ManytoMany_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad47f9b",
   "metadata": {},
   "source": [
    "- reshape patients class labels from long to wide form;\n",
    "- output array formulation, **one** columns;\n",
    "- Label smoothing;\n",
    "    - was_preterm: 0.5, 0.67, 0.83, 1;\n",
    "    - not was_preterm: 0.5, 0.33, 0.17, 0;\n",
    "    - no missing values;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "94f2e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Reshaper_Output_ManytoMany_0(data, seq_length, classlabel):\n",
    "\n",
    "    num_samples = len(np.unique(data['participant_id']))\n",
    "    \n",
    "    data_wide = data.pivot_table(index=['participant_id'], columns='collect_period', values=classlabel)\n",
    "    data_wide = data_wide.sort_index(axis=1)\n",
    "    \n",
    "    myoutput = np.zeros((num_samples, seq_length, 1), dtype=np.float32)\n",
    "    for i in range(num_samples):\n",
    "        tmp = data_wide.iloc[i,:]\n",
    "        \n",
    "        if np.nanmax(tmp) == 1:\n",
    "            # label linear smoonthing from 0.5 to 1\n",
    "            # fill all position 1 to have final labels equal to 1\n",
    "            myoutput[i,:,0].fill(1)\n",
    "            myoutput[i,:,0] = np.linspace(start=0.5, stop=1, num=seq_length)\n",
    "        else:\n",
    "            # label linear smoonthing from 0.5 to 0\n",
    "            # fill all position 0 to have final labels equal to 0 \n",
    "            #     but array alrady initialize as 0\n",
    "            myoutput[i,:,0] = np.linspace(start=0.5, stop=0, num=seq_length)\n",
    "            \n",
    "    return myoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "677cfb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(850, 4, 1)\n",
      "[[0.5       ]\n",
      " [0.33333334]\n",
      " [0.16666667]\n",
      " [0.        ]]\n",
      "(242, 4, 1)\n",
      "[[0.5      ]\n",
      " [0.6666667]\n",
      " [0.8333333]\n",
      " [1.       ]]\n",
      "(120, 4, 1)\n",
      "[[0.5      ]\n",
      " [0.6666667]\n",
      " [0.8333333]\n",
      " [1.       ]]\n"
     ]
    }
   ],
   "source": [
    "mytrain_output_0 = Data_Reshaper_Output_ManytoMany_0(data=meta_data_train, seq_length=4, classlabel=\"was_preterm\")\n",
    "print(mytrain_output_0.shape)\n",
    "print(mytrain_output_0[2])\n",
    "\n",
    "myvalid_output_0 = Data_Reshaper_Output_ManytoMany_0(data=meta_data_valid, seq_length=4, classlabel=\"was_preterm\")\n",
    "print(myvalid_output_0.shape)\n",
    "print(myvalid_output_0[4])\n",
    "\n",
    "mytest_output_0 = Data_Reshaper_Output_ManytoMany_0(data=meta_data_test, seq_length=4, classlabel=\"was_preterm\")\n",
    "print(mytest_output_0.shape)\n",
    "print(mytest_output_0[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2823f8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>collect_period</th>\n",
       "      <th>project</th>\n",
       "      <th>delivery_wk</th>\n",
       "      <th>collect_wk</th>\n",
       "      <th>age_imp</th>\n",
       "      <th>race_imp</th>\n",
       "      <th>was_preterm</th>\n",
       "      <th>was_early_preterm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00003</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00004</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00005</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00006</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00008</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>J00111</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>J00112</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>J00113</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>J00115</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>J00116</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1098 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant_id  collect_period  project  delivery_wk  collect_wk  \\\n",
       "0            A00003               4      1.0         40.0   30.000000   \n",
       "1            A00004               4      1.0         40.0   28.666667   \n",
       "2            A00005               4      1.0         41.0   27.500000   \n",
       "3            A00006               4      1.0         41.0   31.000000   \n",
       "4            A00008               3      1.0         35.0   17.000000   \n",
       "...             ...             ...      ...          ...         ...   \n",
       "1577         J00111               3     10.0         40.0   17.000000   \n",
       "1578         J00112               3     10.0         39.0   19.000000   \n",
       "1579         J00113               2     10.0         41.0   16.000000   \n",
       "1580         J00115               3     10.0         42.0   18.000000   \n",
       "1581         J00116               3     10.0         40.0   17.000000   \n",
       "\n",
       "      age_imp  race_imp  was_preterm  was_early_preterm  \n",
       "0        32.0       2.0          0.0                0.0  \n",
       "1        25.0       5.0          0.0                0.0  \n",
       "2        31.0       5.0          0.0                0.0  \n",
       "3        28.0       5.0          0.0                0.0  \n",
       "4        38.0       5.0          1.0                0.0  \n",
       "...       ...       ...          ...                ...  \n",
       "1577     27.0       5.0          0.0                0.0  \n",
       "1578     27.0       5.0          0.0                0.0  \n",
       "1579     32.0       5.0          0.0                0.0  \n",
       "1580     35.0       5.0          0.0                0.0  \n",
       "1581     26.0       5.0          0.0                0.0  \n",
       "\n",
       "[1098 rows x 9 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaf9b56",
   "metadata": {},
   "source": [
    "### 2). Data_Reshaper_Output_ManytoMany_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d61d22",
   "metadata": {},
   "source": [
    "- reshape patients class labels from long to wide form\n",
    "- output array formulation, **two** columns, \n",
    "    - (0,0) indicating missing values;\n",
    "    - (1,0) indicating preterm classes;\n",
    "    - (0,1) indicating not preterm classes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28e792d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Reshaper_Output_ManytoMany_1(data, seq_length, classlabel):\n",
    "    \n",
    "    num_samples = len(np.unique(data['participant_id']))\n",
    "\n",
    "    data_wide = data.pivot_table(index=['participant_id'], columns='collect_period', values=classlabel)\n",
    "    data_wide = data_wide.sort_index(axis=1)\n",
    "\n",
    "    myoutput = np.zeros((num_samples, seq_length, 2), dtype=np.float32)\n",
    "    myoutput[:,data_wide.columns.values-1,0] = data_wide\n",
    "    myoutput[:,data_wide.columns.values-1,1] = 1 - data_wide\n",
    "    myoutput[np.isnan(myoutput)] = 0\n",
    "    \n",
    "    return myoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a325b80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(850, 4, 2)\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 1.]]\n",
      "(242, 4, 2)\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]]\n",
      "(120, 4, 2)\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "mytrain_output_1 = Data_Reshaper_Output_ManytoMany_1(data=meta_data_train, seq_length=4, classlabel=\"was_preterm\")\n",
    "print(mytrain_output_1.shape)\n",
    "print(mytrain_output_1[2])\n",
    "\n",
    "myvalid_output_1 = Data_Reshaper_Output_ManytoMany_1(data=meta_data_valid, seq_length=4, classlabel=\"was_preterm\")\n",
    "print(myvalid_output_1.shape)\n",
    "print(myvalid_output_1[4])\n",
    "\n",
    "mytest_output_1 = Data_Reshaper_Output_ManytoMany_1(data=meta_data_test, seq_length=4, classlabel=\"was_preterm\")\n",
    "print(mytest_output_1.shape)\n",
    "print(mytest_output_1[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7790470d",
   "metadata": {},
   "source": [
    "### 3). Data_Reshaper_Output_ManytoMany"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69341b2",
   "metadata": {},
   "source": [
    "- reshape patients class labels from long to wide form\n",
    "- output array formulation, **one** column, \n",
    "    - 0 indicating missing values;\n",
    "    - 1 indicating preterm classes;\n",
    "    - 2 indicating not preterm classes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a71e498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Reshaper_Output_ManytoMany_2(data, seq_length, classlabel):\n",
    "    \n",
    "    num_samples = len(np.unique(data['participant_id']))\n",
    "    data_wide = data.pivot_table(index=['participant_id'], columns='collect_period', values=classlabel)\n",
    "    data_wide = data_wide.sort_index(axis=1)\n",
    "    \n",
    "    myoutput = np.zeros((num_samples, seq_length, 1), dtype=np.float32)\n",
    "    myoutput[:,data_wide.columns.values-1,0] = data_wide + 1\n",
    "    myoutput[np.isnan(myoutput)] = 0\n",
    "    \n",
    "    return myoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cc6657b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(850, 4, 1)\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "(242, 4, 1)\n",
      "[[0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "(120, 4, 1)\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "mytrain_output_2 = Data_Reshaper_Output_ManytoMany_2(data=meta_data_train, seq_length=4, classlabel=\"was_preterm\")\n",
    "print(mytrain_output_2.shape)\n",
    "print(mytrain_output_2[2])\n",
    "\n",
    "myvalid_output_2 = Data_Reshaper_Output_ManytoMany_2(data=meta_data_valid, seq_length=4, classlabel=\"was_preterm\")\n",
    "print(myvalid_output_2.shape)\n",
    "print(myvalid_output_2[4])\n",
    "\n",
    "mytest_output_2 = Data_Reshaper_Output_ManytoMany_2(data=meta_data_test, seq_length=4, classlabel=\"was_preterm\")\n",
    "print(mytest_output_2.shape)\n",
    "print(mytest_output_2[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97ccc9e",
   "metadata": {},
   "source": [
    "### 4). Data_Reshaper_Output_ManytoOne_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acddec8",
   "metadata": {},
   "source": [
    "- reshape patients class labels from long to wide form\n",
    "- output array formulation, each subject has **one** label, \n",
    "    - Then No missing values;\n",
    "    - 0 indicating preterm classes;\n",
    "    - 1 indicating not preterm classes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "264c007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Reshaper_Output_ManytoOne_1(data, classlabel):\n",
    "    num_samples = len(np.unique(data['participant_id']))\n",
    "    data_wide = data.pivot_table(index=['participant_id'], columns='collect_period', values=classlabel)\n",
    "    data_wide = data_wide.sort_index(axis=1)\n",
    "\n",
    "    myoutput = np.zeros((num_samples, 1, 1), dtype=np.float32)\n",
    "    myoutput[:,0,0] = data_wide.max(axis=1)\n",
    "    return myoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a5f3fb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(850, 1, 1)\n",
      "[[0.]]\n",
      "(242, 1, 1)\n",
      "[[1.]]\n",
      "(120, 1, 1)\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "mytrain_output_3 = Data_Reshaper_Output_ManytoOne_1(data=meta_data_train, classlabel=\"was_preterm\")\n",
    "print(mytrain_output_3.shape)\n",
    "print(mytrain_output_3[2])\n",
    "\n",
    "myvalid_output_3 = Data_Reshaper_Output_ManytoOne_1(data=meta_data_valid, classlabel=\"was_preterm\")\n",
    "print(myvalid_output_3.shape)\n",
    "print(myvalid_output_3[4])\n",
    "\n",
    "mytest_output_3 = Data_Reshaper_Output_ManytoOne_1(data=meta_data_test, classlabel=\"was_preterm\")\n",
    "print(mytest_output_3.shape)\n",
    "print(mytest_output_3[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
