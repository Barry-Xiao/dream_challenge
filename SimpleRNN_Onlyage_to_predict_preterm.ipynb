{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14fc022b",
   "metadata": {},
   "source": [
    "Install Pytorch package (need to specify the version to get correctly installed. Possible error will lead died kernal.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8dcb538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f0fb9d",
   "metadata": {},
   "source": [
    "The RNN model with PyTorch will be implemented on the Metadata only to farmiliarize myself with the PyTorch library and get starts with RNN. First of all, we need to treat each patient as an observation and get every "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8b25ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43329a84",
   "metadata": {},
   "source": [
    "A better explanation about the RNN example https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b461620",
   "metadata": {},
   "source": [
    "Read in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7299f00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>project</th>\n",
       "      <th>specimen</th>\n",
       "      <th>was_term</th>\n",
       "      <th>delivery_wk</th>\n",
       "      <th>collect_wk</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>NIH.Racial.Category</th>\n",
       "      <th>NIH.Ethnicity.Category</th>\n",
       "      <th>was_preterm</th>\n",
       "      <th>was_early_preterm</th>\n",
       "      <th>collect_tri</th>\n",
       "      <th>age_imp</th>\n",
       "      <th>race_imp</th>\n",
       "      <th>age_imp_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00001</td>\n",
       "      <td>A</td>\n",
       "      <td>A00001-05</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>American Indian</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00002</td>\n",
       "      <td>A</td>\n",
       "      <td>A00002-01</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00003</td>\n",
       "      <td>A</td>\n",
       "      <td>A00003-02</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>Asian-Japanese</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>Asian</td>\n",
       "      <td>from_29_to_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00004</td>\n",
       "      <td>A</td>\n",
       "      <td>A00004-08</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00004</td>\n",
       "      <td>A</td>\n",
       "      <td>A00004-12</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>29</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>J00111</td>\n",
       "      <td>J</td>\n",
       "      <td>J00111-01</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>J00112</td>\n",
       "      <td>J</td>\n",
       "      <td>J00112-01</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3575</th>\n",
       "      <td>J00113</td>\n",
       "      <td>J</td>\n",
       "      <td>J00113-01</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>32</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>White</td>\n",
       "      <td>from_29_to_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576</th>\n",
       "      <td>J00115</td>\n",
       "      <td>J</td>\n",
       "      <td>J00115-01</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>35</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>White</td>\n",
       "      <td>from_29_to_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>J00116</td>\n",
       "      <td>J</td>\n",
       "      <td>J00116-01</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>26</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>White</td>\n",
       "      <td>from_18_to_28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3578 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant_id project   specimen  was_term  delivery_wk  collect_wk  \\\n",
       "0            A00001       A  A00001-05      True           38          33   \n",
       "1            A00002       A  A00002-01      True           40          38   \n",
       "2            A00003       A  A00003-02      True           40          30   \n",
       "3            A00004       A  A00004-08      True           40          27   \n",
       "4            A00004       A  A00004-12      True           40          29   \n",
       "...             ...     ...        ...       ...          ...         ...   \n",
       "3573         J00111       J  J00111-01      True           40          17   \n",
       "3574         J00112       J  J00112-01      True           39          19   \n",
       "3575         J00113       J  J00113-01      True           41          16   \n",
       "3576         J00115       J  J00115-01      True           42          18   \n",
       "3577         J00116       J  J00116-01      True           40          17   \n",
       "\n",
       "                 race      age               NIH.Racial.Category  \\\n",
       "0     American Indian  Unknown  American Indian or Alaska Native   \n",
       "1               White  Unknown                             White   \n",
       "2      Asian-Japanese  Unknown                             Asian   \n",
       "3               White  Unknown                             White   \n",
       "4               White  Unknown                             White   \n",
       "...               ...      ...                               ...   \n",
       "3573        Caucasian       27                             White   \n",
       "3574        Caucasian       27                             White   \n",
       "3575        Caucasian       32                             White   \n",
       "3576        Caucasian       35                             White   \n",
       "3577        Caucasian       26                             White   \n",
       "\n",
       "     NIH.Ethnicity.Category  was_preterm  was_early_preterm  collect_tri  \\\n",
       "0                   Unknown        False              False            3   \n",
       "1                   Unknown        False              False            3   \n",
       "2                   Unknown        False              False            3   \n",
       "3                   Unknown        False              False            3   \n",
       "4                   Unknown        False              False            3   \n",
       "...                     ...          ...                ...          ...   \n",
       "3573                Unknown        False              False            2   \n",
       "3574                Unknown        False              False            2   \n",
       "3575                Unknown        False              False            2   \n",
       "3576                Unknown        False              False            2   \n",
       "3577                Unknown        False              False            2   \n",
       "\n",
       "      age_imp                          race_imp    age_imp_cat  \n",
       "0          27  American Indian or Alaska Native  from_18_to_28  \n",
       "1          24                             White  from_18_to_28  \n",
       "2          32                             Asian  from_29_to_38  \n",
       "3          25                             White  from_18_to_28  \n",
       "4          25                             White  from_18_to_28  \n",
       "...       ...                               ...            ...  \n",
       "3573       27                             White  from_18_to_28  \n",
       "3574       27                             White  from_18_to_28  \n",
       "3575       32                             White  from_29_to_38  \n",
       "3576       35                             White  from_29_to_38  \n",
       "3577       26                             White  from_18_to_28  \n",
       "\n",
       "[3578 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata = pd.read_csv('/Users/mli171/Desktop/JHU/3Summer2022_JHU/DREAM/metadata_imputed.csv', delimiter=',')\n",
    "mydata = pd.DataFrame(mydata)\n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327d6668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_13597/1563144068.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"project\"] = mydata[\"project\"].astype('category')\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_13597/1563144068.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"race_imp\"] = mydata[\"race_imp\"].astype('category')\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_13597/1563144068.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"age_imp_cat\"] = mydata[\"age_imp_cat\"].astype('category')\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_13597/1563144068.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"project\"] = mydata[\"project\"].cat.codes\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_13597/1563144068.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"race_imp\"] = mydata[\"race_imp\"].cat.codes\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_13597/1563144068.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata[\"age_imp_cat\"] = mydata[\"age_imp_cat\"].cat.codes\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_13597/1563144068.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata['was_preterm'] = mydata['was_preterm'].astype('int8')\n",
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_13597/1563144068.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mydata['was_early_preterm'] = mydata['was_early_preterm'].astype('int8')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "participant_id       object\n",
       "project                int8\n",
       "specimen             object\n",
       "collect_wk            int64\n",
       "was_preterm            int8\n",
       "was_early_preterm      int8\n",
       "race_imp               int8\n",
       "age_imp_cat            int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata = mydata[[\"participant_id\", \"project\", \"specimen\", \"collect_wk\", \n",
    "                 \"was_preterm\", \"was_early_preterm\", \"race_imp\", \"age_imp_cat\" ]]\n",
    "mydata[\"project\"] = mydata[\"project\"].astype('category')\n",
    "mydata[\"race_imp\"] = mydata[\"race_imp\"].astype('category')\n",
    "mydata[\"age_imp_cat\"] = mydata[\"age_imp_cat\"].astype('category')\n",
    "\n",
    "mydata[\"project\"] = mydata[\"project\"].cat.codes\n",
    "mydata[\"race_imp\"] = mydata[\"race_imp\"].cat.codes\n",
    "mydata[\"age_imp_cat\"] = mydata[\"age_imp_cat\"].cat.codes\n",
    "mydata['was_preterm'] = mydata['was_preterm'].astype('int8')\n",
    "mydata['was_early_preterm'] = mydata['was_early_preterm'].astype('int8')\n",
    "mydata.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa51c19",
   "metadata": {},
   "source": [
    "We split the training and testing data set based on *project* J."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b1aabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata_train = mydata[mydata['project']!=9] # Not project J\n",
    "mydata_test  = mydata[mydata['project']==9] # project J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6adfa73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydata_train = mydata_train[[\"participant_id\", \"project\", \"specimen\", \"collect_wk\", \n",
    "#                              \"was_preterm\", \"was_early_preterm\", \"race_imp\", \"age_imp_cat\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1224ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydata1[\"project\"] = mydata1[\"project\"].astype('category')\n",
    "# mydata1[\"race_imp\"] = mydata1[\"race_imp\"].astype('category')\n",
    "# mydata1[\"age_imp_cat\"] = mydata1[\"age_imp_cat\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac97cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydata1[\"project\"] = mydata1[\"project\"].cat.codes\n",
    "# mydata1[\"race_imp\"] = mydata1[\"race_imp\"].cat.codes\n",
    "# mydata1[\"age_imp_cat\"] = mydata1[\"age_imp_cat\"].cat.codes\n",
    "# mydata1['was_preterm'] = mydata1['was_preterm'].astype('int8')\n",
    "# mydata1['was_early_preterm'] = mydata1['was_early_preterm'].astype('int8')\n",
    "# mydata1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca89d4e0",
   "metadata": {},
   "source": [
    "We want to predict the class of preterm birth and early preterm birth for few consecutive specimemns collected. We will have to define the\n",
    "\n",
    "- Input data (2 covariates)\n",
    "    - The meta data (imputed age and race category) for each observation\n",
    "- Output (1 covariate)\n",
    "    - The class label of preterm birth/early preterm birth\n",
    "    \n",
    "via data pre-processing and move the data from numpy arrays to Pytorch data structure - **Torch Tensors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1295b91",
   "metadata": {},
   "source": [
    "## Preterm birth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a11bad",
   "metadata": {},
   "source": [
    "Since the simple RNN only allow one covariates to enter the model, I choose *age_imp_cat* as a starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c4ef4",
   "metadata": {},
   "source": [
    "### Input data from categorical age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85722261",
   "metadata": {},
   "source": [
    "We need to do some data filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f98e4c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2417, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep the rows with collect_wk < 37 for Preterm task\n",
    "mydata1 = mydata_train.loc[mydata_train['collect_wk']<37,]\n",
    "\n",
    "# delete the duplicated samples in the same collection week\n",
    "mydata2 = mydata1.drop_duplicates(subset=['participant_id', 'collect_wk'], keep='first')\n",
    "mydata2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ca36a",
   "metadata": {},
   "source": [
    "Note: Too much samples are deleted, we need to take care of this situation. For metadata table, its OK since the information of duplicates are exactly same. But it will be specimen specific for taxonomy, phylotypes and distance data sets. **We need to discuss it**. We need to either form up some summary statistic for multiple collected sample in the same week or other methods (???)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6843c2e",
   "metadata": {},
   "source": [
    "Since we will give a patient the label of preterm birth as the delievey week < 37, we have 36 as one of the dimension for the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68aadc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of collect_wk       1    2    3    4    5    6    7    8    9    10  ...   27  \\\n",
       "participant_id                                                    ...        \n",
       "A00001          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00003          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00004          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  2.0   \n",
       "A00005          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00006          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "I00534          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "I00535          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "I00536          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "I00537          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "I00538          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "collect_wk       28   29   30   31   32   33   34   35   36  \n",
       "participant_id                                               \n",
       "A00001          0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0  \n",
       "A00003          0.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "A00004          0.0  2.0  2.0  0.0  0.0  2.0  0.0  2.0  0.0  \n",
       "A00005          0.0  3.0  0.0  0.0  0.0  0.0  0.0  3.0  3.0  \n",
       "A00006          0.0  0.0  0.0  2.0  0.0  2.0  0.0  0.0  0.0  \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "I00534          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "I00535          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "I00536          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "I00537          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "I00538          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1174 rows x 36 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata2_wide_age = mydata2.pivot_table(index=['participant_id'], columns='collect_wk', values='age_imp_cat')\n",
    "# sort by collect_wk\n",
    "mydata2_wide_age = mydata2_wide_age.sort_index(axis=1)\n",
    "mydata2_wide_age = mydata2_wide_age.fillna(0)\n",
    "mydata2_wide_age.shape\n",
    "mydata2_wide_age.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b888bd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1174\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "(seq_length, num_feature) = mydata2_wide_age.shape\n",
    "print(seq_length)\n",
    "print(num_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e69b9",
   "metadata": {},
   "source": [
    "### Output data from Preterm birth label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55944bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>collect_wk</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A00001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A00006</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C00026</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C00027</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C00028</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C00029</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C00030</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "collect_wk       1    2    3    4    5    6    7    8    9    10  ...   27  \\\n",
       "participant_id                                                    ...        \n",
       "A00001          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00003          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00004          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00005          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "A00006          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "C00026          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0   \n",
       "C00027          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0   \n",
       "C00028          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0   \n",
       "C00029          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0   \n",
       "C00030          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0   \n",
       "\n",
       "collect_wk       28   29   30   31   32   33   34   35   36  \n",
       "participant_id                                               \n",
       "A00001          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "A00003          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "A00004          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "A00005          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "A00006          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "C00026          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "C00027          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "C00028          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "C00029          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "C00030          1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "\n",
       "[100 rows x 36 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata2_wide_Y = mydata2.pivot_table(index=['participant_id'], columns='collect_wk', values='was_preterm')\n",
    "# sort by collect_wk\n",
    "mydata2_wide_Y = mydata2_wide_Y.sort_index(axis=1)\n",
    "mydata2_wide_Y = mydata2_wide_Y.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "mydata2_wide_Y.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbd00600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/ccg9zpjj4sq_l6d6fypc_5740000gn/T/ipykernel_13597/1327531968.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/distiller/project/pytorch/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  input_seq = torch.Tensor([mydata2_wide_age.to_numpy()])\n"
     ]
    }
   ],
   "source": [
    "# Creating lists that will hold our input and target sequences\n",
    "input_seq = torch.Tensor([mydata2_wide_age.to_numpy()])\n",
    "target_seq = torch.Tensor([mydata2_wide_Y.to_numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e3d8b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1174, 36])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "868976ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1174, 36])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab1a8060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "301a270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True, nonlinearity='relu')   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7825a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model(input_size=num_feature, output_size=num_feature, hidden_dim=12, n_layers=3)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a958829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100............. Loss: 44.2118\n",
      "Epoch: 20/100............. Loss: 44.1784\n",
      "Epoch: 30/100............. Loss: 44.1764\n",
      "Epoch: 40/100............. Loss: 44.1753\n",
      "Epoch: 50/100............. Loss: 44.1747\n",
      "Epoch: 60/100............. Loss: 44.1745\n",
      "Epoch: 70/100............. Loss: 44.1744\n",
      "Epoch: 80/100............. Loss: 44.1744\n",
      "Epoch: 90/100............. Loss: 44.1744\n",
      "Epoch: 100/100............. Loss: 44.1744\n"
     ]
    }
   ],
   "source": [
    "# Training Run\n",
    "input_seq = input_seq.to(device)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    #input_seq = input_seq.to(device)\n",
    "    output, hidden = model(input_seq)\n",
    "    output = output.to(device)\n",
    "    target_seq = target_seq.to(device)\n",
    "    loss = criterion(output, target_seq.view(-1, num_feature))\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fdbad9",
   "metadata": {},
   "source": [
    "### Apply the simple RNN on testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "806f84fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant_id       object\n",
      "project                int8\n",
      "specimen             object\n",
      "collect_wk            int64\n",
      "was_preterm            int8\n",
      "was_early_preterm      int8\n",
      "race_imp               int8\n",
      "age_imp_cat            int8\n",
      "dtype: object\n",
      "(83, 8)\n"
     ]
    }
   ],
   "source": [
    "testset = mydata_test[[\"participant_id\", \"project\", \"specimen\", \"collect_wk\", \n",
    "                       \"was_preterm\", \"was_early_preterm\", \"race_imp\", \"age_imp_cat\" ]]\n",
    "print(testset.dtypes)\n",
    "print(testset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9b91e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep the rows with collect_wk < 37 for Preterm task\n",
    "testset1 = testset.loc[testset['collect_wk']<37,]\n",
    "\n",
    "# delete the duplicated samples in the same collection week\n",
    "testset2 = testset1.drop_duplicates(subset=['participant_id', 'collect_wk'], keep='first')\n",
    "testset2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b305c080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of collect_wk       12   13   14   15   16   17   18   19\n",
       "participant_id                                        \n",
       "J00001          0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0\n",
       "J00004          0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0\n",
       "J00007          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "J00008          0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0\n",
       "J00010          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...\n",
       "J00111          0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0\n",
       "J00112          0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0\n",
       "J00113          0.0  0.0  0.0  0.0  3.0  0.0  0.0  0.0\n",
       "J00115          0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0\n",
       "J00116          0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0\n",
       "\n",
       "[83 rows x 8 columns]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset2_wide_age = testset2.pivot_table(index=['participant_id'], columns='collect_wk', values='age_imp_cat')\n",
    "# sort by collect_wk\n",
    "testset2_wide_age = testset2_wide_age.sort_index(axis=1)\n",
    "testset2_wide_age = testset2_wide_age.fillna(0)\n",
    "testset2_wide_age.shape\n",
    "testset2_wide_age.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edb25d",
   "metadata": {},
   "source": [
    "Fill-in zeros for empty collection weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4de0833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(seq_length_test, num_feature_test) = testset2_wide_age.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64b0b3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 36)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     0.0\n",
       "4     0.0\n",
       "5     0.0\n",
       "6     0.0\n",
       "7     0.0\n",
       "8     0.0\n",
       "9     0.0\n",
       "10    0.0\n",
       "11    0.0\n",
       "12    0.0\n",
       "13    0.0\n",
       "14    0.0\n",
       "15    0.0\n",
       "16    0.0\n",
       "17    0.0\n",
       "18    3.0\n",
       "19    0.0\n",
       "20    0.0\n",
       "21    0.0\n",
       "22    0.0\n",
       "23    0.0\n",
       "24    0.0\n",
       "25    0.0\n",
       "26    0.0\n",
       "27    0.0\n",
       "28    0.0\n",
       "29    0.0\n",
       "30    0.0\n",
       "31    0.0\n",
       "32    0.0\n",
       "33    0.0\n",
       "34    0.0\n",
       "35    0.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset3 = pd.DataFrame(np.nan, index=range(seq_length_test), columns=range(num_feature))\n",
    "testset3 = testset3.rename(columns={x:y for x,y in zip(testset3.columns,range(0,num_feature))})\n",
    "testset3 = testset3.fillna(0)\n",
    "print(testset3.shape)\n",
    "test_index = testset2_wide_age._get_numeric_data().columns.values.tolist()\n",
    "testset3.iloc[:,test_index] = testset2_wide_age\n",
    "\n",
    "# check: first observation in testing set has value 3.0 at column 19 (index 18)\n",
    "testset3.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37b6e7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 36])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii = 0\n",
    "mytest_input = testset3.iloc[ii]\n",
    "mytest_input = torch.Tensor([[mytest_input.to_numpy()]])\n",
    "mytest_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c0d3775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0284)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval() # eval mode\n",
    "out, hidden = model(mytest_input)\n",
    "prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "# Taking the class with the highest probability score from the output\n",
    "prob_max = torch.max(prob)\n",
    "print(prob_max)\n",
    "pred_label = 1*(prob_max > 0.5)\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a6ea0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028367556631565094\n",
      "0.02836424857378006\n",
      "0.028406862169504166\n",
      "0.028367556631565094\n",
      "0.028406862169504166\n",
      "0.028377937152981758\n",
      "0.028367556631565094\n",
      "0.028425009921193123\n",
      "0.028425851836800575\n",
      "0.028354018926620483\n",
      "0.028406862169504166\n",
      "0.028427284210920334\n",
      "0.028406862169504166\n",
      "0.028377937152981758\n",
      "0.028377937152981758\n",
      "0.028367556631565094\n",
      "0.028406862169504166\n",
      "0.028354018926620483\n",
      "0.028406862169504166\n",
      "0.028377937152981758\n",
      "0.028406862169504166\n",
      "0.028425851836800575\n",
      "0.028425009921193123\n",
      "0.028425009921193123\n",
      "0.028425009921193123\n",
      "0.028425009921193123\n",
      "0.028354018926620483\n",
      "0.028406862169504166\n",
      "0.028377937152981758\n",
      "0.028377937152981758\n",
      "0.028377937152981758\n",
      "0.028354018926620483\n",
      "0.02838703617453575\n",
      "0.028367556631565094\n",
      "0.028377937152981758\n",
      "0.028354018926620483\n",
      "0.028377937152981758\n",
      "0.028386743739247322\n",
      "0.028354018926620483\n",
      "0.028377937152981758\n",
      "0.028364913538098335\n",
      "0.02836424857378006\n",
      "0.028377937152981758\n",
      "0.028377937152981758\n",
      "0.028381386771798134\n",
      "0.028377937152981758\n",
      "0.02836424857378006\n",
      "0.02840493805706501\n",
      "0.028406862169504166\n",
      "0.028386743739247322\n",
      "0.028354018926620483\n",
      "0.028377937152981758\n",
      "0.028354018926620483\n",
      "0.028333254158496857\n",
      "0.028377937152981758\n",
      "0.028377937152981758\n",
      "0.028406862169504166\n",
      "0.028406862169504166\n",
      "0.028377937152981758\n",
      "0.028354018926620483\n",
      "0.028354018926620483\n",
      "0.028427284210920334\n",
      "0.028354018926620483\n",
      "0.028406862169504166\n",
      "0.028377937152981758\n",
      "0.02838703617453575\n",
      "0.028354018926620483\n",
      "0.028354018926620483\n",
      "0.028367556631565094\n",
      "0.028406862169504166\n",
      "0.028354018926620483\n",
      "0.02836424857378006\n",
      "0.028406862169504166\n",
      "0.028381386771798134\n",
      "0.028367556631565094\n",
      "0.028406862169504166\n",
      "0.028377937152981758\n",
      "0.028354018926620483\n",
      "0.02836424857378006\n",
      "0.02840493805706501\n",
      "0.028377937152981758\n",
      "0.028367556631565094\n",
      "0.02836424857378006\n"
     ]
    }
   ],
   "source": [
    "model.eval() # eval mode\n",
    "\n",
    "predicted_labels = []\n",
    "for ii in range(seq_length_test):\n",
    "    mytest_input = testset3.iloc[ii]\n",
    "    mytest_input = torch.Tensor([[mytest_input.to_numpy()]])\n",
    "    out, hidden = model(mytest_input)\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    # Taking the class with the highest probability score from the output\n",
    "    prob_max = torch.max(prob).item()\n",
    "    print(prob_max)\n",
    "    pred_label = 1*(prob_max > 0.5)\n",
    "    predicted_labels.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a5f931f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328bbc1e",
   "metadata": {},
   "source": [
    "Note: since we only involved *age_imp_cat* in this baby RNN model, all patients in project J are poredicted to not have preterm with a very small p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27cdf83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant_id\n",
      "J00004    0.0\n",
      "J00007    0.0\n",
      "J00008    0.0\n",
      "J00010    0.0\n",
      "J00011    0.0\n",
      "         ... \n",
      "J00107    0.0\n",
      "J00108    0.0\n",
      "J00109    0.0\n",
      "J00111    0.0\n",
      "J00112    0.0\n",
      "Length: 79, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "testset2_wide_Y = testset2.pivot_table(index=['participant_id'], columns='collect_wk', values='was_preterm')\n",
    "# sort by collect_wk\n",
    "testset2_wide_Y = testset2_wide_Y.sort_index(axis=1)\n",
    "actual_labels = testset2_wide_Y.mean(axis=1)\n",
    "print(actual_labels.iloc[1:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ceef68b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8192771084337349"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create vectors for actual labels and predicted labels...\n",
    "my_accuracy = accuracy_score(actual_labels, predicted_labels, normalize=False) / float(actual_labels.size)\n",
    "my_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
